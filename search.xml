<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>CNN模型之ZFNet</title>
      <link href="/2019/09/16/cnn-mo-xing-zhi-zfnet/"/>
      <url>/2019/09/16/cnn-mo-xing-zhi-zfnet/</url>
      
        <content type="html"><![CDATA[<h4 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZFNet是Matthew D.Zeiler于2013年提出，并获得了13年ImageNet的冠军。2012年AlexNet问世，并在ImageNet竞赛中取得了优异的成绩，也证明了大的卷积网路的性能优异，但是我们并不知道为什么CNN性能好。因此，这篇论文介绍了一个可视化技术来了解隐藏层做了什么以及怎么进行分类。也是基于这个技术，作者对AlexNet进行了优化，调整之后的网络的性能在很多问题上性能都好于AlexNet。</p><h4 id="二、模型结构"><a href="#二、模型结构" class="headerlink" title="二、模型结构"></a>二、模型结构</h4><p><img src="https://img-blog.csdnimg.cn/20190916154402708.png" alt="ZFNet模型结构图"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZFNet的网络结构是基于AlexNet改进的。作者通过可视化技术发现小尺度的过滤器比大尺度的过滤器所得到的特征更加好。并且第一层的步长太大，导致后面出现混叠现象，学到的特征不是很好。因此，主要做了以下更改：</p><ul><li>将第一层的滤波器由$11\times 11$调整为$7\times 7$。</li><li>将第一层的步长由4调整为2.</li></ul><p><strong>可视化技术：</strong><br> <img src="https://img-blog.csdnimg.cn/20190916155817765.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，通过反池化和反卷积得到原始图像。经过了可视化后，发现调整尺寸和步长后，得到的中间层特征更好。<br><img src="https://img-blog.csdnimg.cn/20190916160615693.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h4 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;经过对中间层的可视化，可以观察到模型中间层的特征。并依据特征的好坏调整模型的卷积核大小和步长。在ImageNet上取得了比AlexNet更好的成绩，获得了2013年的第一名。这个技术也让我们明白了卷积神经网络是如何工作的。最后，在代码实现中，仅仅构造了网络的结构，我使用的是cifar10数据集。如果训练需要更改网络的一些设置。</p><blockquote><p>友情链接：<br>代码实现：<a href="https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch" target="_blank" rel="noopener">https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch</a><br>联系方式：2391855138(加好友请备注)</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 卷积神经网络模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN模型之AlexNet</title>
      <link href="/2019/09/05/cnn-mo-xing-zhi-alexnet/"/>
      <url>/2019/09/05/cnn-mo-xing-zhi-alexnet/</url>
      
        <content type="html"><![CDATA[<h4 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AlexNet是Alex Krizhevsky等人2012年提出。这个模型具有重大的意义，将ImageNet ILSVRC-2010竞赛的120万张图片1000个类别。top-1错误率为37.5%，top-5错误率为17.0%。在2012年的比赛中，将top-5错误率降到了15.3%，相较于第二名26.2%的错误率。AlexNet的性能提升了很多。</p><h4 id="二、网络结构"><a href="#二、网络结构" class="headerlink" title="二、网络结构"></a>二、网络结构</h4><p><img src="https://img-blog.csdnimg.cn/20190905211805456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AlexNet的网络结构：5个卷积层+3个全连接层(包含一个输出层)。</p><ul><li>第一个卷积层：Conv+LRN+ReLU+MaxPool。96个大小为$11\times 11\times 3$的卷积核，步长为4</li><li>第二个卷积层：Conv+LRN+ReLU+MaxPool。256个大小为$5 \times 5\times 48$的卷积核。</li><li>第三个卷积层：Conv+ReLU。256个大小为$3\times 3\times 256$的卷积核。</li><li>第四个卷积层：Conv+ReLU。384个大小为$3\times 3\times 192$的卷积核。</li><li>第五个卷积层：Conv+ReLU+MaxPool。256个大小为$3\times 3\times 192$的卷积核。</li><li>两个全连接层：都配有ReLU和Dropout。4096个单元。</li><li>输出层：1000个单元。配有softmax多分类器。</li></ul><h5 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h5><ul><li>使用ReLU代替传统的激活函数</li><li>LRN：局部响应归一化，将数据归一化到0-1之间。</li><li>重叠池化使特征图更加稠密，类似于2*2滤波器卷积</li><li>Dropout防止过拟合，正则化方法。</li><li>使用了数据增强来丰富样本。</li><li>Softmax损失函数，分类器。<h4 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h4>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AlexNet在卷积神经网络的发展上非常重要，也是从这个模型开始，卷积神经网络蓬勃发展。其使用了ReLU、LRN、Dropout等方法来提高模型的精度。虽然现在有很多模型，但这个模型也是我们必须学习的模型，从模型的分析来理解模型每个技术的作用。<blockquote><p>友情链接：<br>代码实现：<a href="https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch" target="_blank" rel="noopener">https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch</a><br>联系方式：2391855138(加好友请备注)</p></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> 卷积神经网络模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN模型之LeNet-5</title>
      <link href="/2019/09/05/cnn-mo-xing-zhi-lenet-5/"/>
      <url>/2019/09/05/cnn-mo-xing-zhi-lenet-5/</url>
      
        <content type="html"><![CDATA[<h4 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;卷积神经网络是当前深度学习领域比较火的研究方法。其应用主要是在计算机视觉上。例如，图像分类，目标检测，人脸识别等等。并且已经在这些领域取得了相当大的成就。本文主要介绍卷积神经网络的开篇之作：LeNet-5。LeNet-5由Y. LeCun 在1998年发表的文章《Gradient-Based Learning Applied to Document Recognition 》中正式提出。在论文中，应用MNIST手写数字体数据做实验。LeNet并不是1998年才存在的。在1989年Y.LeCun的另一篇文章就已经提到。知识在1998年正式提出。下面，我们就看一下LeNet-5的网络结构。</p><h4 id="二、模型结构"><a href="#二、模型结构" class="headerlink" title="二、模型结构"></a>二、模型结构</h4><p><img src="https://img-blog.csdnimg.cn/20190826193656596.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="图1：LeNet-5网络结构图"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图是LeNet-5的网络结构图。该网络一共包含7层，输入时一个$32\times 32$的图像。当我们实际应用这个网络的时候可以根据实际的问题来修改输入尺寸与网络中的结构。</p><ol><li>Layer C1：第一个卷积层，得到6个$28\times28$的特征图。卷积核的大小为$5\times5$。</li><li>Layer S2：下采样层等同于池化层，我们一般使用最大池化操作。得到6个$14\times14$的特征图。设置$2\times2$的过滤器。</li><li>Layer C3：第二个卷积层，得到16个$5\times5$的特征图。卷积核的大小为$5\times5$。</li><li>Layer S4：下采样层等同于池化层。得到16个$5\times5$的特征图。设置$2\times2$的过滤器。</li><li>Layer C5：第三个卷积层，得到120个$1\times1$的特征图。卷积核的大小为$5\times5$。因为S4得到的特征图也是$5\times5$。所以得到的输出是1个数。这步相当于全连接。通常我们直接设置全连接层。</li><li>Layer F6：全连接层，设置84个单元。激活函数可以使用Relu。</li><li>Layer F7：输出层，10个单元。根据问题来决定，因为从0-9一共10类。随意设置为10。激活函数使用softmax。</li></ol><p><strong>主要贡献：</strong></p><ul><li>局部感受野(local receptive fields)，局部连接</li><li>权值共享（参数共享）</li><li>下采样(sub-sampling)，pooling层<h4 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h4>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LeNet-5是一个简单的卷积神经网络，相较于传统的神经网络其参数更少，性能也更优。是卷积神经网络的一个开端。最后的损失函数我们使用了均方差损失函数。如果对神经网络有一定的了解，应该可以了解整个神经网络的运行过程。到这里这篇文章就完事了。我们只是为了来记录LeNet-5的网络结构。并没有细讲网络的具体知识。如有不懂，想深入讨论。可以加我联系方式一起学习。<blockquote><p>友情链接：<br>代码实现：<a href="https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch" target="_blank" rel="noopener">https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch</a><br>联系方式：2391855138(加好友请备注)</p></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> 卷积神经网络模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>周志华《机器学习》读书笔记----第二章：模型评估与选择</title>
      <link href="/2019/09/05/zhou-zhi-hua-ji-qi-xue-xi-du-shu-bi-ji-di-er-zhang-mo-xing-ping-gu-yu-xuan-ze/"/>
      <url>/2019/09/05/zhou-zhi-hua-ji-qi-xue-xi-du-shu-bi-ji-di-er-zhang-mo-xing-ping-gu-yu-xuan-ze/</url>
      
        <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;机器学习要做的工作可以这样理解：给定一些数据，在数据上训练模型，得到能解决我们实际问题的模型。在这个过程中，数据的处理，模型的选择，模型的评估都需要花费一些时间来处理。这节内容就是模型的选择与评估。</p><h4 id="一、经验误差与过拟合"><a href="#一、经验误差与过拟合" class="headerlink" title="一、经验误差与过拟合"></a>一、经验误差与过拟合</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在训练过程中，学习器的实际预测输出与样本的真实输出之间的差异称为<strong>误差</strong>。学习器在训练集上的误差称为<strong>训练误差</strong>或<strong>经验误差</strong>。在新样本上的误差称为<strong>泛化误差</strong>。我们希望得到泛化误差小的学习器。然而我们实际能做的是使经验误差最小化。可惜的是经验误差最小时，泛化误差不一定是最好的。我们希望学习器能从训练样本中尽可能学出适用于所有潜在样本的<strong>普遍规律</strong>。但是有时候学习器的能力过强，将一些样本自身的特点当作了样本的一般性质。导致泛化性能下降，造成<strong>过拟合</strong>现象。还有时学习器的学习能力不够，学习不到样本的潜在规律，会造成<strong>欠拟合</strong>现象。也会使泛化性能下降。因此，我们要解决模型存在的欠拟合或者过拟合现象，提高模型的泛化性能。在实际的问题中，我们可以获得多种学习算法，不同的参数会出现不同的模型。因此，模型的选择就是要对候选模型的泛化误差进行评估，然后选择泛化误差最小的模型。</p><h4 id="二、评估方法"><a href="#二、评估方法" class="headerlink" title="二、评估方法"></a>二、评估方法</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;经验误差由于过拟合问题的存在，不能作为选择模型的标准。又无法直接获得泛化误差。因此，我们通过实验测试来对学习器的泛化误差进行评估，然后做出选择。我们设置一个<strong>测试集</strong>来测试学习器对新样本的判别性能。在测试集上的误差我们称之为<strong>测试误差</strong>。使用测试误差来作为泛化误差的近似。我们假设测试数据也是从真实样本中独立同分布采样得到。要求测试集与训练集要互斥。通常我们可以得到一个包含$m$个样本的数据集D,然后对D进行适当的划分，划分为测试集和训练集。<br>$$D=\left { (x_{1},y_{1}), (x_{2},y_{2}), …,(x_{m},y_{m})\right }$$</p><h5 id="方法一：留出法"><a href="#方法一：留出法" class="headerlink" title="方法一：留出法"></a>方法一：留出法</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>留出法</strong>直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试机T，用数学公式表示为：$D=S\cup T,S\cap T=\varnothing$。在训练集上训练出模型后，在测试集上评估测试误差，作为对泛化误差的估计。例如，包含1000个样本的数据集，S包含700个样本，T包含300个样本。留出法需要注意以下三点：</p><ol><li>划分数据时，要保证数据的一致性。例如1000个样本中包含500个正例，500个反例。如果按照S：70%，T：30%的比例划分。那么对于正例，应该取350个作为S，150个作为T。反例也是如此。这叫保持样本的列别比例相似。假如S、T中的样本类别比例差别很大，则测试估计将由于训练/测试数据分布的差异而产生偏差。</li><li>单次使用留出法得到的估计结果往往不够稳定可靠。因此，可以多次划分，重复实验，取平均值做留出法的评估结果。</li><li>选择训练集与测试集的比例也很重要，一般训练集大约占$\frac{2}{3}\sim \frac{4}{5}$，剩下的样本用作测试集。</li></ol><h5 id="方法二：交叉验证法"><a href="#方法二：交叉验证法" class="headerlink" title="方法二：交叉验证法"></a>方法二：交叉验证法</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>交叉验证法</strong>先将数据集D划分为k个大小相似的互斥子集。即$D=D_{1}\cup D_{2}\cup …\cup D_{k},D_{i}\cap D{j}=\varnothing (i\neq j)$。将前k-1个子集作为训练集，余下的那个子集作为测试集。获得k组训练集/测试集。可以进行k次训练和测试，返回k个测试结果的均值。这种方法一般叫做<strong>k折交叉验证法</strong>。k值是此方法的关键，一般常用的值为5、10、20等。与留出法相同，k折交叉验证法仍然可以重复多次实验，最后取平均值作为最终的评估结果。</p><h5 id="方法三：自助法"><a href="#方法三：自助法" class="headerlink" title="方法三：自助法"></a>方法三：自助法</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>自助法</strong>是让我们可以使用数据集D来训练模型，然而并不是真正意义上的数据集D，只是训练数据集的规模与数据集D相同。留出法与交叉验证法都保留了一些数据用作测试数据。会引入一些因训练样本规模不同而导致的估计偏差。自助法以<strong>自助采样</strong>为基础。自助法从包含m个样本的数据集D中采样得到训练数据集$D^{‘}$。每次从数据集D中抽取一个一样，将其放入到$D^{‘}$中，然后再将该样本放回初始数据集D中，使得样本在下次采样时仍然可以被采到。重复执行m次后，得到包含m个样本的数据集$D^{‘}$。D中会有一部分样本多次出现在$D^{‘}$中，有一部分不会出现在其中。我们可以估计样本在m次采样中始终不被采到的概率为$(1-\frac{1}{m})^{m}$,取极限得到$\underset{m\rightarrow \infty }{lim}(1-\frac{1}{m})^{m}=\frac{1}{e}\approx 0.368$，也就是说数据集D中有36.8%的数据未出现在采样数据$D^{‘}$中，因此，数据集$D^{‘}$作为训练集，$D-D^{‘}$作为测试集。自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，我们常用留出法和交叉验证法。</p><h5 id="方法四：调参与最终模型"><a href="#方法四：调参与最终模型" class="headerlink" title="方法四：调参与最终模型"></a>方法四：调参与最终模型</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;机器学习算法通常涉及两类参数，一类是算法的参数，也就是超参数，数目在10以内，另一类是模型的参数，参数有很多。因此，<strong>调参</strong>是一个重要的任务。通常的做法是给定一个参数取值范围，在其中选取几个值测试模型，选取泛化性能最好的。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们通常把学得模型在实际使用中遇到的数据称为测试集，模型评估与选择中用于评估测试的数据集通常称为<strong>验证集</strong>。因此，用测试集上的判别效果来估计模型在实际应用中的泛化能力，把训练集划分为训练集和测试集，基于验证集上的性能来进行模型选择和调参。</p><h4 id="三、性能度量"><a href="#三、性能度量" class="headerlink" title="三、性能度量"></a>三、性能度量</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了衡量模型的泛化能力，要有一个评价标准，就是性能度量。当我们使用不同的性能度量来对比不同模型的能力时，往往可以得到不同的评判结果。因此，要根据实际问题的需求，使用正确的性能度量来评判模型。给定数据集$D=\left { (x_{1},y_{1}), (x_{2},y_{2}), …,(x_{m},y_{m})\right }$，评估学习器$f$的性能，就需要将预测结果$f(x)$与真实标记$y$进行比较。</p><h5 id="1-均方误差"><a href="#1-均方误差" class="headerlink" title="1. 均方误差"></a>1. 均方误差</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;均方误差是回归任务常用的性能度量。<br>$$<br>E(f;D)=\frac{1}{m}\sum_{i=1}^{m}(f(x_{i})-y_{i})^{2}<br>$$</p><h5 id="2-错误率与精度"><a href="#2-错误率与精度" class="headerlink" title="2. 错误率与精度"></a>2. 错误率与精度</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>错误率</strong>是分类错误的样本数占样本总数的比例，<strong>精度</strong>是分类正确的样本数占样本总数的比例。<br>错误率：<br>$$<br>E(f;D)=\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}(f(x_{i})\neq y_{i})<br>$$<br>精度：<br>$$<br>acc(f;D)=\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}(f(x_{i})=  y_{i})=1-E(f;D)<br>$$</p><h5 id="3-查准率、查全率与F1"><a href="#3-查准率、查全率与F1" class="headerlink" title="3. 查准率、查全率与F1"></a>3. 查准率、查全率与F1</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>查准率</strong>是在所有预测为正例的结果中，真实为正例的比例。<strong>查全率</strong>是所有真实为正例的样本中，预测出为正例所占的比例。查准率与查全率是为了应对我们存在不同需求时的性能度量。二分类问题中，将样例根据真实类别与学习器预测类别的组合划分为真正例(TP)、假正例(FP)、真反例(TN)、假反例(FN)四种情况。<strong>F1</strong>度量是综合考虑了查准率和查全率。</p><table>    <tr>        <th rowspan="2">真实情况</th>        <th colspan="2">预测结果</th>    </tr>    <tr>        <td>正例</td>        <td>反例</td>    </tr>    <tr>        <td>正例</td>        <td>TP(真正例)</td>        <td>FN(假反例)</td>    </tr>    <tr>        <td>反例</td>        <td>FP(假正例)</td>        <td>TN(真反例)</td>    </tr></table><p>查准率：<br>$$<br>P=\frac{TP}{TP+FP}<br>$$<br>查全率：<br>$$<br>R=\frac{TP}{TP+FN}<br>$$<br>F1度量：<br>$$<br>F1=\frac{2\times P\times R}{R+P}<br>$$</p><h5 id="4-ROC与AUC"><a href="#4-ROC与AUC" class="headerlink" title="4. ROC与AUC"></a>4. ROC与AUC</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>ROC</strong>的全称是“受试者工作特征”曲线，ROC曲线的纵轴是“真正例率”(TPR)，横轴是“假正例率”(FPR)。<br>TPR：<br>$$<br>TPR=\frac{TP}{TP+FN}<br>$$<br>FPR:<br>$$<br>FPR=\frac{FP}{FP+TN}<br>$$</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>AUC</strong>代表的是ROC曲线与坐标轴围成的面积。</p><h5 id="5-代价敏感错误率与代价曲线"><a href="#5-代价敏感错误率与代价曲线" class="headerlink" title="5. 代价敏感错误率与代价曲线"></a>5. 代价敏感错误率与代价曲线</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在现实的任务中，不同类型的错误所造成的后果不同。为了权衡不同类型错误所造成的不同损失，可以为错误赋予<strong>非均等代价</strong>。以二分类为例，设定一个代价矩阵，其中$cost_{ij}$表示将第i类样本预测为第j类样本的代价。一般来说，$cost_{ii}=0$.若将第0类判别为第1类所造成的损失更大。则$cost_{01}&gt;cost_{10}$。</p><table>    <tr>        <th rowspan="2">真实类别</th>        <th colspan="2">预测类别</th>    </tr>    <tr>        <td>第0类</td>        <td>第1类</td>    </tr>    <tr>        <td>第0类</td>        <td>0</td>        <td>cost01</td>    </tr>    <tr>        <td>第1类</td>        <td>cost10</td>        <td>0</td>    </tr></table><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在非均等代价下，我们希望最小化总体代价。将第0类作为正类，第1类作为反类。令$D^{+}$与$D^{-}$分别代表数据D的正例子集和反例子集。则<strong>代价敏感错误率</strong>为$$<br>E(f;D;cost)=\frac{1}{m}(\sum_{x_{i}\in D^{+}}\mathbb{I}(f(x_{i}\neq y_{i})\times cost_{01}+\sum_{x_{i}\in D^{-}}\mathbb{I}(f(x_{i}\neq y_{i})\times cost_{10})<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在非均等代价下，ROC曲线不能直接反应出学习器的期望总体代价，我么可以使用<strong>代价曲线</strong>。代价曲线的横轴取值为$[0,1]$的正例概率代价：<br>$$<br>P(+)cost=\frac{p\times cost_{01}}{p\times cost_{01}+(1-p)\times cost_{10}}<br>$$<br>p代表样例为正例的概率。纵轴是取值为[0,1]的归一化代价：<br>$$<br>cost_{norm}=\frac{FNR\times p\times cost_{01}+FPR\times (1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}}<br>$$</p><h4 id="四、比较检验"><a href="#四、比较检验" class="headerlink" title="四、比较检验"></a>四、比较检验</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先使用某种实验的评估方法测得学习器的某个性能度量结果，然后对这些结果进行比较选择模型。但是，怎么进行比较，在机器学习中的性能比较涉及几个重要因素：</p><ol><li>我们得到的是在测试集上的性能，我们希望比较的是泛化性能。那测试性能是否可以代表泛化性能。</li><li>测试性能因测试数据本身的选择有关系，测试集的大小和测试集样例不同，都会影响到测试的性能。</li><li>机器学习算法本身存在随机性，即使参数相同，结果也不相同。</li></ol><p>这些因此，造成了我们比较学习器的性能时，就不能只进行普通的比较。<strong>统计假设检验</strong>为我们进行学习器的性能比较提供了重要依据。<font color="red">基于假设检验结果我们可推断出，若在测试集上观察到学习器A比B好，则A的泛化性能是否在统计意义上优于B，以及这个结论的把握有多大。</font>简单的说就是如果测试集上的性能A好于B，那么是否就可以说A的泛化性能好于B。对于这个结论有多大的可能认为是正确的。<br>常用的假设检验方法：</p><ul><li>假设检验</li><li>t检验</li><li>交叉验证t检验</li></ul><p>常用的性能比较方法：</p><ul><li>McNemar检验</li><li>Friedman检验与Nemenyi后续检验</li></ul><h5 id="1-偏差与方差"><a href="#1-偏差与方差" class="headerlink" title="1. 偏差与方差"></a>1. 偏差与方差</h5><p>我们试图理解学习算法为什么具有这样的性能，<strong>偏差-方差分解</strong>是解释学习算法泛化性能的一种重要工具。偏差-方差分解试图对学习算法的期望泛化错误率进行拆解。测试样本$x$。$x$在数据集中的标记为$y_{D}$，$x$的真实标记$y$。$f(x;D)$为模型的输出结果。<strong>偏差</strong>度量了学习算法的期望预测与真实结果的偏离程度，刻画了算法的本身拟合能力。<strong>方差</strong>度量了同样大小的训练集的变动所导致的学习性能的变化，刻画了数据扰动所造成的影响。<strong>噪声</strong>表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界。刻画了问题的本身难度。<br>学习算法的期望预测：$\overline{f}(x)=E_{D}[f(x;D)]$<br>样本数相同的不同训练集产生的方差：$var(x)=E_{D}[(f(x;D)-\overline{f}(x))^{2}]$<br>噪声：$\varepsilon^{2}=E_{D}[(y_{D}-y)^{2}]$<br>偏差：$bias^{2}(x)=(\overline{f}(x)-y)^{2}$<br>算法的<strong>期望泛化误差</strong>：$$<br>E(f;D)=bias^{2}(x)+var(x)+\varepsilon ^{2}<br>$$<br>期望泛化误差可以分解为偏差、方差和噪声之和。因此，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。</p>]]></content>
      
      
      <categories>
          
          <category> 周志华《机器学习》 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 读书笔记 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI圣经《深度学习》读书笔记----第二章：线性代数</title>
      <link href="/2019/08/21/ai-sheng-jing-shen-du-xue-xi-du-shu-bi-ji-di-er-zhang-xian-xing-dai-shu/"/>
      <url>/2019/08/21/ai-sheng-jing-shen-du-xue-xi-du-shu-bi-ji-di-er-zhang-xian-xing-dai-shu/</url>
      
        <content type="html"><![CDATA[<blockquote><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;线性代数是数学的一个分支，应用于科学和工程中。线性代数主要是面向连续数学，而非离散数学。掌握好线性代数对于学习机器学习算法是必要的，尤其是深度学习算法。因此，本章学习必要的线性代数知识。</p></blockquote><h4 id="知识点一：标量、向量、矩阵和张量"><a href="#知识点一：标量、向量、矩阵和张量" class="headerlink" title="知识点一：标量、向量、矩阵和张量"></a>知识点一：标量、向量、矩阵和张量</h4><p><strong>标量(scalar)：</strong> 一个标量就是一个单独的数，不同于线性代数中研究的其他大部分对象。当介绍标量时，会明确标量的类型。<br><strong>向量(vector)：</strong> 一个向量是一列数。这些数是有序排列的，通过次序的索引，可以得到每个单独的数。表示为</p><p>$$<br>x =<br>\begin{pmatrix}<br>x_{1}\<br>x_{2}\<br>\vdots\<br>x_{n}\<br>\end{pmatrix}<br>$$<br><strong>矩阵(matrix)：</strong> 矩阵是一个二维数组，其中的每一个元素由两个索引确定。一个2行2列的矩阵表示为<br>$$<br>A =<br>\begin{pmatrix}<br>A_{1,1}&amp;A_{1,2}\<br>A_{2,1}&amp;A_{2,2}\<br>\end{pmatrix}<br>$$<br><strong>张量(tensor)：</strong> 某些情况下，会讨论坐标超过两维的数组。一般地，一个数组中的元素分布在若干维坐标的规则网格中，我们称之为张量。<br><strong>转置：</strong> 矩阵的转置是以对角线为轴的镜像。从左上角到右下角的对角线称为主对角线。表示为$(A^T)<em>{i,j}=A</em>{j,i}$。向量可看作是只有一列的矩阵，那么向量的转置就是只有一行的矩阵。标量的转置等于其本身。</p><h4 id="知识点二：矩阵的运算"><a href="#知识点二：矩阵的运算" class="headerlink" title="知识点二：矩阵的运算"></a>知识点二：矩阵的运算</h4><p> <strong>矩阵相加：</strong> 当矩阵形状相同时，矩阵对应位置的元素相加，表示为$C_{i,j}=A_{i,j}+B_{i,j}$。<br> <strong>标量和矩阵相加或相乘：</strong> 只需将标量与矩阵的每个元素相乘或相加。表示为$D_{i,j}=a<em>B_{i,j}+c$<br> *</em>矩阵和向量相加：** 就是将向量和矩阵的每一行相加。表示为$C_{i,j}=A_{i,j}+b_{j}$。这种方法类似于将向量展开成一个与矩阵同维度的矩阵，然后在相加。这种方式称为<strong>广播。</strong><br> <strong>矩阵相乘：</strong> 矩阵A和B相乘，矩阵A的列数必须和矩阵B的行数相等。表示为$C_{i,j}=\sum A_{i,k}B_{k,j}$。还有一种是矩阵元素对应乘积，也就是对应元素的乘积。</p><h4 id="知识点三：单位矩阵、逆矩阵和特殊类型的矩阵与向量"><a href="#知识点三：单位矩阵、逆矩阵和特殊类型的矩阵与向量" class="headerlink" title="知识点三：单位矩阵、逆矩阵和特殊类型的矩阵与向量"></a>知识点三：单位矩阵、逆矩阵和特殊类型的矩阵与向量</h4><p> <strong>单位矩阵：</strong> 对角线为1，其他位置为0的矩阵，单位矩阵与任何向量相乘，都不会改变。<br>$$<br>A =<br>\begin{pmatrix}<br>A_{1,1}&amp;A_{1,2}\<br>A_{2,1}&amp;A_{2,2}\<br>\end{pmatrix}<br>$$<br><strong>逆矩阵：</strong> 矩阵A的逆矩阵记作$A^{-1}$，满足$A^{-1}A=I_{n}$。<br><strong>对角矩阵：</strong> 对角矩阵是在主对角线上含有非零元素，其他位置都为零。对角矩阵的逆矩阵就是将对角线元素取倒数。<br><strong>对称矩阵：</strong> 矩阵是转置和自己相等的矩阵。即$A=A^T$。<br><strong>单位向量：</strong> 是具有单位范数的向量。即$||x||_{2}=1$。<br><strong>正交矩阵：</strong> 指行向量和列向量是分别标准正交的方阵。标准正交是矩阵中的行向量或者列向量两两相乘等于0，并且范数为1.正交矩阵满足：<br>$$<br>A^TA=AA^T=I<br>$$<br>$$<br>A^{-1}=A^T<br>$$</p><h4 id="知识点四：范数"><a href="#知识点四：范数" class="headerlink" title="知识点四：范数"></a>知识点四：范数</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;范数是用来衡量向量的大小，形式上，$L^p$范数可以定义为<br>$$<br>||x||<em>{p}=(\sum</em>{i} |x_{i}|^p)^{\frac{1}{p}}<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，$p\geq1$。范数是将向量映射到非负值的函数。x的范数可以理解为衡量从原点到点x的距离。范数需要满足如下性质：</p><ul><li>$f(x)=0=&gt;x=0$</li><li>$f(x+y)\leq f(x)+f(y)$</li><li>$\forall \alpha \in \mathbb{R}f(\alpha x)=\left | \alpha  \right |f(x)$</li><li><em>$L^2$范数：*</em> 又叫欧几里得范数，表示从原点到向量x的欧几里得距离。常用来衡量向量的大小。计算公式为：<br>$$<br>\left | x \right |<em>{2}=\left | x \right |=\sqrt{\sum</em>{i}x_{i}^{2}}<br>$$</li><li><em>$L^{1}$范数：*</em> 当问题中，零和非零元素之间的差异非常重要时，使用$L^1$范数。表示为<br>$$<br>\left | x \right |<em>{1}=\sum</em>{i}\left | x_{i} \right |<br>$$</li><li><em>$L^0$范数：*</em> 统计向量中非零元素的个数来衡量向量的大小。但是非零元素的数目并不是范数，因为对向量进行缩放，非零元素的个数不变。因此，使用$L^1$范数替代。</li><li><em>$L^{\propto }$范数：*</em> 也叫最大范数。表示向量中具有最大幅值的元素的绝对值。表示为<br>$$<br>\left | x \right |<em>{\propto }=\underset{i}{max}\left | x \right |</em>{i}<br>$$</li><li><em>Frobenius范数：*</em> 用来衡量矩阵的大小。表示为<br>$$<br>\left | A \right |<em>{F}=\sqrt{\sum</em>{i,j}A^{2}_{i,j} }<br>$$<h4 id="知识点五：特征值分解与奇异值分解"><a href="#知识点五：特征值分解与奇异值分解" class="headerlink" title="知识点五：特征值分解与奇异值分解"></a>知识点五：特征值分解与奇异值分解</h4></li><li><em>特征分解：*</em> 是将矩阵分解为一组特征向量和特征值。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;方阵A的特征向量是指与A相乘后相当于对该向量进行缩放的非零向量。表示为<br>$$<br>Av=\lambda v<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，$\lambda$为特征值，v为特征向量。我们将特征向量连接成一个矩阵，使得每一列是一个特征向量：$V=\left { v^{(1)},v^{(2)},…,v^{(3)} \right }$。同样，可以将一个特征值连接成一个向量$\lambda =\left [ \lambda _{1},…,\lambda _{n} \right ]$。因此，A的<strong>特征分解</strong>可以记作<br>$$A=Vdiag(\lambda )V^{-1}$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;并不是所有的矩阵都是可以特征分解的。所有特征值都是正数的矩阵称为正定。</li><li><em>奇异值分解(SVD)：*</em> 将矩阵分解为奇异向量和奇异值。每个实数矩阵都有一个奇异值分解。但是不一定存在特征值分解。奇异值分解可将矩阵A分解为<br>$$<br>A=UDV^{T}<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，A是一个$m\times n$的矩阵，U是一个$m\times m$的矩阵，D是一个$m\times n$的矩阵，V是一个$n\times n$的矩阵。矩阵U和V都是正交矩阵。D是对角矩阵。但不一定是方阵，D的对角线上的元素是矩阵A的奇异值。矩阵U的列向量是左奇异向量，矩阵V的列向量是右奇异向量。<h4 id="知识点六：Moore-Penrose伪逆"><a href="#知识点六：Moore-Penrose伪逆" class="headerlink" title="知识点六：Moore-Penrose伪逆"></a>知识点六：Moore-Penrose伪逆</h4>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当矩阵是非方阵时，是没有逆矩阵的。当我们求解线性方程$Ax=y$时。使用A的逆矩阵$A^{-1}$来求解。得到<br>$$<br>x = A^{-1}y<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，如果矩阵A的行数大于列数，那么上述方程没有解。如果矩阵A的行数小于列数，那么上述方程可能有多个解。因此，我们使用Moore-Penrose伪逆解决这个问题。矩阵A的伪逆定义为<br>$$<br>A^{+}=\underset{\alpha \rightarrow 0}{lim}(A^{T}A+\alpha I)^{-1}A^{T}<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，我们使用如下公式计算<br>$$<br>A^{+}=VD^{+}U^{T}<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，U、D和V时矩阵A奇异值分解后得到的矩阵。对角矩阵D的伪逆$D^+$是其非零元素取倒数之后在转置得到的。使用伪逆求得的x使得Ax和y的欧几里得距离最小。<h4 id="知识点七：迹运算和行列式"><a href="#知识点七：迹运算和行列式" class="headerlink" title="知识点七：迹运算和行列式"></a>知识点七：迹运算和行列式</h4></li><li><em>迹运算：*</em> 返回的是矩阵对角元素的和<br>$$<br>Tr(A)=\sum_{i}A_{i,i}<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们可以使用矩阵的迹运算，描述很多运算</li><li>Frobennins范数：$\left | A \right |_{F}=\sqrt{Tr(AA^{T})}$</li><li>迹运算在转置运算下是不变的：$Tr(A)=Tr(A^{T})$</li><li>多个矩阵相乘得到的方阵的迹。等于把矩阵中最后一个挪到最前面之后相乘的迹：$Tr(ABC)=Tr(CAB)=Tr(BCA)$</li><li>循环置换后矩阵乘积得到的矩阵形状改变，但是迹运算的结果不变:$Tr(AB)=Tr(BA)$</li><li>标量在迹运算后仍是自己：$a=Tr(a)$</li></ul><p><strong>行列式：</strong> 记作$det(A)$，是一个将方阵A映射到实数的函数。行列式等于矩阵特征值的乘积。用来衡量矩阵参与矩阵乘法后空间扩大或者缩小了多少。如果为0，那么空间至少沿着某一维完全收缩。失去了所有的体积。如果行列式是1。则转换空间保持不变。</p><h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;线性代数在机器学习中扮演着重要的角色。因此，了解线性代数的知识是必要的。本章只是介绍了线性代数的一些基本知识。如果有精力，还需要仔细学习线性代数的知识。</p><blockquote><p>友情链接：<br>github主页：<a href="https://github.com/guoyuantao" target="_blank" rel="noopener">https://github.com/guoyuantao</a><br>CSDN博客：<a href="https://blog.csdn.net/gyt15663668337" target="_blank" rel="noopener">https://blog.csdn.net/gyt15663668337</a><br>个人博客主页：<a href="https://guoyuantao.github.io/">https://guoyuantao.github.io/</a><br>QQ讨论群：218803539</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI圣经《深度学习》读书笔记----第一章：引言</title>
      <link href="/2019/08/15/ai-sheng-jing-shen-du-xue-xi-du-shu-bi-ji-di-yi-zhang-yin-yan/"/>
      <url>/2019/08/15/ai-sheng-jing-shen-du-xue-xi-du-shu-bi-ji-di-yi-zhang-yin-yan/</url>
      
        <content type="html"><![CDATA[<blockquote><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这本书从我开始学习深度学习时，就买了这本书。但是，因为自身知识储备不够，觉得这本书很难。多次想学习这本书，但是都失败了。距离本次学习，已经时隔一年。希望这次能将这本书看完，学习书中的知识。并通过博客的方式，记录自己学习的过程和对知识进行总结。</p></blockquote><h3 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所谓的人工智能就是让机器具有智能，能像人类一样处理事务。具有人的智能。目前，人工智能已经成为一个具有众多实际应用和活跃研究课题的领域，并这在蓬勃发展，我们希望通过智能软件自动地处理常规劳动、理解语音或图像、帮助医学诊断和支持基础科学研究。在人工智能的早期，那些对人类智力来说比较困难，但对计算机来说很简单的问题得到迅速解决。比如说可以用一系列形式化的数学规则来描述的问题。然而，<font color="red" size="3">人工智能真正的挑战是解决那些对人类来说很容易做到，但是很难形式化的任务。</font>例如，识别图像中的物体。本书给出一种解决方案，该方案可以让计算机从经验中学习，并根据层次化的概念体系来理解世界，而每个概念则通过与某些相对简单的概念之间的关系来定义。我们称这种方法为 <strong>AI深度学习</strong>。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;人工智能的一个关键挑战就是如何一些非形式化的知识传达给计算机。一些人工智能项目将关于世界得知识用形式化的语言进行硬编码。然后计算机可以通过逻辑推理规则自动地理解这些形式化语言中的声明。这就是众所周知的<strong>知识库</strong>方法。但是这些声明是人类监督者输入的，它没有足够的形式化规则来精确地描述世界。因此，AI系统具备自己获取知识的能力，<font color="red" size="3">即从原始数据从提取模式的能力。</font>这种能力叫做<strong>机器学习</strong>。机器学习算法的性能依赖于<strong>数据的表示</strong>。例如一个称为逻辑回归的简单算法，用它判断产妇是否适合剖腹产时，AI系统不能直接检查患者，需要医生给出患者的相关信息。表示患者的每条信息称为一个特征。<font color="red" size="3">逻辑回归学习病人的这些特征如何与各种结果相关联。</font>因此，表示的选择对机器学习算法的性能产生巨大的影响。许多问题都是先提取一个合适的特征集，然后将这些特征提供给简单的机器学习算法。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，提取特征来说是一件很难的事情，依靠人类来说，并不知道应该提取那些特征。因此，解决这个问题的途径是使用机器学习来发掘表示的本身，而不仅仅是把表示映射到输出，这种方法我们称为<strong>表示学习</strong>。<font color="red" size="3">学习到的表示往往比手动设计的表示表现的更好。</font>表示学习的典型例子是自编码器，自编码器由一个编码器和一个解码器组成。编码器函数就是将输入数据转换为一种不同的表示。当设计特征或设计用于学习特征的算法时，我们的目标是分离出能解释观察数据的<strong>变差因素</strong>。这些因素不能被直接观察到的量，但会影响可观测的量。有时具有多个变差因素时，会影响到我们观察到的每个数据。而<strong>深度学习</strong>通过其他较简单的表示来表达复杂表示，解决了表示学习中的核心问题。深度学习让计算机通过简单的概念构造复杂的概念。典型例子是多层感知器。它是一个将一组输入映射到输出值的数学函数。该函数由许多简单的函数复合而成。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;深度学习是通向人工智能的途径之一，是机器学习的一种，能够使计算机系统从经验和数据中得到提高的技术。<font color="red" size="3">深度学习是一种特定类型的机器学习，具有强大的能力和灵活性，它将大千世界表示为嵌套的层次概念体系(由简单概念间的联系定义复杂概念、从一般抽象概括到高级抽象表示。</font><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用维恩图表示深度学习的关系。<br><img src="https://img-blog.csdnimg.cn/20190815195543929.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_8,color_FFFFFF,t_70" alt><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下图展示AI系统在不同的AI学科中彼此相关，阴影框表示能从数据中学习的组件。<br><img src="https://img-blog.csdnimg.cn/20190815201143926.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt></p><h3 id="二、深度学习的发展"><a href="#二、深度学习的发展" class="headerlink" title="二、深度学习的发展"></a>二、深度学习的发展</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;人工智能的历史要追溯到1956年的达特茅斯会议，其实早在这之前就提过。只是达特茅斯会议算是一个正式的提出。有兴趣研究人工智能历史的可以去读《人工智能简史》这本书。深度学习的历史可以总结为经历了3次发展浪潮。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>20世界40年代到60年代，</strong> 深度学习的雏形出现在控制论中。随着生物学习理论的发展和一个模型的实现，能实现单个神经元的训练。感知机是第一个能根据每个类别的输入样本来学习权重的模型，在同一时期，自适应线性单元简单地返回函数f(x)本身的值来预测一个实数，并且它还可以学习从数据预测这些数。基于感知机和自适应线性单元中使用的函数f(x,w)的模型称为线性模型。但是这种线性模型存在局限性，最著名的是无法解决异或问题。这也导致了神经网络热潮的第一次大衰退。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>20世纪80年代到90年代</strong>，深度学习表现为联结主义。联结主义在认知科学的背景下出现的。认知科学是理解思维的跨学科途径，即它融合多个不同的分析层次。20世纪80年代初期，大多数认知科学家研究符号推理模型。但符号模型很难解释大脑如何真正使用神经元实现推理功能。联结主义者开始研究真正基于神经系统实现的认知模型。<font color="red" size="3">联结主义的中心思想是，当网络将大量简单的计算单元连接在一起时可以实现智能行为。</font>其中一个概念是分布式表示，思想是：系统的每一个输入都应该由多个特征表示，并且每一个特征都应该参与到多个可能输入的表示。联结主义潮流的另一个重要成就是反向传播在训练具有内部表示的深度神经网络中的成功使用以及反向传播算法的普及。神经网络的第二次浪潮一直持续到20世纪90年代中期，由于基于神经网络的深度学习并不能满足应用的需要，而同时其他机器学习方法取得了进步。这两个因素导致了神经网络浪潮的第二次衰退。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>2006年至今，</strong> 人工智能的第三次浪潮在2006年，以深度学习之名复兴。起因是Geoffrey Hinton大神名为“深度信念网络”的神经网络可以使用一种“贪婪逐层预训练”的策略有效地训练。从此，深度学习的浪潮一直持续至今。第三次浪潮开始着眼于新的无监督学习技术和深度模型在小数据集的泛化能力。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目前，深度学习的发展已经为人类的生活带来了很多应用。如在人脸识别，目标检测，机器翻译，语言识别等。深度学习的发展伴随着三个方面的发展。**一是，数据量的增大。二是，模型的规模变大。三是，精度的提高以及对现实世界的影响。深度学习能发展的这么好，也是因为数据量的增大，深度学习的模型是基于数据的。从MNIST到ImageNet。数据越来越大。<font color="red" size="3">截止2016年，一个经验法则是，监督深度学习算法在每类给定约5000个标注样本情况下一般将达到可以接受的性能，当至少有1000万个标注样本的数据集用于训练时，它将到达或超过人类表现。</font>。随着数据的增加。深度学习模型的规模也在增加，体现在参数的增加。人工神经网络的规模大概每2.4年增加一倍。但是与人类的神经元还是差很多。这也意味着计算机的计算能力要增加。最后，随着数据和模型的进化，带来的是实际问题上精度的提高。可以将一些模型应用到实际的问题中，解决实际的生活问题。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;深度学习的发展解决了现实生活中的实际问题，为我们的生活带来了方便。也让我们看到了人工智能的曙光。未来的很长时间。深度学习都将是主要的研究方向。</p><blockquote><p>友情链接：<br>github主页：<a href="https://github.com/guoyuantao" target="_blank" rel="noopener">https://github.com/guoyuantao</a><br>CSDN博客：<a href="https://blog.csdn.net/gyt15663668337" target="_blank" rel="noopener">https://blog.csdn.net/gyt15663668337</a><br>个人博客主页：<a href="https://guoyuantao.github.io/">https://guoyuantao.github.io/</a><br>QQ讨论群：218803539</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----比较操作</title>
      <link href="/2019/07/14/pytorch-xue-xi-zhi-torch-bi-jiao-cao-zuo-comparison-ops/"/>
      <url>/2019/07/14/pytorch-xue-xi-zhi-torch-bi-jiao-cao-zuo-comparison-ops/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-eq-input-other-out-None"><a href="#1-torch-eq-input-other-out-None" class="headerlink" title="1. torch.eq(input, other, out=None)"></a>1. torch.eq(input, other, out=None)</h3><p><strong>说明：</strong> 比较元素是否相等，第二个参数可以是一个数，或者是第一个参数同类型形状的张量</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 待比较张量</li><li>other(Tenosr or float) —- 比较张量或者数</li><li>out(Tensor,可选的) —- 输出张量</li></ul><p><strong>返回值：</strong> 一个torch.ByteTensor张量，包含了每个位置的比较结果(相等为1，不等为0)</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="2-torch-equal-tensor1-tensor2-out-None"><a href="#2-torch-equal-tensor1-tensor2-out-None" class="headerlink" title="2. torch.equal(tensor1, tensor2, out=None)"></a>2. torch.equal(tensor1, tensor2, out=None)</h3><p><strong>说明：</strong> 如果两个张量有相同的形状和元素值，则返回true，否则False</p><p><strong>参数：</strong></p><ul><li>tensor1(Tenosr) —- 比较张量1</li><li>tensor2(Tensor) —- 比较张量2</li><li>out(Tensor,可选的) —- 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token boolean">True</span></code></pre><h3 id="3-torch-ge-input-other-out-None"><a href="#3-torch-ge-input-other-out-None" class="headerlink" title="3. torch.ge(input, other, out=None)"></a>3. torch.ge(input, other, out=None)</h3><p><strong>说明：</strong> 逐元素比较input和other，即是否input &gt;= other。</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 待对比的张量</li><li>other(Tensor or float) —- 对比的张量或float值</li><li>out(Tensor,可选的) —- 输出张量，</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>ge<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="4-torch-gt-input-other-out-None"><a href="#4-torch-gt-input-other-out-None" class="headerlink" title="4. torch.gt(input, other, out=None)"></a>4. torch.gt(input, other, out=None)</h3><p><strong>说明：</strong> 逐元素比较input和other，即是否input &gt; other</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 要对比的张量</li><li>other(Tensor or float) —- 要对比的张量或float值</li><li>out(Tensor,可选的) —- 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>gt<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="5-torch-kthvalue-input-k-dim-None-out-None"><a href="#5-torch-kthvalue-input-k-dim-None-out-None" class="headerlink" title="5. torch.kthvalue(input, k, dim=None, out=None)"></a>5. torch.kthvalue(input, k, dim=None, out=None)</h3><p><strong>说明：</strong> 取输入张量input指定维度上第k个最小值。如果不指定dim。默认为最后一维。返回一个元组(value, indices), 其中indices是原始输入张量中沿dim维的第k个最小值下标。</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 要对比的张量</li><li>k(int) —- 第k个最小值</li><li>dim(int, 可选的) —- 沿着此维度进行排序</li><li>out(tuple,可选的) —- 输出元组</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>kthvalue<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>kthvalue<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>kthvalue<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>kthvalue<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-le-input-other-out-None"><a href="#6-torch-le-input-other-out-None" class="headerlink" title="6. torch.le(input, other, out=None)"></a>6. torch.le(input, other, out=None)</h3><p><strong>说明：</strong> 逐元素比较input和other，即是否input &lt;= other.</p><p><strong>参数：</strong></p><ul><li>input(Tenosr) —- 要对比的张量</li><li>other(Tensor or float) —- 对比的张量或float值</li><li>out(Tensor,可选的) —- 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>le<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="7-torch-lt-input-other-out-None"><a href="#7-torch-lt-input-other-out-None" class="headerlink" title="7.   torch.lt(input, other, out=None)"></a>7.   torch.lt(input, other, out=None)</h3><p><strong>说明：</strong> 逐元素比较input和other，即是否input &lt; other</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 要对比的张量</li><li>other(Tensor or float) —- 对比的张量或float值</li><li>out(Tensor,可选的) —- 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>lt<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="8-torch-max-input"><a href="#8-torch-max-input" class="headerlink" title="8. torch.max(input)"></a>8. torch.max(input)</h3><p><strong>说明：</strong> 返回输入张量所有元素的最大值</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.1553</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4140</span><span class="token punctuation">,</span>  <span class="token number">1.8393</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">1.8393</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-max-input-dim-max-None-max-indices-None"><a href="#9-torch-max-input-dim-max-None-max-indices-None" class="headerlink" title="9. torch.max(input, dim, max=None, max_indices=None)"></a>9. torch.max(input, dim, max=None, max_indices=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度上每行的最大值，并同时返回每个最大值的位置索引。</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 指定的维度</li><li>max(Tensor,可选的) —- 结果张量，包含给定维度上的最大值</li><li>max_indices(LongTensor,可选的) —- 结果张量，包含给定维度上每个最大值的位置的索引。</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.4067</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7722</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6560</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9621</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8754</span><span class="token punctuation">,</span>  <span class="token number">0.0282</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7947</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1870</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.4300</span><span class="token punctuation">,</span>  <span class="token number">0.5444</span><span class="token punctuation">,</span>  <span class="token number">0.3180</span><span class="token punctuation">,</span>  <span class="token number">1.2647</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.0775</span><span class="token punctuation">,</span>  <span class="token number">0.5886</span><span class="token punctuation">,</span>  <span class="token number">0.1662</span><span class="token punctuation">,</span>  <span class="token number">0.8986</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>max<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.4067</span><span class="token punctuation">,</span> <span class="token number">0.0282</span><span class="token punctuation">,</span> <span class="token number">1.2647</span><span class="token punctuation">,</span> <span class="token number">0.8986</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-max-input-other-out-None"><a href="#10-torch-max-input-other-out-None" class="headerlink" title="10. torch.max(input, other, out=None)"></a>10. torch.max(input, other, out=None)</h3><p><strong>说明：</strong> 返回两个元素的最大值。</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 待比较张量</li><li>other(Tensor) —- 比较张量</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.5767</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0841</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0942</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9405</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6375</span><span class="token punctuation">,</span>  <span class="token number">1.4165</span><span class="token punctuation">,</span>  <span class="token number">0.2738</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8996</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.5767</span><span class="token punctuation">,</span>  <span class="token number">1.4165</span><span class="token punctuation">,</span>  <span class="token number">0.2738</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8996</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-min-input"><a href="#11-torch-min-input" class="headerlink" title="11.torch.min(input)"></a>11.torch.min(input)</h3><p><strong>说明：</strong> 返回输入张量所有元素的最小值</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8142</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9847</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3637</span><span class="token punctuation">,</span>  <span class="token number">0.5191</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>min<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.9847</span><span class="token punctuation">)</span></code></pre><h3 id="12-torch-min-input-dim-min-None-min-indices-None"><a href="#12-torch-min-input-dim-min-None-min-indices-None" class="headerlink" title="12. torch.min(input, dim, min=None, min_indices=None)"></a>12. torch.min(input, dim, min=None, min_indices=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度上每行的最小值，并同时返回每个最小值的位置索引</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 指定的维度</li><li>min(Tensor,可选的) —- 结果张量，包含给定维度上的最小值</li><li>min_indices(LongTensor,可选的) —- 结果张量，包含给定维度上每个最小值的位置索引。</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0243</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7382</span><span class="token punctuation">,</span>  <span class="token number">0.3102</span><span class="token punctuation">,</span>  <span class="token number">0.9720</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3805</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7999</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2856</span><span class="token punctuation">,</span>  <span class="token number">0.2657</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0284</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1638</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8840</span><span class="token punctuation">,</span>  <span class="token number">1.2679</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0347</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.3428</span><span class="token punctuation">,</span>  <span class="token number">0.3107</span><span class="token punctuation">,</span>  <span class="token number">1.0575</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>min<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>min<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7382</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2856</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0284</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.3428</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="13-torch-ne-input-other-out-None"><a href="#13-torch-ne-input-other-out-None" class="headerlink" title="13. torch.ne(input, other, out=None)"></a>13. torch.ne(input, other, out=None)</h3><p><strong>说明：</strong> 逐元素比较input和other，即是否input 不等于 other。第二个参数可以为一个数或与第一个参数相同形状和类型的张量</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 待对比的张量</li><li>other(Tensor or float) —- 对比的张量或float值</li><li>out(Tensor, 可选的) —- 输出张量</li></ul><p>** 返回值：** 一个torch.ByteTensor 张量，包含了每个位置的比较结果，如果tensor和other不相等为True，返回1.</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> torch<span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>ne<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="14-torch-sort-input-dim-None-descending-False-out-None"><a href="#14-torch-sort-input-dim-None-descending-False-out-None" class="headerlink" title="14. torch.sort(input, dim=None, descending=False, out=None)"></a>14. torch.sort(input, dim=None, descending=False, out=None)</h3><p><strong>说明：</strong> 对输入张量input沿指定维度按升序排序，如果不给定dim，则默认为输入的最后一维。如果指定参数descending为True，则按降序排序。</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 要排序的张量</li><li>dim(int,可选的) —- 沿着此维度排序</li><li>descending(bool,可选的) —- 布尔值，控制升序排序</li><li>out(tuple,可选的) —- 输出张量</li></ul><p><strong>返回值：</strong> 为ByteTensor类型或与tensor相同类型，为元组(sorted_tensor,sorted_indices)，sorted_indices为原始输入中的下标</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3613</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2583</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4276</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.3106</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.1577</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7505</span><span class="token punctuation">,</span>  <span class="token number">1.7217</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6247</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1338</span><span class="token punctuation">,</span>  <span class="token number">0.4423</span><span class="token punctuation">,</span>  <span class="token number">0.0280</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4796</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> sorted<span class="token punctuation">,</span> indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> sortedtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.3106</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4276</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3613</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2583</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.1577</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7505</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6247</span><span class="token punctuation">,</span>  <span class="token number">1.7217</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4796</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1338</span><span class="token punctuation">,</span>  <span class="token number">0.0280</span><span class="token punctuation">,</span>  <span class="token number">0.4423</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> indicestensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="15-torch-topk-input-dim-None-largest-True-sorted-True-out-None"><a href="#15-torch-topk-input-dim-None-largest-True-sorted-True-out-None" class="headerlink" title="15. torch.topk(input, dim=None, largest=True, sorted=True, out=None)"></a>15. torch.topk(input, dim=None, largest=True, sorted=True, out=None)</h3><p><strong>说明：</strong> 沿指定dim维度返回输入张量input中k个最大值。如果不指定dim，则默认input的最后一维，如果largest为False，则返回最小的k个值。</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>k(int) —- “top-k”中的k值</li><li>dim(int,可选的) —- 排序的维度</li><li>largest(bool,可选的) —- 布尔值，控制返回最大或最小值</li><li>sorted(bool,可选的) —- 布尔值，控制返回值是否排序</li><li>out(tuple,可选的) —- 可选输出张量</li></ul><p><strong>返回值：</strong> 返回一个元组(values, indices)，其中indices是原始输入张量input中排序元素下标。如果设定布尔值sorted为True，将会确保返回的k个值被排序</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> largest<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----Reduction Ops</title>
      <link href="/2019/07/14/pytorch-xue-xi-zhi-torch-reduction-ops/"/>
      <url>/2019/07/14/pytorch-xue-xi-zhi-torch-reduction-ops/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-cumprod-input-dim-out-None"><a href="#1-torch-cumprod-input-dim-out-None" class="headerlink" title="1. torch.cumprod(input, dim, out=None)"></a>1. torch.cumprod(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入沿指定维度的累积积。如果输入是一个N元向量，则结果也是一个N元向量，第i个输出元素值为 $$y_{i} = x_{1} * x_{2} * … * x_{i}$$</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 累积积操作的维度</li><li>out(Tensor,可选) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> torch<span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ret <span class="token operator">=</span> torch<span class="token punctuation">.</span>cumprod<span class="token punctuation">(</span>b<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> rettensor<span class="token punctuation">(</span><span class="token punctuation">[</span>  <span class="token number">1</span><span class="token punctuation">,</span>   <span class="token number">2</span><span class="token punctuation">,</span>   <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ret1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cumprod<span class="token punctuation">(</span>b<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ret1tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2-torch-cumsum-input-dim-out-None"><a href="#2-torch-cumsum-input-dim-out-None" class="headerlink" title="2. torch.cumsum(input, dim, out=None)"></a>2. torch.cumsum(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入沿指定维度的累积和。例如，如果输入是一个N元向量，则结果也是一个N元向量，第i个输出元素的值为$$y_{i} = x_{1} + x_{2} + … + x_{i}$$</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 累积和操作的维度</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ret <span class="token operator">=</span> torch<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>b<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> rettensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="3-torch-dist-input-other-p-2-out-None"><a href="#3-torch-dist-input-other-p-2-out-None" class="headerlink" title="3. torch.dist(input, other, p=2, out=None)"></a>3. torch.dist(input, other, p=2, out=None)</h3><p><strong>说明：</strong> 返回(input - other) 的p范数</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 左侧输入张量</li><li>other(Tensor) —- 右侧输入张量</li><li>p(float,可选的) —- 所计算的范数</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1559</span><span class="token punctuation">,</span> <span class="token number">0.7725</span><span class="token punctuation">,</span> <span class="token number">0.8706</span><span class="token punctuation">,</span> <span class="token number">0.3684</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ytensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.1464</span><span class="token punctuation">,</span>  <span class="token number">0.4444</span><span class="token punctuation">,</span>  <span class="token number">1.7968</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.3197</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>dist<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">2.1900</span><span class="token punctuation">)</span></code></pre><h3 id="4-torch-mean-input"><a href="#4-torch-mean-input" class="headerlink" title="4. torch.mean(input)"></a>4. torch.mean(input)</h3><p><strong>说明：</strong> 返回输入张量所有元素的均值</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.0543</span><span class="token punctuation">,</span>  <span class="token number">1.6074</span><span class="token punctuation">,</span>  <span class="token number">0.2915</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.0518</span><span class="token punctuation">)</span></code></pre><h3 id="5-torch-mean-input-dim-out-None"><a href="#5-torch-mean-input-dim-out-None" class="headerlink" title="5. torch.mean(input, dim, out=None)"></a>5. torch.mean(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度dim上每行的均值。</p><p><strong>参数：</strong></p><ul><li>inptu(Tensor) —- 输入张量</li><li>dim(int) —- 操作的维度</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.2351</span><span class="token punctuation">,</span>  <span class="token number">0.7531</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2863</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8551</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.2716</span><span class="token punctuation">,</span>  <span class="token number">1.0863</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.0343</span><span class="token punctuation">,</span>  <span class="token number">1.9529</span><span class="token punctuation">,</span>  <span class="token number">1.4611</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.9935</span><span class="token punctuation">,</span>  <span class="token number">0.5430</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1580</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.2340</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6801</span><span class="token punctuation">,</span>  <span class="token number">1.1494</span><span class="token punctuation">,</span>  <span class="token number">0.7928</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.6019</span><span class="token punctuation">,</span> <span class="token number">0.2444</span><span class="token punctuation">,</span> <span class="token number">0.2758</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-median-input-dim-1-values-None-indices-None"><a href="#6-torch-median-input-dim-1-values-None-indices-None" class="headerlink" title="6. torch.median(input, dim=-1, values=None, indices=None)"></a>6. torch.median(input, dim=-1, values=None, indices=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度每行中的中位数，同时返回一个包含中位数的索引的LongTensor。dim值默认为输入张量的最后一维。<br><strong>注意：</strong> 这个函数没有在torch.cuda.Tensor中定义</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 缩减的维度</li><li>values(Tensor,可选的) —- 结果张量</li><li>indices(Tensor,可选的) —- 返回的索引结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2479</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4734</span><span class="token punctuation">,</span>  <span class="token number">0.1368</span><span class="token punctuation">,</span>  <span class="token number">0.9601</span><span class="token punctuation">,</span>  <span class="token number">2.9435</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.3210</span><span class="token punctuation">,</span>  <span class="token number">0.8147</span><span class="token punctuation">,</span>  <span class="token number">0.3052</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6380</span><span class="token punctuation">,</span>  <span class="token number">0.0879</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.9500</span><span class="token punctuation">,</span>  <span class="token number">0.0926</span><span class="token punctuation">,</span>  <span class="token number">0.6948</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9723</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2437</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7056</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4905</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2469</span><span class="token punctuation">,</span>  <span class="token number">0.3753</span><span class="token punctuation">,</span>  <span class="token number">1.6451</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>median<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>median<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.1368</span><span class="token punctuation">,</span>  <span class="token number">0.3052</span><span class="token punctuation">,</span>  <span class="token number">0.0926</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2469</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-mode-input-dim-1-values-None-indices-None"><a href="#7-torch-mode-input-dim-1-values-None-indices-None" class="headerlink" title="7. torch.mode(input, dim=-1, values=None, indices=None)"></a>7. torch.mode(input, dim=-1, values=None, indices=None)</h3><p><strong>说明：</strong> 返回给定维dim上，每行的众数值，同时返回一个LongTensor，包含众数的索引。dim默认为输入张量的最后一维。<br><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 缩减的维度</li><li>values(Tensor,可选的) —- 结果的张量</li><li>indices(Tensor,可选的) —- 返回的索引张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.2427</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2035</span><span class="token punctuation">,</span>  <span class="token number">0.0828</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9490</span><span class="token punctuation">,</span>  <span class="token number">0.8610</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5330</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0207</span><span class="token punctuation">,</span>  <span class="token number">1.2805</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2771</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1151</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.2495</span><span class="token punctuation">,</span>  <span class="token number">0.6887</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1247</span><span class="token punctuation">,</span>  <span class="token number">1.3126</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4973</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.3097</span><span class="token punctuation">,</span>  <span class="token number">0.1821</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9910</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0591</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.0153</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0525</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0337</span><span class="token punctuation">,</span>  <span class="token number">1.2929</span><span class="token punctuation">,</span>  <span class="token number">1.4164</span><span class="token punctuation">,</span>  <span class="token number">1.3975</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>mode<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>mode<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.2427</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0207</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2495</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.0153</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0525</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-norm-input-p-2"><a href="#8-torch-norm-input-p-2" class="headerlink" title="8. torch.norm(input, p=2)"></a>8. torch.norm(input, p=2)</h3><p><strong>说明：</strong> 返回输入张量input的p范数</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li><li>p(float,可选的) —- 范数计算中的幂指数值</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.5397</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4304</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7689</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">1.9158</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-norm-input-p-dim-out-None"><a href="#9-torch-norm-input-p-dim-out-None" class="headerlink" title="9. torch.norm(input, p, dim, out=None)"></a>9. torch.norm(input, p, dim, out=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度dim上每行的p范数。<br><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>p(float) —- 范数计算中的幂指数值</li><li>dim(int) —- 缩减的维度</li><li>out(Tenosr,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3436</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6034</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2127</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0089</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.7678</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0787</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.9961</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2598</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.6944</span><span class="token punctuation">,</span> <span class="token number">0.2129</span><span class="token punctuation">,</span> <span class="token number">2.0709</span><span class="token punctuation">,</span> <span class="token number">1.0294</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-prod-input"><a href="#10-torch-prod-input" class="headerlink" title="10. torch.prod(input)"></a>10. torch.prod(input)</h3><p><strong>说明：</strong> 返回输入张量input所有元素的积</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-prod-input-dim-out-None"><a href="#11-torch-prod-input-dim-out-None" class="headerlink" title="11. torch.prod(input, dim, out=None)"></a>11. torch.prod(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度上每行的积。<br><strong>参数：</strong> </p><ul><li>input(Tenosr) —- 输入张量</li><li>dim(int) —- 缩减的维度</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0593</span><span class="token punctuation">,</span>  <span class="token number">0.3449</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0491</span><span class="token punctuation">,</span>  <span class="token number">0.2711</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.4155</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1968</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6646</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9474</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.0205</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0133</span><span class="token punctuation">,</span>  <span class="token number">0.4972</span><span class="token punctuation">,</span>  <span class="token number">0.6296</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0008</span><span class="token punctuation">,</span>  <span class="token number">0.1060</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="12-torch-std-input"><a href="#12-torch-std-input" class="headerlink" title="12. torch.std(input)"></a>12. torch.std(input)</h3><p><strong>说明：</strong> 返回输入张量input所有元素的标准差<br><strong>参数：</strong> </p><ul><li>inut(Tensor) —- 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2022</span><span class="token punctuation">,</span>  <span class="token number">1.9407</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1263</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>std<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">1.2159</span><span class="token punctuation">)</span></code></pre><h3 id="13-torch-std-input-dim-out-None"><a href="#13-torch-std-input-dim-out-None" class="headerlink" title="13. torch.std(input, dim, out=None)"></a>13. torch.std(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度上每行的标准差。<br><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) </li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.3646</span><span class="token punctuation">,</span>  <span class="token number">0.9681</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7199</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>std<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">0.8554</span><span class="token punctuation">)</span></code></pre><h3 id="14-torch-std-input-dim-out-None"><a href="#14-torch-std-input-dim-out-None" class="headerlink" title="14. torch.std(input, dim, out=None)"></a>14. torch.std(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入给定维度上每行的标准差。</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 缩减的维度</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.4083</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.0872</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.7175</span><span class="token punctuation">,</span>  <span class="token number">0.4151</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1804</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.9027</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6310</span><span class="token punctuation">,</span>  <span class="token number">0.3519</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1215</span><span class="token punctuation">,</span>  <span class="token number">0.5891</span><span class="token punctuation">,</span>  <span class="token number">0.1468</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2249</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.3558</span><span class="token punctuation">,</span>  <span class="token number">1.2970</span><span class="token punctuation">,</span>  <span class="token number">0.1988</span><span class="token punctuation">,</span>  <span class="token number">0.1279</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>std<span class="token punctuation">(</span>a<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.6449</span><span class="token punctuation">,</span> <span class="token number">0.9626</span><span class="token punctuation">,</span> <span class="token number">0.3633</span><span class="token punctuation">,</span> <span class="token number">0.6725</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="15-torch-sum-input"><a href="#15-torch-sum-input" class="headerlink" title="15. torch.sum(input)"></a>15. torch.sum(input)</h3><p><strong>说明：</strong> 返回输入张量input所有元素的和。</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.7710</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9921</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2817</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3.0449</span><span class="token punctuation">)</span></code></pre><h3 id="16-torch-sum-input-dim-out-None"><a href="#16-torch-sum-input-dim-out-None" class="headerlink" title="16. torch.sum(input, dim, out=None)"></a>16. torch.sum(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度上每行的和，</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 缩减的维度</li><li>out(Tensor, 可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6091</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5861</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2564</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3686</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7146</span><span class="token punctuation">,</span>  <span class="token number">0.7276</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7998</span><span class="token punctuation">,</span>  <span class="token number">0.5817</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.7700</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7373</span><span class="token punctuation">,</span>  <span class="token number">0.1708</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0295</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">2.2606</span><span class="token punctuation">,</span>  <span class="token number">1.9379</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7269</span><span class="token punctuation">,</span>  <span class="token number">0.7523</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.8202</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2051</span><span class="token punctuation">,</span>  <span class="token number">0.1741</span><span class="token punctuation">,</span>  <span class="token number">4.2239</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.7069</span><span class="token punctuation">,</span>  <span class="token number">1.3422</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.6123</span><span class="token punctuation">,</span>  <span class="token number">0.9359</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="17-torch-var-input"><a href="#17-torch-var-input" class="headerlink" title="17. torch.var(input)"></a>17. torch.var(input)</h3><p><strong>说明：</strong> 返回输入张量所有元素的方差</p><p><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7134</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1119</span><span class="token punctuation">,</span>  <span class="token number">1.0638</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0858</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>var<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">0.9016</span><span class="token punctuation">)</span></code></pre><h3 id="18-torch-var-input-dim-out-None"><a href="#18-torch-var-input-dim-out-None" class="headerlink" title="18. torch.var(input, dim, out=None)"></a>18. torch.var(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度上每行的方差</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 缩减维度</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0977</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2619</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3367</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5301</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.8751</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2703</span><span class="token punctuation">,</span>  <span class="token number">1.2129</span><span class="token punctuation">,</span>  <span class="token number">0.5508</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.1301</span><span class="token punctuation">,</span>  <span class="token number">0.6452</span><span class="token punctuation">,</span>  <span class="token number">0.5054</span><span class="token punctuation">,</span>  <span class="token number">0.3386</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.2502</span><span class="token punctuation">,</span>  <span class="token number">1.4547</span><span class="token punctuation">,</span>  <span class="token number">1.0562</span><span class="token punctuation">,</span>  <span class="token number">0.4640</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>var<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0322</span><span class="token punctuation">,</span> <span class="token number">0.4036</span><span class="token punctuation">,</span> <span class="token number">0.1161</span><span class="token punctuation">,</span> <span class="token number">0.3031</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----数学操作(三)</title>
      <link href="/2019/06/23/pytorch-xue-xi-zhi-torch-shu-xue-cao-zuo-san/"/>
      <url>/2019/06/23/pytorch-xue-xi-zhi-torch-shu-xue-cao-zuo-san/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-reciprocal-input-out-None"><a href="#1-torch-reciprocal-input-out-None" class="headerlink" title="1. torch.reciprocal(input, out=None)"></a>1. torch.reciprocal(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的倒数。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.6535</span><span class="token punctuation">,</span>  <span class="token number">1.3616</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.6167</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0142</span><span class="token punctuation">,</span>  <span class="token number">0.0186</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>reciprocal<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>  <span class="token number">1.5303</span><span class="token punctuation">,</span>   <span class="token number">0.7345</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">0.6186</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">70.6554</span><span class="token punctuation">,</span>  <span class="token number">53.8015</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2-torch-remainder-input-divisor-out-None"><a href="#2-torch-remainder-input-divisor-out-None" class="headerlink" title="2. torch.remainder(input, divisor, out=None)"></a>2. torch.remainder(input, divisor, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的除法余数。除数与被除数可能同时包含整数或浮点数，余数与除数有相同的符号<br><strong>参数：</strong></p><ul><li>input(Tensor) – 被除数</li><li>divisor(Tensor or float) – 除数，一个数或者与除数相同大小的张量</li><li>out(Tensor，可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>remainder<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="3-torch-round-input-out-None"><a href="#3-torch-round-input-out-None" class="headerlink" title="3. torch.round(input, out=None)"></a>3. torch.round(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，将输入input张量每个元素舍入到最近的整数<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>round<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="4-torch-rsqrt-input-out-None"><a href="#4-torch-rsqrt-input-out-None" class="headerlink" title="4. torch.rsqrt(input, out=None)"></a>4. torch.rsqrt(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的平方根倒数。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选0 – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.0934</span><span class="token punctuation">,</span>  <span class="token number">0.2079</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4841</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.2004</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>rsqrt<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.2716</span><span class="token punctuation">,</span> <span class="token number">2.1930</span><span class="token punctuation">,</span>    nan<span class="token punctuation">,</span>    nan<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="5-torch-sigmoid-input-out-None"><a href="#5-torch-sigmoid-input-out-None" class="headerlink" title="5. torch.sigmoid(input, out=None)"></a>5. torch.sigmoid(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的sigmoid值<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.6220</span><span class="token punctuation">,</span>  <span class="token number">0.4341</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5248</span><span class="token punctuation">,</span>  <span class="token number">0.8342</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.6507</span><span class="token punctuation">,</span> <span class="token number">0.6068</span><span class="token punctuation">,</span> <span class="token number">0.3717</span><span class="token punctuation">,</span> <span class="token number">0.6973</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-sign-input-out-None"><a href="#6-torch-sign-input-out-None" class="headerlink" title="6. torch.sign(input, out=None)"></a>6. torch.sign(input, out=None)</h3><p><strong>说明：</strong> 符号函数，返回一个新张量，包含输入input张量每个元素的正负<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.1224</span><span class="token punctuation">,</span>  <span class="token number">0.6647</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3843</span><span class="token punctuation">,</span>  <span class="token number">1.2878</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sign<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-sin-input-out-None"><a href="#7-torch-sin-input-out-None" class="headerlink" title="7. torch.sin(input, out=None)"></a>7. torch.sin(input, out=None)</h3><p><strong>说明：</strong>返回一个新张量，包含输入input张量每个元素的正弦。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8258</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8077</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5048</span><span class="token punctuation">,</span>  <span class="token number">0.9997</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-sinh-input-out-None"><a href="#8-torch-sinh-input-out-None" class="headerlink" title="8. torch.sinh(input, out=None)"></a>8. torch.sinh(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的双曲正弦<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.1792</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0052</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2577</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1537</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sinh<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.4722</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1833</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2605</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1543</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-sqrt-input-out-None"><a href="#9-torch-sqrt-input-out-None" class="headerlink" title="9. torch.sqrt(input, out=None)"></a>9. torch.sqrt(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的平方根<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.3252</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8610</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1563</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2361</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5703</span><span class="token punctuation">,</span>    nan<span class="token punctuation">,</span>    nan<span class="token punctuation">,</span>    nan<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-tan-input-out-None"><a href="#10-torch-tan-input-out-None" class="headerlink" title="10. torch.tan(input, out=None)"></a>10. torch.tan(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的正切。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.4005</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2229</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4596</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7481</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>tan<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.4233</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2267</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">8.9521</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9280</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-tanh-input-out-None"><a href="#11-torch-tanh-input-out-None" class="headerlink" title="11. torch.tanh(input, out=None)"></a>11. torch.tanh(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的双曲正切<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2677</span><span class="token punctuation">,</span>  <span class="token number">0.7824</span><span class="token punctuation">,</span>  <span class="token number">0.0271</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0853</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="12-torch-trunc-input-out-None"><a href="#12-torch-trunc-input-out-None" class="headerlink" title="12. torch.trunc(input, out=None)"></a>12. torch.trunc(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入张量每个元素的截断值（标量x的截断值是最接近其的整数）<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1385</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7681</span><span class="token punctuation">,</span>  <span class="token number">0.4294</span><span class="token punctuation">,</span>  <span class="token number">0.4270</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>trunc<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----数学操作(二)</title>
      <link href="/2019/06/23/pytorch-xue-xi-zhi-torch-shu-xue-cao-zuo-er/"/>
      <url>/2019/06/23/pytorch-xue-xi-zhi-torch-shu-xue-cao-zuo-er/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-floor-input-out-None"><a href="#1-torch-floor-input-out-None" class="headerlink" title="1. torch.floor(input, out=None)"></a>1. torch.floor(input, out=None)</h3><p><strong>说明：</strong> 床函数，返回一个新张量，包含输入input张量每个元素的floor，即不小于元素的最大整数。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tenosr, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2-torch-fmod-input-divisor-out-None"><a href="#2-torch-fmod-input-divisor-out-None" class="headerlink" title="2. torch.fmod(input, divisor, out=None)"></a>2. torch.fmod(input, divisor, out=None)</h3><p><strong>说明：</strong> 计算除法余数。除数与被除数可能同时含有整数和浮点数。此时，余数的正负与被除数相同<br><strong>参数：</strong></p><ul><li>input(Tensor) – 被除数</li><li>divisor(Tensor或float) –  除数，一个数或与被除数相同类型的张量</li><li>out(Tensor，可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>fmod<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>fmod<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token number">0.5000</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token number">0.5000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="3-torch-frac-tensor-out-None"><a href="#3-torch-frac-tensor-out-None" class="headerlink" title="3. torch.frac(tensor, out=None)"></a>3. torch.frac(tensor, out=None)</h3><p><strong>说明：</strong> 返回每个元素的分数部分<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 输入张量，可以是小数也可是整数</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>frac<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2.3</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.0000</span><span class="token punctuation">,</span>  <span class="token number">0.3000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="4-torch-lerp-start-end-weight-out-None"><a href="#4-torch-lerp-start-end-weight-out-None" class="headerlink" title="4. torch.lerp(start, end, weight, out=None)"></a>4. torch.lerp(start, end, weight, out=None)</h3><p><strong>说明：</strong> 对两个张量以start，end做线性插值，将结果返回到输出张量。即out = start + weight * (end - start).<br><strong>参数：</strong></p><ul><li>start(Tensor) – 起始点张量</li><li>end(Tensor) – 终止点张量</li><li>weight(float) – 插值公式的weight</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> start <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> end <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> starttensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> endtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>lerp<span class="token punctuation">(</span>start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5.5000</span><span class="token punctuation">,</span> <span class="token number">6.0000</span><span class="token punctuation">,</span> <span class="token number">6.5000</span><span class="token punctuation">,</span> <span class="token number">7.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="5-torch-log-input-out-None"><a href="#5-torch-log-input-out-None" class="headerlink" title="5. torch.log(input, out=None)"></a>5. torch.log(input, out=None)</h3><p><strong>说明：</strong> 计算input的自然对数<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.1601</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8747</span><span class="token punctuation">,</span>  <span class="token number">0.2048</span><span class="token punctuation">,</span>  <span class="token number">1.8377</span><span class="token punctuation">,</span>  <span class="token number">0.2801</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>    nan<span class="token punctuation">,</span>     nan<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.5856</span><span class="token punctuation">,</span>  <span class="token number">0.6085</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2725</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-log1p-input-out-None"><a href="#6-torch-log1p-input-out-None" class="headerlink" title="6. torch.log1p(input, out=None)"></a>6. torch.log1p(input, out=None)</h3><p><strong>说明：</strong> 计算input+1的自然对数，对值比较小的输入，此函数比torch.log()更准确<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.4177</span><span class="token punctuation">,</span>  <span class="token number">0.7744</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.8840</span><span class="token punctuation">,</span>  <span class="token number">0.3302</span><span class="token punctuation">,</span>  <span class="token number">1.7383</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1667</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>log1p<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.3490</span><span class="token punctuation">,</span>  <span class="token number">0.5735</span><span class="token punctuation">,</span>     nan<span class="token punctuation">,</span>  <span class="token number">0.2854</span><span class="token punctuation">,</span>  <span class="token number">1.0073</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1824</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-mul-input-value-out-None"><a href="#7-torch-mul-input-value-out-None" class="headerlink" title="7. torch.mul(input, value, out=None)"></a>7. torch.mul(input, value, out=None)</h3><p><strong>说明：</strong> 用标量值value乘以输入input的每个元素，并返回一个新的结果张量。out = tensor * value<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>value(Number) – 乘到每个元素的数</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.7720</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8593</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0354</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0747</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">177.2037</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">85.9287</span><span class="token punctuation">,</span>   <span class="token operator">-</span><span class="token number">3.5436</span><span class="token punctuation">,</span>   <span class="token operator">-</span><span class="token number">7.4714</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-mul-input-other-out-None"><a href="#8-torch-mul-input-other-out-None" class="headerlink" title="8. torch.mul(input, other, out=None)"></a>8. torch.mul(input, other, out=None)</h3><p><strong>说明：</strong> 两个张量input，other按元素进行相乘，并返回输出张量<br><strong>参数：</strong></p><ul><li>input(Tensor) – 第一个相乘张量</li><li>other(Tensor) – 第二个相乘张量</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.1404</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3859</span><span class="token punctuation">,</span>  <span class="token number">1.9077</span><span class="token punctuation">,</span>  <span class="token number">0.7873</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.5376</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7447</span><span class="token punctuation">,</span>  <span class="token number">1.6224</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3152</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0610</span><span class="token punctuation">,</span>  <span class="token number">0.2805</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0194</span><span class="token punctuation">,</span>  <span class="token number">0.4091</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0842</span><span class="token punctuation">,</span>  <span class="token number">0.1382</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1696</span><span class="token punctuation">,</span>  <span class="token number">0.0576</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-neg-input-out-None"><a href="#9-torch-neg-input-out-None" class="headerlink" title="9. torch.neg(input, out=None)"></a>9. torch.neg(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量按元素取负。out = -1 * input<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.8791</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5795</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1354</span><span class="token punctuation">,</span>  <span class="token number">0.4425</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1631</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>neg<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8791</span><span class="token punctuation">,</span>  <span class="token number">0.5795</span><span class="token punctuation">,</span>  <span class="token number">1.1354</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4425</span><span class="token punctuation">,</span>  <span class="token number">0.1631</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-pow-input-exponent-out-None"><a href="#10-torch-pow-input-exponent-out-None" class="headerlink" title="10. torch.pow(input, exponent, out=None)"></a>10. torch.pow(input, exponent, out=None)</h3><p><strong>说明：</strong> 对输入input按元素求exponent次幂值，并返回结果张量，幂值exponent可以为标量也可以是和input相同大小的张量。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>exponent(float or Tensor) – 幂值</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2202</span><span class="token punctuation">,</span>  <span class="token number">0.0814</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0079</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7530</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4.8492e-02</span><span class="token punctuation">,</span> <span class="token number">6.6341e-03</span><span class="token punctuation">,</span> <span class="token number">6.1897e-05</span><span class="token punctuation">,</span> <span class="token number">5.6697e-01</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-pow-base-input-out-None"><a href="#11-torch-pow-base-input-out-None" class="headerlink" title="11. torch.pow(base, input, out=None)"></a>11. torch.pow(base, input, out=None)</h3><p><strong>说明：</strong> base为标量浮点值，input为张量，返回的输出张量out与输出张量相同形状。执行操作<br><strong>参数：</strong></p><ul><li>base(float) – 标量值，指数的底</li><li>input(Tensor) – 幂值</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> exp <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> base <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>base<span class="token punctuation">,</span> exp<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----数学操作(一)</title>
      <link href="/2019/06/23/pytorch-xue-xi-zhi-torch-shu-xue-cao-zuo-yi/"/>
      <url>/2019/06/23/pytorch-xue-xi-zhi-torch-shu-xue-cao-zuo-yi/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-abs-input-out-None"><a href="#1-torch-abs-input-out-None" class="headerlink" title="1. torch.abs(input, out=None)"></a>1. torch.abs(input, out=None)</h3><p><strong>说明：</strong> 计算输入张量的每个元素绝对值<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(可选) – 输出</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> torch<span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2-torch-acos-input-out-None"><a href="#2-torch-acos-input-out-None" class="headerlink" title="2. torch.acos(input, out=None)"></a>2. torch.acos(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入张量每个元素的反余弦。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">2.5609</span><span class="token punctuation">,</span>  <span class="token number">0.1132</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5844</span><span class="token punctuation">,</span>  <span class="token number">0.0257</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>acos<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>   nan<span class="token punctuation">,</span> <span class="token number">1.4573</span><span class="token punctuation">,</span> <span class="token number">2.1950</span><span class="token punctuation">,</span> <span class="token number">1.5451</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="3-torch-add-input-value-out-None"><a href="#3-torch-add-input-value-out-None" class="headerlink" title="3. torch.add(input, value, out=None)"></a>3. torch.add(input, value, out=None)</h3><p><strong>说明：</strong> 对输入张量input逐元素加上标量值value，并返回到一个新的张量out。即out = tensor + value。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>value(Number) – 添加到输入每个元素的数</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.6450</span><span class="token punctuation">,</span>  <span class="token number">0.8491</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2552</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1404</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">20.6450</span><span class="token punctuation">,</span> <span class="token number">20.8491</span><span class="token punctuation">,</span> <span class="token number">19.7448</span><span class="token punctuation">,</span> <span class="token number">19.8596</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">9.8</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10.4450</span><span class="token punctuation">,</span> <span class="token number">10.6491</span><span class="token punctuation">,</span>  <span class="token number">9.5448</span><span class="token punctuation">,</span>  <span class="token number">9.6596</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="4-torch-add-input-value-other-out-None"><a href="#4-torch-add-input-value-other-out-None" class="headerlink" title="4. torch.add(input, value, other, out=None)"></a>4. torch.add(input, value, other, out=None)</h3><p><strong>说明：</strong> other张量的每个元素乘以以标量值value，并加到input张量上，返回结果到输出张量out。即out = input + (other * value)。形状需要匹配。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 第一个输入张量</li><li>value(Number) – 用于第二个张量的尺寸因子</li><li>other(Tensor) – 第二个输入张量</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0692</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1224</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.6475</span><span class="token punctuation">,</span>  <span class="token number">2.0617</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5094</span><span class="token punctuation">,</span>  <span class="token number">0.4380</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3469</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8634</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5.1634</span><span class="token punctuation">,</span>  <span class="token number">3.2573</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">5.1164</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">6.5726</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="5-torch-addcdiv-tensor-value-1-tensor1-tensor2-out-None"><a href="#5-torch-addcdiv-tensor-value-1-tensor1-tensor2-out-None" class="headerlink" title="5. torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None)"></a>5. torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None)</h3><p><strong>说明：</strong> 用tensor2对tensor1逐元素相除，然后乘以标量值value，并加到tensor。张量的形状需要匹配。我实验过形状不匹配时，会报错。<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 张量，对tensor1./tensor2进行相加</li><li>value(number) – 标量，对tensor1./tensor2进行相除</li><li>tensor1(Tensor) – 张量，作为被除数(分子)</li><li>tensor2(Tensor) – 张量，作为除数(分母)</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> t <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> t2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>addcdiv<span class="token punctuation">(</span>t<span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.8583</span><span class="token punctuation">,</span>  <span class="token number">2.1763</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5981</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2156</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3442</span><span class="token punctuation">,</span>  <span class="token number">1.3631</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-addcmul-tensor-value-1-tensor1-tensor2-out-None"><a href="#6-torch-addcmul-tensor-value-1-tensor1-tensor2-out-None" class="headerlink" title="6. torch.addcmul(tensor, value=1, tensor1, tensor2, out=None)"></a>6. torch.addcmul(tensor, value=1, tensor1, tensor2, out=None)</h3><p><strong>说明：</strong> 用tensor2对tensor1逐元素相乘，并对结果乘以标量值value然后加到tensor。张量的形状需要匹配的。<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 张量，对tensor1*tensor2进行相加</li><li>value(Number) – 标量，对tensor1，tensor2进行相乘</li><li>tensor1(Tensor) – 张量，作为乘子1</li><li>tensor2(Tensor) – 张量，作为乘子2</li><li>out(Tensor， 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> t <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> t2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>addcmul<span class="token punctuation">(</span>t<span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0198</span><span class="token punctuation">,</span>  <span class="token number">1.0696</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2039</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8555</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9452</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2066</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-asin-input-out-None"><a href="#7-torch-asin-input-out-None" class="headerlink" title="7. torch.asin(input, out=None)"></a>7. torch.asin(input, out=None)</h3><p><strong>说明：</strong> 返回一个张量，包含输入input张量每个元素的反正弦函数<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 输入张量</li><li>out(Tensor，可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.0829</span><span class="token punctuation">,</span>  <span class="token number">0.3976</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7801</span><span class="token punctuation">,</span>  <span class="token number">1.1426</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>asin<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>    nan<span class="token punctuation">,</span>  <span class="token number">0.4089</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8948</span><span class="token punctuation">,</span>     nan<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-atan-input-out-None"><a href="#8-torch-atan-input-out-None" class="headerlink" title="8. torch.atan(input, out=None)"></a>8. torch.atan(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的反正切函数。<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 输入张量</li><li>out(Tensor, optional) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>atan<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.4967</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6854</span><span class="token punctuation">,</span>  <span class="token number">0.8361</span><span class="token punctuation">,</span>  <span class="token number">1.0014</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-atan2-input1-input2-out-None"><a href="#9-torch-atan2-input1-input2-out-None" class="headerlink" title="9. torch.atan2(input1, input2, out=None)"></a>9. torch.atan2(input1, input2, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含两个输入张量input1和input2的反正切函数<br><strong>参数：</strong></p><ul><li>input1(Tensor) – 第一个输入张量</li><li>input2(Tensor) – 第二个输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>atan2<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.8779</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.7628</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.9384</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4760</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-ceil-input-out-None"><a href="#10-torch-ceil-input-out-None" class="headerlink" title="10. torch.ceil(input, out=None)"></a>10. torch.ceil(input, out=None)</h3><p><strong>说明：</strong> 天井函数，对输入input张量每个元素向上取整，即取不小于每个元素的最小整数。并返回结果到输出<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7592</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8455</span><span class="token punctuation">,</span>  <span class="token number">1.2844</span><span class="token punctuation">,</span>  <span class="token number">1.4402</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-clamp-input-min-max-out-None"><a href="#11-torch-clamp-input-min-max-out-None" class="headerlink" title="11. torch.clamp(input, min, max, out=None)"></a>11. torch.clamp(input, min, max, out=None)</h3><p><strong>说明：</strong> 将输入input张量每个元素的夹紧到区间[min,max]，并返回结果到一个新张量。对小于min的值，令其等于min，大于max的值等于max。其他值仍等于原值。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>min(Numberi) – 限制范围下限</li><li>max(Number) – 限制范围上限</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.8579</span><span class="token punctuation">,</span>  <span class="token number">0.4232</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1166</span><span class="token punctuation">,</span>  <span class="token number">1.1509</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>a<span class="token punctuation">,</span> min<span class="token operator">=</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> max<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5000</span><span class="token punctuation">,</span>  <span class="token number">0.4232</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1166</span><span class="token punctuation">,</span>  <span class="token number">0.5000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="12-torch-clamp-input-min-out-None"><a href="#12-torch-clamp-input-min-out-None" class="headerlink" title="12. torch.clamp(input, *, min, out=None)"></a>12. torch.clamp(input, *, min, out=None)</h3><p><strong>说明：</strong> 将输入input张量每个元素的限制都不小于min，并返回结果到一个新张量。如果输入是FloatTensor或DoubleTensor类型，则参数min必须为实数，否则须为整数。经过实验得知。无论输入类型，皆可。<br><strong>参数：</strong></p><ul><li>input(Tenosr) – 输入张量</li><li>min(Number) – 限制范围下限</li><li>out(Tenosr,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.6551</span><span class="token punctuation">,</span>  <span class="token number">0.6760</span><span class="token punctuation">,</span>  <span class="token number">2.2335</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7242</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0403</span><span class="token punctuation">,</span>  <span class="token number">0.7974</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>a<span class="token punctuation">,</span> min<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.6551</span><span class="token punctuation">,</span> <span class="token number">0.6760</span><span class="token punctuation">,</span> <span class="token number">2.2335</span><span class="token punctuation">,</span> <span class="token number">0.5000</span><span class="token punctuation">,</span> <span class="token number">0.5000</span><span class="token punctuation">,</span> <span class="token number">0.7974</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="13-torch-clamp-input-max-out-None"><a href="#13-torch-clamp-input-max-out-None" class="headerlink" title="13. torch.clamp(input, *, max, out=None)"></a>13. torch.clamp(input, *, max, out=None)</h3><p><strong>说明：</strong> 将输入input张量每个元素的限制到不大于max，并返回结果到一个新张量。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>max(Number) – 限制范围上限</li><li>out(Tenosr, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.9049</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.5959</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2436</span><span class="token punctuation">,</span>  <span class="token number">0.2380</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5851</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>a<span class="token punctuation">,</span> max<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.9049</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.5959</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2436</span><span class="token punctuation">,</span>  <span class="token number">0.2380</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5851</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="14-torch-cos-input-out-None"><a href="#14-torch-cos-input-out-None" class="headerlink" title="14. torch.cos(input, out=None)"></a>14. torch.cos(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的余弦。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tenosr,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5251</span><span class="token punctuation">,</span>  <span class="token number">1.2806</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0669</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2035</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.8653</span><span class="token punctuation">,</span> <span class="token number">0.2861</span><span class="token punctuation">,</span> <span class="token number">0.9978</span><span class="token punctuation">,</span> <span class="token number">0.9794</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="15-torch-cosh-input-out-None"><a href="#15-torch-cosh-input-out-None" class="headerlink" title="15. torch.cosh(input, out=None)"></a>15. torch.cosh(input, out=None)</h3><p><strong>说明：</strong>返回一个新张量，包含输入input张量每个元素的双曲余弦<br><strong>参数：</strong></p><ul><li>input(Tenosr) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.6999</span><span class="token punctuation">,</span>  <span class="token number">0.4897</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0476</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4528</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>cosh<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.2551</span><span class="token punctuation">,</span> <span class="token number">1.1223</span><span class="token punctuation">,</span> <span class="token number">1.6008</span><span class="token punctuation">,</span> <span class="token number">1.1043</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="16-torch-div-input-value-out-None"><a href="#16-torch-div-input-value-out-None" class="headerlink" title="16. torch.div(input, value, out=None)"></a>16. torch.div(input, value, out=None)</h3><p><strong>说明：</strong> 将input逐元素除以标量值value，并返回结果到输出张量out。<br><strong>参数：</strong></p><ul><li>input(Tenosr) – 输入张量</li><li>value(Number) – 除数</li><li>out(Tenosr,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.1755</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7143</span><span class="token punctuation">,</span>  <span class="token number">2.1232</span><span class="token punctuation">,</span>  <span class="token number">0.4559</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.3207</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>div<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">2.3510</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4286</span><span class="token punctuation">,</span>  <span class="token number">4.2465</span><span class="token punctuation">,</span>  <span class="token number">0.9119</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.6414</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="17-torch-div-input-other-out-None"><a href="#17-torch-div-input-other-out-None" class="headerlink" title="17. torch.div(input, other, out=None)"></a>17. torch.div(input, other, out=None)</h3><p><strong>说明：</strong> 两张量input和other逐元素相除，并将结果返回到输出。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 张量(分子)</li><li>other(Tensor) – 张量(分母)</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.6808</span><span class="token punctuation">,</span>  <span class="token number">1.1017</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1122</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.9604</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1047</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9544</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2481</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9300</span><span class="token punctuation">,</span>  <span class="token number">0.5857</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4382</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4094</span><span class="token punctuation">,</span>  <span class="token number">0.6650</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2651</span><span class="token punctuation">,</span>  <span class="token number">0.5529</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7386</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0719</span><span class="token punctuation">,</span>  <span class="token number">1.3542</span><span class="token punctuation">,</span>  <span class="token number">2.0680</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>div<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.4734</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.6912</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.6723</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3.6223</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1894</span><span class="token punctuation">,</span>  <span class="token number">1.2921</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">3.4513</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6867</span><span class="token punctuation">,</span>  <span class="token number">0.2832</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="18-torch-exp-tensor-out-None"><a href="#18-torch-exp-tensor-out-None" class="headerlink" title="18. torch.exp(tensor, out=None)"></a>18. torch.exp(tensor, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的指数。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.3263</span><span class="token punctuation">,</span> <span class="token number">2.6751</span><span class="token punctuation">,</span> <span class="token number">1.1791</span><span class="token punctuation">,</span> <span class="token number">0.4109</span><span class="token punctuation">,</span> <span class="token number">0.2701</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----随机抽样、序列化、并行化</title>
      <link href="/2019/06/23/pytorch-xue-xi-zhi-torch-sui-ji-chou-yang-xu-lie-hua-bing-xing-hua/"/>
      <url>/2019/06/23/pytorch-xue-xi-zhi-torch-sui-ji-chou-yang-xu-lie-hua-bing-xing-hua/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-manual-seed-seed"><a href="#1-torch-manual-seed-seed" class="headerlink" title="1. torch.manual_seed(seed)"></a>1. torch.manual_seed(seed)</h3><p><strong>说明：</strong> 设置生成随机数的种子，返回一个torch._C.Generator对象。使用随机数种子之后，生成的随机数是相同的。<br><strong>参数：</strong></p><ul><li>seed(int or long) – 种子</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> torch<span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">&lt;</span>torch<span class="token punctuation">.</span>_C<span class="token punctuation">.</span>Generator object at <span class="token number">0x0000019684586350</span><span class="token operator">></span><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7576</span><span class="token punctuation">,</span> <span class="token number">0.2793</span><span class="token punctuation">,</span> <span class="token number">0.4031</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.7347</span><span class="token punctuation">,</span> <span class="token number">0.0293</span><span class="token punctuation">,</span> <span class="token number">0.7999</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">&lt;</span>torch<span class="token punctuation">.</span>_C<span class="token punctuation">.</span>Generator object at <span class="token number">0x0000019684586350</span><span class="token operator">></span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7576</span><span class="token punctuation">,</span> <span class="token number">0.2793</span><span class="token punctuation">,</span> <span class="token number">0.4031</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.7347</span><span class="token punctuation">,</span> <span class="token number">0.0293</span><span class="token punctuation">,</span> <span class="token number">0.7999</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">==</span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="2-torch-initial-seed"><a href="#2-torch-initial-seed" class="headerlink" title="2. torch.initial_seed()"></a>2. torch.initial_seed()</h3><p><strong>说明：</strong>返回生成随机数的原始种子值</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">&lt;</span>torch<span class="token punctuation">.</span>_C<span class="token punctuation">.</span>Generator object at <span class="token number">0x0000019684586350</span><span class="token operator">></span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>initial_seed<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token number">4</span></code></pre><h3 id="3-torch-get-rng-state"><a href="#3-torch-get-rng-state" class="headerlink" title="3. torch.get_rng_state()"></a>3. torch.get_rng_state()</h3><p><strong>说明：</strong> 返回随机生成器状态(ByteTensor)</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>initial_seed<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token number">4</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>get_rng_state<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="4-torch-set-rng-state"><a href="#4-torch-set-rng-state" class="headerlink" title="4. torch.set_rng_state()"></a>4. torch.set_rng_state()</h3><p><strong>说明：</strong> 设定随机生成器状态<br><strong>参数：</strong></p><ul><li>new_state(ByteTensor) – 期望的状态</li></ul><h3 id="5-torch-default-generator"><a href="#5-torch-default-generator" class="headerlink" title="5. torch.default_generator"></a>5. torch.default_generator</h3><p><strong>说明：</strong>默认的随机生成器。等于&lt;torch._C.Generator object&gt;</p><h3 id="6-torch-bernoulli-input-out-None"><a href="#6-torch-bernoulli-input-out-None" class="headerlink" title="6. torch.bernoulli(input, out=None)"></a>6. torch.bernoulli(input, out=None)</h3><p><strong>说明：</strong>从伯努利分布中抽取二元随机数(0或1)。输入张量包含用于抽取二元值的概率。因此，输入中的所有值都必须在[0,1]区间内。输出张量的第i个元素值，将会以输入张量的第i个概率值等于1。返回值将会是与输入相同大小的张量，每个值为0或者1.<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入为伯努利分布的概率值</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>uniform_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5596</span><span class="token punctuation">,</span> <span class="token number">0.5591</span><span class="token punctuation">,</span> <span class="token number">0.0915</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.2100</span><span class="token punctuation">,</span> <span class="token number">0.0072</span><span class="token punctuation">,</span> <span class="token number">0.0390</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.9929</span><span class="token punctuation">,</span> <span class="token number">0.9131</span><span class="token punctuation">,</span> <span class="token number">0.6186</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-multinomial-input-num-samples-replacement-False-out-None"><a href="#7-torch-multinomial-input-num-samples-replacement-False-out-None" class="headerlink" title="7. torch.multinomial(input, num_samples, replacement=False, out=None)"></a>7. torch.multinomial(input, num_samples, replacement=False, out=None)</h3><p><strong>说明：</strong> 返回一个张量，每行包含从input相应行中定义的多项分布中抽取的num_samples个样本。要求输入input每行的值不需要总和为1，但是必须非负且总和不能为0。当抽取样本时，依次从左到右排列(第一个样本对应第一列)。如果输入input是一个向量，输出out也是一个相同长度num_samples的向量。如果输入input是m行的矩阵，输出out是形如m x n的矩阵。并且如果参数replacement为True，则样本抽取可以重复。否则，一个样本在每行不能被重复。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 包含概率的张量</li><li>num_samples(int) – 抽取的样本数</li><li>replacement(bool) – 布尔值，决定是否能重复抽取</li><li>out(Tensor) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> weights <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> weightstensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>weights<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> replacement<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-normal-means-std-out-None"><a href="#8-torch-normal-means-std-out-None" class="headerlink" title="8. torch.normal(means, std, out=None)"></a>8. torch.normal(means, std, out=None)</h3><p><strong>说明：</strong>返回一个张量，包含从给定参数means，std的离散正态分布中抽取随机数。均值means是一个张量，包含每个输出元素相关的正态分布的均值。std是一个张量。包含每个输出元素相关的正态分布的标准差。均值和标准差的形状不须匹配，但每个张量的元素个数必须想听。<br><strong>参数：</strong></p><ul><li>means(Tensor) – 均值</li><li>std(Tensor) – 标准差</li><li>out(Tensor) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> n_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> n_datatensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> x0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> n_data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> x0tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.6544</span><span class="token punctuation">,</span> <span class="token number">0.9805</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2.1114</span><span class="token punctuation">,</span> <span class="token number">2.7113</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1.0646</span><span class="token punctuation">,</span> <span class="token number">1.9675</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2.7652</span><span class="token punctuation">,</span> <span class="token number">3.2138</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1.1204</span><span class="token punctuation">,</span> <span class="token number">2.0293</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-save-obj-f-pickle-module-lt-module-‘pickle’-from-‘-home-lzjs-…"><a href="#9-torch-save-obj-f-pickle-module-lt-module-‘pickle’-from-‘-home-lzjs-…" class="headerlink" title="9. torch.save(obj, f, pickle_module=&lt;module ‘pickle’ from ‘/home/lzjs/…)"></a>9. torch.save(obj, f, pickle_module=&lt;module ‘pickle’ from ‘/home/lzjs/…)</h3><p><strong>说明：</strong> 保存一个对象到一个硬盘文件上。<br><strong>参数：</strong></p><ul><li>obj – 保存对象</li><li>f – 类文件对象或一个保存文件名的字符串</li><li>pickle_module – 用于pickling源数据和对象的模块</li><li>pickle_protocol – 指定pickle protocal可以覆盖默认参数</li></ul><h3 id="10-torch-load-f-map-location-None-pickle-module-lt-module-‘pickle’-from-‘-home-lzjs-…"><a href="#10-torch-load-f-map-location-None-pickle-module-lt-module-‘pickle’-from-‘-home-lzjs-…" class="headerlink" title="10. torch.load(f, map_location=None, pickle_module=&lt;module ‘pickle’ from ‘/home/lzjs/…)"></a>10. torch.load(f, map_location=None, pickle_module=&lt;module ‘pickle’ from ‘/home/lzjs/…)</h3><p><strong>说明：</strong> 从磁盘文件中读取一个通过torch.save()保存的对象。torch.load()可通过参数map_location动态地进行内存重映射，使其能从不动设备中读取文件。一般调用时，需两个参数：storage和location tag。返回不同地址中的storage，或者返回None。如果这个参数是字典的话，意味着从文件的地址标记到当前系统的地址标记的映射。<br><strong>参数：</strong></p><ul><li>f – l类文件对象或一个保存文件名的字符串</li><li>map_location – 一个函数或字典规定如何remap存储位置</li><li>pickle_module – 用于unpickling元数据和对象的模块</li></ul><pre class=" language-python"><code class="language-python">torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'tensors.pt'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 加载所有的张量到CPU</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'tensor.pt'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token keyword">lambda</span> storage<span class="token punctuation">,</span> loc<span class="token punctuation">:</span>storage<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 加载张量到GPU</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'tensors.pt'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'cuda:1'</span><span class="token punctuation">:</span><span class="token string">'cuda:0'</span><span class="token punctuation">}</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-get-num-threads"><a href="#11-torch-get-num-threads" class="headerlink" title="11. torch.get_num_threads()"></a>11. torch.get_num_threads()</h3><p><strong>说明：</strong> 获得用于并行化CPU操作的OpenMP线程数</p><h3 id="12-torch-set-num-threads"><a href="#12-torch-set-num-threads" class="headerlink" title="12. torch.set_num_threads()"></a>12. torch.set_num_threads()</h3><p><strong>说明：</strong> 设定用于并行化CPU操作的OpenMP线程数</p>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----索引、切片、连接、变异操作</title>
      <link href="/2019/06/22/pytorch-xue-xi-zhi-torch-suo-yin-qie-pian-lian-jie-bian-yi-cao-zuo/"/>
      <url>/2019/06/22/pytorch-xue-xi-zhi-torch-suo-yin-qie-pian-lian-jie-bian-yi-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-cat-seq-dim-0-out-None"><a href="#1-torch-cat-seq-dim-0-out-None" class="headerlink" title="1. torch.cat(seq, dim=0, out=None)"></a>1. torch.cat(seq, dim=0, out=None)</h3><p><strong>说明：</strong> 在给定维度上对输入的张量序列seq进行连接操作<br><strong>参数：</strong></p><ul><li>seq(Tensor的序列) – 可以是相同类型的Tensor的任何Python序列</li><li>dim(int, 可选) – 张量连接的维度，按dim维度连接张量</li><li>out(Tensor,可选) – 输出参数</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.2132</span><span class="token punctuation">,</span>  <span class="token number">0.5984</span><span class="token punctuation">,</span>  <span class="token number">0.7383</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.0272</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7861</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1590</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.2132</span><span class="token punctuation">,</span>  <span class="token number">0.5984</span><span class="token punctuation">,</span>  <span class="token number">0.7383</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.0272</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7861</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1590</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.2132</span><span class="token punctuation">,</span>  <span class="token number">0.5984</span><span class="token punctuation">,</span>  <span class="token number">0.7383</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.0272</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7861</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1590</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.2132</span><span class="token punctuation">,</span>  <span class="token number">0.5984</span><span class="token punctuation">,</span>  <span class="token number">0.7383</span><span class="token punctuation">,</span>  <span class="token number">0.2132</span><span class="token punctuation">,</span>  <span class="token number">0.5984</span><span class="token punctuation">,</span>  <span class="token number">0.7383</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.0272</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7861</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1590</span><span class="token punctuation">,</span>  <span class="token number">1.0272</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7861</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1590</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2-torch-chunk-tensor-chunks-dim"><a href="#2-torch-chunk-tensor-chunks-dim" class="headerlink" title="2. torch.chunk(tensor, chunks, dim)"></a>2. torch.chunk(tensor, chunks, dim)</h3><p><strong>说明：</strong> 在给定的维度上讲张量进行分块。<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 待分块的输入张量</li><li>chunks(int) – 分块的个数</li><li>dim(int) – 维度，沿着此维度进行分块</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0103</span><span class="token punctuation">,</span>  <span class="token number">2.3358</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.9236</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3890</span><span class="token punctuation">,</span>  <span class="token number">0.6594</span><span class="token punctuation">,</span>  <span class="token number">0.6664</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.5240</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4193</span><span class="token punctuation">,</span>  <span class="token number">0.1681</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0103</span><span class="token punctuation">,</span>  <span class="token number">2.3358</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.9236</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3890</span><span class="token punctuation">,</span>  <span class="token number">0.6594</span><span class="token punctuation">,</span>  <span class="token number">0.6664</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.5240</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4193</span><span class="token punctuation">,</span>  <span class="token number">0.1681</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0103</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3890</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.5240</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">2.3358</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.6594</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4193</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.9236</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.6664</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.1681</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0103</span><span class="token punctuation">,</span>  <span class="token number">2.3358</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3890</span><span class="token punctuation">,</span>  <span class="token number">0.6594</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.5240</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4193</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.9236</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.6664</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.1681</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="3-torch-gather-input-dim-index-out-None"><a href="#3-torch-gather-input-dim-index-out-None" class="headerlink" title="3. torch.gather(input, dim, index, out=None)"></a>3. torch.gather(input, dim, index, out=None)</h3><p><strong>说明：</strong> 沿着给定维度，将输入索引张量index指定的位置的值重新聚合为一个新的张量。如果dim=1，那就是横向，index的索引代表列。dim=0那就是纵向，index索引代表的就是行值。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 源张量</li><li>dim(int) – 索引的维度</li><li>index(LongTensor) – 聚合元素的下表</li><li>out(Tensor,可选) – 目标张量</li></ul><p>下面的例子中，维度为1.那么取横行的元素。所以在第一行的下标为[0, 0],因此，聚合后的元素都取1，第二行的下表为[1, 0],因此聚合后的元素去[4, 3]。</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> t <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ttensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> index <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> indextensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>t<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="4-torch-index-select-input-dim-index-out-None"><a href="#4-torch-index-select-input-dim-index-out-None" class="headerlink" title="4. torch.index_select(input, dim, index, out=None)"></a>4. torch.index_select(input, dim, index, out=None)</h3><p><strong>说明：</strong>沿着指定维度对输入进行切片，取index中指定的相应项，返回一个新的张量，返回的张量与原始的张量有相同的维度。返回张量不与原始张量共享内存中的空间。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>dim(int) – 索引的维度</li><li>index(LongTensor) – 包含索引下标的一维张量</li><li>out(Tensor, 可选) – 目标张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0190</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7541</span><span class="token punctuation">,</span>  <span class="token number">2.1090</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9576</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4745</span><span class="token punctuation">,</span>  <span class="token number">0.1462</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.2930</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9130</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.7339</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.0842</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9208</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5618</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> indices<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0190</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7541</span><span class="token punctuation">,</span>  <span class="token number">2.1090</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9576</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.7339</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.0842</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9208</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5618</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> indices<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0190</span><span class="token punctuation">,</span>  <span class="token number">2.1090</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4745</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.2930</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.7339</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9208</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="5-torch-masked-select-input-mask-out-None"><a href="#5-torch-masked-select-input-mask-out-None" class="headerlink" title="5. torch.masked_select(input, mask, out=None)"></a>5. torch.masked_select(input, mask, out=None)</h3><p><strong>说明：</strong> 根据掩码张量mask中的二元值，取输入张量中指定项，将取值返回到一个新的1维张量。张量mask必须跟input张量有相同数量的元素数目，但形状或维度不需要相同。并且返回的张量不与原始张量共享内存空间。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>mask(ByteTensor) – 掩码张量，包含了二元索引值</li><li>out(Tensor, 可选) – 目标张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>ByteTensor<span class="token punctuation">(</span>x <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> masktensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>x<span class="token punctuation">,</span> mask<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1965</span><span class="token punctuation">,</span> <span class="token number">0.4689</span><span class="token punctuation">,</span> <span class="token number">0.2898</span><span class="token punctuation">,</span> <span class="token number">0.4847</span><span class="token punctuation">,</span> <span class="token number">2.8944</span><span class="token punctuation">,</span> <span class="token number">0.7096</span><span class="token punctuation">,</span> <span class="token number">0.0900</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-nonzero-input-out-None"><a href="#6-torch-nonzero-input-out-None" class="headerlink" title="6. torch.nonzero(input, out=None)"></a>6. torch.nonzero(input, out=None)</h3><p><strong>说明：</strong> 返回一个包含输入input中非零元素索引的张量。输出张量中的每行包含输入中非零元素的索引。如果输入input有n维，则输出的索引张量output的形状为z x n，这里z是输入张量input中所有非零元素的个数。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 源张量</li><li>out(LongTensor, 可选) – 包含索引值的结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                             <span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-split-tensor-split-size-dim-0"><a href="#7-torch-split-tensor-split-size-dim-0" class="headerlink" title="7. torch.split(tensor, split_size, dim=0)"></a>7. torch.split(tensor, split_size, dim=0)</h3><p><strong>说明：</strong> 将输入张量分割成相等形状的chunks(如果可分)。如果沿指定维的张量形状大小不能被整分，则最后一块会小于其他分块。<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 待分割张量</li><li>split_size(int) – 单个分块的形状大小</li><li>dim(int) – 沿着此维进行分割</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.1135</span><span class="token punctuation">,</span>  <span class="token number">0.5779</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9737</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0718</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.4136</span><span class="token punctuation">,</span>  <span class="token number">1.1577</span><span class="token punctuation">,</span>  <span class="token number">0.5689</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1970</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.4281</span><span class="token punctuation">,</span>  <span class="token number">0.3540</span><span class="token punctuation">,</span>  <span class="token number">1.4346</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1444</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1135</span><span class="token punctuation">,</span> <span class="token number">0.5779</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.4136</span><span class="token punctuation">,</span> <span class="token number">1.1577</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1.4281</span><span class="token punctuation">,</span> <span class="token number">0.3540</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.9737</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0718</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.5689</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1970</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.4346</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1444</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.1135</span><span class="token punctuation">,</span>  <span class="token number">0.5779</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9737</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0718</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.4136</span><span class="token punctuation">,</span>  <span class="token number">1.1577</span><span class="token punctuation">,</span>  <span class="token number">0.5689</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1970</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.4281</span><span class="token punctuation">,</span>  <span class="token number">0.3540</span><span class="token punctuation">,</span>  <span class="token number">1.4346</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1444</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-squeeze-input-dim-None-out-None"><a href="#8-torch-squeeze-input-dim-None-out-None" class="headerlink" title="8. torch.squeeze(input, dim=None, out=None)"></a>8. torch.squeeze(input, dim=None, out=None)</h3><p><strong>说明：</strong>将输入张量形状中的1去除并返回。如果输入是形如(Ax1xBx1xCx1xD)，那么输入的形状就为：(AxBxCxD)。当给定维度时，那么挤压操作只在给定维度上。例如，输入形状为：(Ax1xB),squeeze(input,0)将会保持张量不变，只有用squeeze(input,1)，形状会变成(AxB)。注意返回张量与输入张量共享内存，所以改变其中一个的内容会改变另一个。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>dim(int,可选) – 如果给定，则input只会在给定维度挤压</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-stack-sequence-dim-0"><a href="#9-torch-stack-sequence-dim-0" class="headerlink" title="9. torch.stack(sequence, dim=0)"></a>9. torch.stack(sequence, dim=0)</h3><p><strong>说明：</strong> 沿着一个新维度对输入张量序列进行连接。序列中所有的张量都应该为相同形状。<br>** 参数：**</p><ul><li>sequence(序列) – 待连接的张量序列</li><li>dim(int) – 插入的维度，必须介于0与待连接的张量序列数之间</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                   <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                   <span class="token punctuation">[</span><span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">90</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">70</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">90</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> c <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                   <span class="token punctuation">[</span><span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                   <span class="token punctuation">[</span><span class="token number">700</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">,</span> <span class="token number">900</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ctensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">400</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">700</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">900</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span>  <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">20</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span>  <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">40</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">30</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span>  <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">50</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span>  <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">60</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">70</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">700</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span>  <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">80</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span>  <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">90</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">900</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-t-input-out-None"><a href="#10-torch-t-input-out-None" class="headerlink" title="10. torch.t(input, out=None)"></a>10. torch.t(input, out=None)</h3><p><strong>说明：</strong>输入一个矩阵(2为张量)，并转置0,1维。可以被视为函数transpose(input, 0, 1)的简写函数。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.9204</span><span class="token punctuation">,</span>  <span class="token number">0.7971</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.8631</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8583</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.3379</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4079</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>t<span class="token punctuation">(</span>x<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.9204</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8583</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.7971</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.3379</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.8631</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4079</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-transpose-input-dim0-dim1-out-None"><a href="#11-torch-transpose-input-dim0-dim1-out-None" class="headerlink" title="11. torch.transpose(input, dim0, dim1, out=None)"></a>11. torch.transpose(input, dim0, dim1, out=None)</h3><p><strong>说明：</strong> 返回输入矩阵input的转置。交换维度dim0和dim1.输出张量与输入张量共享内存，所以改变其中一个会导致另外一个也被修改。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>dim0(int) – 转置的第一维</li><li>dim1(int) – 转置的第二维</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.5434</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.3860</span><span class="token punctuation">,</span>  <span class="token number">0.0252</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.4734</span><span class="token punctuation">,</span>  <span class="token number">0.2466</span><span class="token punctuation">,</span>  <span class="token number">0.3052</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.5434</span><span class="token punctuation">,</span>  <span class="token number">0.4734</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.3860</span><span class="token punctuation">,</span>  <span class="token number">0.2466</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.0252</span><span class="token punctuation">,</span>  <span class="token number">0.3052</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="12-torch-unbind-tensor-dim-0"><a href="#12-torch-unbind-tensor-dim-0" class="headerlink" title="12. torch.unbind(tensor, dim=0):"></a>12. torch.unbind(tensor, dim=0):</h3><p><strong>说明：</strong> 移除指定维后，返回一个元组，包含了沿着指定维切片后的各个切片。<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 输入张量</li><li>dim(int) – 删除的维度</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.4775</span><span class="token punctuation">,</span>  <span class="token number">0.0161</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9403</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.6109</span><span class="token punctuation">,</span>  <span class="token number">2.1144</span><span class="token punctuation">,</span>  <span class="token number">1.1833</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2656</span><span class="token punctuation">,</span>  <span class="token number">0.7772</span><span class="token punctuation">,</span>  <span class="token number">0.5989</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.4775</span><span class="token punctuation">,</span>  <span class="token number">1.6109</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2656</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0161</span><span class="token punctuation">,</span> <span class="token number">2.1144</span><span class="token punctuation">,</span> <span class="token number">0.7772</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.9403</span><span class="token punctuation">,</span>  <span class="token number">1.1833</span><span class="token punctuation">,</span>  <span class="token number">0.5989</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="13-torch-unsqueeze-input-dim-out-None"><a href="#13-torch-unsqueeze-input-dim-out-None" class="headerlink" title="13. torch.unsqueeze(input, dim, out=None)"></a>13. torch.unsqueeze(input, dim, out=None)</h3><p><strong>说明：</strong>返回一个新的张量，对输入的指定位置插入维度1.注意返回张量与输入张量共享内存，如果dim为负，则将会被转换为dim + input.dim() + 1.<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 输入张量</li><li>dim(int) – 插入维度的索引</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----创建操作</title>
      <link href="/2019/06/21/pytorch-xue-xi-zhi-torch-chuang-jian-cao-zuo/"/>
      <url>/2019/06/21/pytorch-xue-xi-zhi-torch-chuang-jian-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-eye-n-m-None-out-None"><a href="#1-torch-eye-n-m-None-out-None" class="headerlink" title="1. torch.eye(n, m=None, out=None)"></a>1. torch.eye(n, m=None, out=None)</h3><p><strong>说明：</strong> 创建一个2维张量，对角线数字为1， 其他位置为0。也就是一个单位矩阵。</p><p><strong>参数：</strong></p><ul><li>n – 行数，</li><li>m – 列数，如果为None，默认等于n，</li><li>out – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> torch<span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2-torch-from-numpy-ndarray"><a href="#2-torch-from-numpy-ndarray" class="headerlink" title="2. torch.from_numpy(ndarray)"></a>2. torch.from_numpy(ndarray)</h3><p><strong>说明：</strong> 将numpy.ndarray转换为Tensor。返回的Tensor和numpy的ndarray共享同一内存空间。修改一个会导致另外一个也被修改。返回的张量不能调整大小。</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> numpy<span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> numpy<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> t <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ttensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> t<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token operator">>></span><span class="token operator">></span> aarray<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="3-torch-linspace-start-end-steps-100-out-None"><a href="#3-torch-linspace-start-end-steps-100-out-None" class="headerlink" title="3. torch.linspace(start, end, steps=100, out=None)"></a>3. torch.linspace(start, end, steps=100, out=None)</h3><p><strong>说明：</strong> 返回start和end之间长度为steps的一维张量，也就是start和end之间的steps个数。并且其返回的是一个等差数列。<br><strong>参数：</strong></p><ul><li>start(float) – 点集的起始值，</li><li>end(float) – 点集的最终值，</li><li>steps(int) – start和end之间的采样数，即返回多少个数</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> steps<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>   <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>   <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">1.2500</span><span class="token punctuation">,</span> <span class="token number">2.5000</span><span class="token punctuation">,</span> <span class="token number">3.7500</span><span class="token punctuation">,</span> <span class="token number">5.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token operator">=</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> steps<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10.0000</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">7.7778</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">5.5556</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">3.3333</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">1.1111</span><span class="token punctuation">,</span>   <span class="token number">1.1111</span><span class="token punctuation">,</span>   <span class="token number">3.3333</span><span class="token punctuation">,</span>          <span class="token number">5.5556</span><span class="token punctuation">,</span>   <span class="token number">7.7778</span><span class="token punctuation">,</span>  <span class="token number">10.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="4-torch-logspace-start-end-steps-100-out-None"><a href="#4-torch-logspace-start-end-steps-100-out-None" class="headerlink" title="4. torch.logspace(start, end, steps=100, out=None)"></a>4. torch.logspace(start, end, steps=100, out=None)</h3><p><strong>说明：</strong> 返回一个1维张量，包含在区间和上，以对数刻度均匀间隔的steps个点。输出1维张量的长度为steps。<br><strong>参数：</strong></p><ul><li>start(float) – 点集的起始点</li><li>end(float) – 点集的最终点</li><li>steps(int) – 在start和end间生成的样本数</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>logspace<span class="token punctuation">(</span>start<span class="token operator">=</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> steps<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0000e-10</span><span class="token punctuation">,</span> <span class="token number">1.0000e-05</span><span class="token punctuation">,</span> <span class="token number">1.0000e+00</span><span class="token punctuation">,</span> <span class="token number">1.0000e+05</span><span class="token punctuation">,</span> <span class="token number">1.0000e+10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>logspace<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.2589</span><span class="token punctuation">,</span>  <span class="token number">2.1135</span><span class="token punctuation">,</span>  <span class="token number">3.5481</span><span class="token punctuation">,</span>  <span class="token number">5.9566</span><span class="token punctuation">,</span> <span class="token number">10.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="5-torch-ones-sizes-out-None"><a href="#5-torch-ones-sizes-out-None" class="headerlink" title="5. torch.ones(*sizes, out=None)"></a>5. torch.ones(*sizes, out=None)</h3><p><strong>说明：</strong> 返回一个全为1的张量，形状由可变参数sizes定义。<br><strong>参数：</strong></p><ul><li>sizes(int) – 整数序列，定义了输出的形状。如(3,3）</li><li>out(Tensor, 可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-rand-size-out-None"><a href="#6-torch-rand-size-out-None" class="headerlink" title="6. torch.rand(*size, out=None)"></a>6. torch.rand(*size, out=None)</h3><p><strong>说明：</strong> 返回一个张量，填充在[0,1]区间的一组均匀分布随机数。Tensor的形状由变量sizes定义。<br><strong>参数：</strong></p><ul><li>sizes(int) – 整数序列，定义了输出形状</li><li>out(Tensor, 可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.4962</span><span class="token punctuation">,</span> <span class="token number">0.0724</span><span class="token punctuation">,</span> <span class="token number">0.0478</span><span class="token punctuation">,</span> <span class="token number">0.3524</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.3200</span><span class="token punctuation">,</span> <span class="token number">0.7308</span><span class="token punctuation">,</span> <span class="token number">0.3226</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.8039</span><span class="token punctuation">,</span> <span class="token number">0.2359</span><span class="token punctuation">,</span> <span class="token number">0.7256</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-randn-size-out-None"><a href="#7-torch-randn-size-out-None" class="headerlink" title="7. torch.randn(*size, out=None)"></a>7. torch.randn(*size, out=None)</h3><p><strong>说明：</strong> 返回一个张量，包含了从正态分布(均值为0，方差为1)中抽取一组随机数。Tensor的形状由变量sizes定义。<br><strong>参数：</strong></p><ul><li>sizes(int) – 整数序列，定义了输出形状</li><li>out(Tensor, 可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.3094</span><span class="token punctuation">,</span>  <span class="token number">0.4774</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1807</span><span class="token punctuation">,</span>  <span class="token number">0.9894</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3299</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0495</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4758</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0680</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3875</span><span class="token punctuation">,</span>  <span class="token number">0.9846</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-randperm-n-out-None"><a href="#8-torch-randperm-n-out-None" class="headerlink" title="8. torch.randperm(n, out=None)"></a>8. torch.randperm(n, out=None)</h3><p><strong>说明：</strong> 返回以LongTenor，输入参数n，返回一个从0到n-1的随机整数排列。<br><strong>参数：</strong></p><ul><li>n(int) – 上限，即最大值。</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-arange-start-end-step-1-out-None"><a href="#9-torch-arange-start-end-step-1-out-None" class="headerlink" title="9. torch.arange(start, end, step=1, out=None)"></a>9. torch.arange(start, end, step=1, out=None)</h3><p><strong>说明：</strong>  返回一个1维张量，长度为，中间计算值，向下取整的意思。包含从start到end，以step为步长的一组序列值。默认步长为1。<br><strong>参数：</strong></p><ul><li>start(float) – 该点集的起始点</li><li>end(float) – 点集的终止点</li><li>step(float) – 相邻点的间隔大小</li><li>out(Tensor, 可选的) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token number">1.5000</span><span class="token punctuation">,</span> <span class="token number">2.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-range-start-end-step-1-out-None"><a href="#10-torch-range-start-end-step-1-out-None" class="headerlink" title="10. torch.range(start, end, step=1, out=None)"></a>10. torch.range(start, end, step=1, out=None)</h3><p><strong>说明：</strong> 返回一维张量，长度为+1，从start开始，到end结束。以step为步长的一组值。step是两个值之间的间隔。<br><strong>参数：</strong></p><ul><li>start(float) – 点集的起始点</li><li>end(float) – 点集的最终值</li><li>step(int) – 相邻点之间的间隔大小</li><li>out(Tensor, 可选的) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>__main__<span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">:</span> UserWarning<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>range <span class="token keyword">is</span> deprecated <span class="token keyword">in</span> favor of torch<span class="token punctuation">.</span>arange <span class="token operator">and</span> will be removed <span class="token keyword">in</span> <span class="token number">0.5</span><span class="token punctuation">.</span> Note that arange generates values <span class="token keyword">in</span> <span class="token punctuation">[</span>start<span class="token punctuation">;</span> end<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">not</span> <span class="token punctuation">[</span>start<span class="token punctuation">;</span> end<span class="token punctuation">]</span><span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token number">1.5000</span><span class="token punctuation">,</span> <span class="token number">2.0000</span><span class="token punctuation">,</span> <span class="token number">2.5000</span><span class="token punctuation">,</span> <span class="token number">3.0000</span><span class="token punctuation">,</span> <span class="token number">3.5000</span><span class="token punctuation">,</span> <span class="token number">4.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-zeros-size-out-None"><a href="#11-torch-zeros-size-out-None" class="headerlink" title="11. torch.zeros(*size, out=None)"></a>11. torch.zeros(*size, out=None)</h3><p><strong>说明：</strong>返回一个全0的张量，形状由可变参数sizes定义。<br><strong>参数：</strong></p><ul><li>sizes(int) – 整数序列，定义了输出形状</li><li>out(Tensor, 可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p><strong>总结：</strong> 这部分内容主要是创建操作，创建一些随机数，或者是矩阵。在pytorch中，他们都是张量类型。简单的创建操作。反复练习。方可掌握。如果有numpy的基础。那就更加容易学习。其实无论numpy，tensorflow，pytorch等。在创建一些随机数/矩阵中，他们都是相同的。只不过是存在不同的第三方库中。</p>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
