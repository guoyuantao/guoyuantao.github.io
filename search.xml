<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>特征工程入门与实践----特征增强</title>
      <link href="/2019/10/04/te-zheng-gong-cheng-ru-men-yu-shi-jian-te-zheng-zeng-qiang/"/>
      <url>/2019/10/04/te-zheng-gong-cheng-ru-men-yu-shi-jian-te-zheng-zeng-qiang/</url>
      
        <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;特征增强是对数据的进一步修改，我们开始清洗和增强数据。主要涉及的操作有</p><ul><li>识别数据中的缺失值</li><li>删除有害数据</li><li>输入缺失值</li><li>对数据进行归一化/标准化</li></ul><h5 id="1-识别数据中的缺失值"><a href="#1-识别数据中的缺失值" class="headerlink" title="1. 识别数据中的缺失值"></a>1. 识别数据中的缺失值</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;特征增强的第一种方法是识别数据的缺失值，可以让我们更好的明白如何使用真是世界中的数据。通常，数据因为一些原因，导致数据缺失，不完整。我们需要做的就是识别出数据中的缺失值。并对缺失值进行处理。本文使用皮马印第安人糖尿病预测数据集。这个数据集包含768行数据点，9列特征。预测21岁以上的女性皮马印第安人5年内是否会患糖尿病。数据每列的含义如下：<br>（1）怀孕次数<br>（2）口服葡萄糖耐量实验中的2小时血浆葡萄糖浓度<br>（3）舒张压<br>（4）三头肌皮褶厚度<br>（5）2小时血清胰岛素浓度<br>（6）体重指数<br>（7）糖尿病家族函数<br>（8）年龄<br>（9）类变量(0或1,代表有无糖尿病)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先我们先来了解一下数据</p><pre><code># 导入探索性数据分析所需的包import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as sns%matplotlib inlineplt.style.use('fivethirtyeight')# 添加标题pima_column_names = ['times_pregnant', 'plasma_glucose_concentration', 'diastolic_blood_pressure', 'triceps_thickness',                    'serum_insulin', 'bmi', 'pedigree_function', 'age', 'onset_diabetes']pima = pd.read_csv('./data/pima.data', names=pima_column_names)pima.head()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004142223109.png" alt="数据"></p><pre><code># 计算一下空准确率pima['onset_diabetes'].value_counts(normalize=True)</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004142341291.png" alt="结果"></p><pre><code># 对plasma_glucose_concentration列绘制两类的直方图col = 'plasma_glucose_concentration'plt.hist(pima[pima['onset_diabetes'] == 0][col], 10, alpha=0.5, label='non-diabetes')   # 不患糖尿病plt.hist(pima[pima['onset_diabetes'] == 1][col], 10, alpha=0.5, label='diabetes')  # 患糖尿病plt.legend(loc='upper right')plt.xlabel(col)plt.ylabel('Frequency')plt.title('Histogram of {}'.format(col))plt.show()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004142409752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="患病与不患病的血糖浓度频率直方图"></p><pre><code># 线性相关矩阵量化变量间的关系# 数据相关矩阵的热力图sns.heatmap(pima.corr())</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004142610107.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="数据相关热力图"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上面的分析中，我们首先可以得到患者和常人的血糖浓度是有很大的差异的。并且血糖浓度与患者是否患病的相关性很大。下面我们来分析一下数据是否存在缺失值。</p><pre><code># 查看数据中是否存在缺失值pima.isnull().sum()</code></pre><p><img src="https://img-blog.csdnimg.cn/201910041432437.png" alt="结果"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上面的结果我们可以看到并没有缺失值，我们在看一下关于数据的基本描述性统计。</p><pre><code># 查看数据的基本描述性统计pima.describe()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004143411926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="结果"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们可以看到BMI指标的最小值是0.这是有悖于医学常识的。这有可能是缺失或不存在的点都用0填充了。从数据中可以看到，有好几列都是0.但是onset——diabetes中的0代表没有糖尿病，人也可以怀孕0次。所以这两列没有问题，其他的列的缺失值用0填充了。</p><ul><li>plasma_glucose_concentration</li><li>diastolic_blood_pressure</li><li>triceps_thickness</li><li>serum_insulin</li><li>bmi<h5 id="2-处理数据中的缺失值"><a href="#2-处理数据中的缺失值" class="headerlink" title="2. 处理数据中的缺失值"></a>2. 处理数据中的缺失值</h5>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先，对存在缺失值的列，使用None代替0。然后在查看是否存在缺失值。</li></ul><pre><code># 直接对所有列操作columns = ['serum_insulin', 'bmi', 'plasma_glucose_concentration', 'diastolic_blood_pressure', 'triceps_thickness']for col in columns:    pima[col].replace([0], [None], inplace=True)# 查看缺失值情况pima.isnull().sum()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004144030184.png" alt="结果"></p><h6 id="（1）删除有害的行"><a href="#（1）删除有害的行" class="headerlink" title="（1）删除有害的行"></a>（1）删除有害的行</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们首先删除有害的行，然后对删除前后的数据做一个分析，最后应用机器学习算法评估一下当前数据的性能。<br><strong>删除存在缺失值的数据</strong>：</p><pre><code># 删除存在缺失的行pima_dropped = pima.dropna()# 检查删除了多少行num_rows_lost = round(100*(pima.shape[0] - pima_dropped.shape[0]) / float(pima.shape[0]))print("retained {}% of rows".format(num_rows_lost))</code></pre><p>retained 49% of rows<br><strong>数据分析</strong>：</p><pre><code># 继续对数据做一下探索性分析# 未删除数据的空准确率pima['onset_diabetes'].value_counts(normalize=True)</code></pre><p>0    0.651042<br>1    0.348958<br>Name: onset_diabetes, dtype: float64</p><pre><code># 删除数据后的空准确率pima_dropped['onset_diabetes'].value_counts(normalize=True)</code></pre><p>0    0.668367<br>1    0.331633<br>Name: onset_diabetes, dtype: float64</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从空准确率来看，前后的True和False并无太大的变化。接下来比较一下删除前后的个属性均值。</p><pre><code># 未删除数据的均值pima.mean()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004144853612.png" alt="结果"></p><pre><code># 删除数据后的均值pima_dropped.mean()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004144926336.png" alt="结果"></p><pre><code># 使用条形图进行可视化# 均值变化百分比条形图ax = ((pima_dropped.mean() - pima.mean()) / pima.mean()).plot(kind='bar', title='% change in average column values')ax.set_ylabel('% change')</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004145010209.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="均值变化条形图"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们可以看到，怀孕次数的均值在删除缺失值后下降了14%，糖尿病血系功能也上升了11%。都变化的比较大。删除行会严重影响数据的形状，所以我们应该保留尽可能多的数据。在我们进行其他操作前，我们使用一个机器学习算法验证一下当前数据情况的模型性能。<br><strong>评估性能</strong>：</p><pre><code># 导入机器学习from sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import GridSearchCV# 删除标签数据X_dropped = pima_dropped.drop('onset_diabetes', axis=1)  # 特征print("leanrning from {} rows".format(X_dropped.shape[0]))y_dropped = pima_dropped['onset_diabetes']   # 标签# KNN的模型参数knn_params = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7]}# KNN模型knn = KNeighborsClassifier()# 使用网格搜索优化grid = GridSearchCV(knn, knn_params)grid.fit(X_dropped, y_dropped)# 输出结果print(grid.best_score_, grid.best_params_)</code></pre><p>结果：0.7448979591836735 {‘n_neighbors’: 7}</p><h6 id="（2）填充缺失值"><a href="#（2）填充缺失值" class="headerlink" title="（2）填充缺失值"></a>（2）填充缺失值</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先，我们检查一下缺失值的情况。然后使用sklearn模块的方法填充缺失值，最后在检查缺失值情况，用机器学期方法验证一下模型的性能。<br><strong>检查缺失值：</strong></p><pre><code># 在此查看缺失值情况pima.isnull().sum()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004154718649.png" alt="结果"><br><strong>填充缺失值：</strong></p><pre><code># 使用scikit-learn预处理类的Imputer模块from sklearn.preprocessing import Imputer# 实例化对象imputer = Imputer(strategy='mean')# 创建新对象pima_imputed = imputer.fit_transform(pima)# 将得到的ndarray类型转化为DataFramepima_imputed = pd.DataFrame(pima_imputed, columns=pima_column_names)pima_imputed.head()</code></pre><p><img src="https://img-blog.csdnimg.cn/2019100415481054.png" alt="填充后的数据"><br><strong>检查缺失值情况并评估性能：</strong></p><pre><code># 判断是否有缺失值pima_imputed.isnull().sum()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004154909841.png" alt="结果"></p><pre><code># 尝试一下填充一些别的值，查看对KNN模型的影响# 用0填充pima_zero = pima.fillna(0)  X_zero = pima_zero.drop('onset_diabetes', axis=1)y_zero = pima_zero['onset_diabetes']# knn模型参数knn_params = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7]}# 网格搜索grid = GridSearchCV(knn, knn_params)grid.fit(X_zero, y_zero)# 输出print(grid.best_score_, grid.best_params_)</code></pre><p>结果：0.7330729166666666 {‘n_neighbors’: 6}</p><h5 id="3-标准化和归一化"><a href="#3-标准化和归一化" class="headerlink" title="3. 标准化和归一化"></a>3. 标准化和归一化</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们现在要做的是进一步增强机器学习流水线，进行一下探索性数据分析。</p><pre><code>impute = Imputer(strategy='mean')# 填充所有的缺失值pima_imputed_mean = pd.DataFrame(impute.fit_transform(pima), columns=pima_column_names)# 画直方图pima_imputed_mean.hist(figsize=(15, 15))</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004155539881.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="部分结果"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从这分析中可以发现，某些特征数据的尺度不同。有一些机器学习模型受数据尺度的影响很大。因此，我们可以使用某种归一化/标准化操作。<br><strong>归一化：</strong>将行和列对齐并转化为一致的规则。将所有定量列转化为同一个静态范围中的值。<br><strong>标准化：</strong>通过确保所有行和列在机器学习中得到平等对待，让数据的处理保持一致。</p><h6 id="（1）z分数标准化"><a href="#（1）z分数标准化" class="headerlink" title="（1）z分数标准化"></a>（1）z分数标准化</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;z分数标准化利用了统计学最简单的z分数思想。将特征重新缩放，均值为0、标准差为1。通过缩放特征、统一化均值和方差，可以让机器学习模型达到最优化。公式为<br>$$<br>z=\frac{x-\mu }{\sigma }<br>$$<br>其中$\mu$为均值，$\sigma$为标准差。</p><pre><code># 取此列均值mu = pima['plasma_glucose_concentration'].mean()# 取此列标准差sigma = pima['plasma_glucose_concentration'].std()# 对每个值计算z分数print(((pima['plasma_glucose_concentration'] - mu) / sigma).head())</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004161219925.png" alt="标准化后的数据"></p><pre><code># 使用内置的z分数归一化from sklearn.preprocessing import StandardScaler# 用z分数标准化scaler = StandardScaler()glucose_z_score_standardized = scaler.fit_transform(pima[['plasma_glucose_concentration']])# 直方图ax = pd.Series(glucose_z_score_standardized.reshape(-1,)).hist()ax.set_title('Distribution of plasma_glucose_concentration after Z Score Scaling')</code></pre><p><img src="https://img-blog.csdnimg.cn/201910041614471.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="标准化后的数据直方图"></p><pre><code># 将z分数标准化插入到机器学习流水线上knn_params = {'imputer__strategy': ['mean', 'median'], 'classify__n_neighbors': [1, 2, 3, 4, 5, 6, 7]}mean_impute_standardize = Pipeline([('imputer', Imputer()), ('standardize', StandardScaler()), ('classify', knn)])X = pima.drop('onset_diabetes', axis=1)y = pima['onset_diabetes']grid = GridSearchCV(mean_impute_standardize, knn_params)grid.fit(X, y)print(grid.best_score_, grid.best_params_)</code></pre><p>结果：0.7421875 {‘classify__n_neighbors’: 7, ‘imputer__strategy’: ‘median’}</p><h6 id="（2）min-max标准化"><a href="#（2）min-max标准化" class="headerlink" title="（2）min-max标准化"></a>（2）min-max标准化</h6><p>$$<br>m=\frac{x-x_{min} }{x_{max}-x_{min}}<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，$x_{min}$为该列最小值，$x_{max}$为该列最大值。<br><strong>标准化</strong></p><pre><code># 导入sklearn模块from sklearn.preprocessing import MinMaxScaler# 实例化min_max = MinMaxScaler()# min-max标准化pima_min_maxed = pd.DataFrame(min_max.fit_transform(pima_imputed), columns=pima_column_names)# 得到描述性统计pima_min_maxed.describe()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004162442416.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="标准化后的数据"><br><strong>评估性能</strong></p><pre><code>knn_params = {'imputer__strategy': ['mean', 'median'], 'classify__n_neighbors': [1, 2, 3, 4, 5, 6, 6]}mean_impute_standardize = Pipeline([('imputer', Imputer()), ('standardize', MinMaxScaler()), ('classify', knn)])X = pima.drop('onset_diabetes', axis=1)y = pima['onset_diabetes']grid = GridSearchCV(mean_impute_standardize, knn_params)grid.fit(X, y)print(grid.best_score_, grid.best_params_)</code></pre><p>结果：0.74609375 {‘classify__n_neighbors’: 4, ‘imputer__strategy’: ‘mean’}</p><h6 id="（3）行归一化"><a href="#（3）行归一化" class="headerlink" title="（3）行归一化"></a>（3）行归一化</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;行归一化是针对行进行操作的，保证每行有单位范数，也就是每行的向量长度相同。<br>$$<br>\left | x \right |=\sqrt{(x_{1}^{2}+x_{2}^{2}+…+x_{n}^{2})}<br>$$<br><strong>归一化</strong></p><pre><code># 引入行归一化from sklearn.preprocessing import Normalizer# 实例化normalize = Normalizer()pima_normalized = pd.DataFrame(normalize.fit_transform(pima_imputed), columns=pima_column_names)# 行归一化后矩阵的平均范数np.sqrt((pima_normalized**2).sum(axis=1)).mean()</code></pre><p>结果：1.0<br><strong>评估性能</strong></p><pre><code>knn_params = {'imputer__strategy': ['mean', 'median'], 'classify__n_neighbors': [1, 2, 3, 4, 5, 6, 6]}mean_impute_standardize = Pipeline([('imputer', Imputer()), ('normalize', Normalizer()), ('classify', knn)])X = pima.drop('onset_diabetes', axis=1)y = pima['onset_diabetes']grid = GridSearchCV(mean_impute_standardize, knn_params)grid.fit(X, y)print(grid.best_score_, grid.best_params_)</code></pre><p>结果：0.6822916666666666 {‘classify__n_neighbors’: 6, ‘imputer__strategy’: ‘mean’}<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从本章的学习中，我们处理了数据中的缺失值，并使用标准化/归一化的方法继续处理数据。然后我们评估了性能。得到的结果是使用均值填充数据，然后用min-max标准化处理出具。得到0.7461的准确率。注意，虽然这个数据比删除存在缺失值的数据准确率没有高很多。但是这是使用全部数据训练的结果。更具有一般化。泛化性能将更好。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 特征工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 特征工程，数据挖掘，数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征工程入门与实践----特征理解</title>
      <link href="/2019/10/03/te-zheng-gong-cheng-ru-men-yu-shi-jian-te-zheng-li-jie/"/>
      <url>/2019/10/03/te-zheng-gong-cheng-ru-men-yu-shi-jian-te-zheng-li-jie/</url>
      
        <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;特征理解，简单说就是理解数据中都有什么，对数据的理解方便我们认清数据，从而对数据进行操作，构造有用的特征。我们将从以下几个方面来认清数据：</p><ul><li>结构化数据与非结构化数据</li><li>定量数据与定性数据</li><li>数据的4个等级</li><li>探索性数据分析和数据可视化</li><li>描述性统计</li></ul><h5 id="1-结构化数据和非结构化数据"><a href="#1-结构化数据和非结构化数据" class="headerlink" title="1. 结构化数据和非结构化数据"></a>1. 结构化数据和非结构化数据</h5><p><strong>结构化(有组织)数据</strong>：分成观察值和特征的数据，以表格的形式组织，行是观察值，列是特征。例如，科学仪器报告的气象数据，是存在表格的行列结构。</p><p><img src="https://img-blog.csdnimg.cn/20191004103250519.png" alt="结构化数据"><br><strong>非结构化(无组织)数据</strong>：作为自由流动的实体，不遵循标准组织结构的数据。例如，服务器日志和推文。<br><img src="https://img-blog.csdnimg.cn/20191004103730746.png" alt="非结构化数据"></p><h5 id="2-定量数据和定性数据"><a href="#2-定量数据和定性数据" class="headerlink" title="2. 定量数据和定性数据"></a>2. 定量数据和定性数据</h5><p><strong>定量数据</strong>：本质上是数值，应该是衡量某样东西的数量。<br><strong>定性数据</strong>：本质上是类别，应该是描述某样东西的性质。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们首先导入一个数据，这个数据是旧金山做不同工作的工资。</p><pre><code># 导包# 数学计算包import numpy as np# 存储表格数据import pandas as pd# 数据可视化包import matplotlib.pyplot as pltimport seaborn as sns# 允许行内渲染图形%matplotlib inline# 流行的数据可视化主题plt.style.use('fivethirtyeight')# 导入数据salary_ranges = pd.read_csv('./data/Salary_Ranges_by_Job_Classification.csv')# 查看前几行salary_ranges.head()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004113854263.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="数据展示"></p><pre><code># 查看数据的信息salary_ranges.info()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004113943494.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="数据信息"></p><pre><code># 查看数据是否存在缺失salary_ranges.isnull().sum()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004114050424.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="是否存在缺失值"></p><pre><code># 数据的描述性统计salary_ranges.describe()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004114151371.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="数据的统计特性"></p><h5 id="3-数据的4个等级"><a href="#3-数据的4个等级" class="headerlink" title="3. 数据的4个等级"></a>3. 数据的4个等级</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每个等级都有不同的控制和数学操作等级。了解数据让我们选择合适的可视化类型和操作。</p><h6 id="（1）定类等级"><a href="#（1）定类等级" class="headerlink" title="（1）定类等级"></a>（1）定类等级</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;定类等级，其结构最弱。数据只按名称分类。例如血型和人名。这些数据都是定性的。定类等级的数据上不能执行任何定量的数学操作。如下，对工作种类进行计数，出现次数最多的工作种类是00000。</p><pre><code># 对工作种类进行计数salary_ranges['Grade'].value_counts().head()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004121341631.png" alt="工作种类计数"></p><pre><code># 对工作种类绘制条形图salary_ranges['Grade'].value_counts().sort_values(ascending=False).head(20).plot(kind='bar')</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004121730784.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="工作种类条形图"></p><pre><code># 绘制饼图salary_ranges['Grade'].value_counts().sort_values(ascending=False).head(5).plot(kind='pie')</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004121917567.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="工作种类饼图"></p><h6 id="（2）定序等级"><a href="#（2）定序等级" class="headerlink" title="（2）定序等级"></a>（2）定序等级</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;定序等级继承了定类等级的属性，而且有重要的附加属性。定序等级的数据可以自然排序，但其天然数据属性仍然是类别。定序等级数据也是定性的。其可以像定类等级一样计数，还可以；引入比较和排序。还可以绘制茎叶图和箱线图。例如考试的等级(F、D、C、B、A)。我们使用旧金山国际机场的数据来实现操作。在这个数据的Q7A_ART属性是关于；艺术品和展览的，能选择的是0，1，2，3，4，5，6，每个数字都有含义。我们只考虑1-5。</p><pre><code># 导入数据集customer = pd.read_csv('./data/2013_SFO_Customer_survey.csv')customer.shape# 只考虑1-5art_ratings = art_ratings[(art_ratings &gt;= 1) &amp; (art_ratings &lt;= 6)]# 将值转为字符串art_ratings = art_ratings.astype(str)art_ratings.describe()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004123045191.png" alt="数据信息"></p><pre><code># 使用条形图进行可视化art_ratings.value_counts().plot(kind='bar')</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004123130100.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="条形图"></p><pre><code># 使用箱线图进行可视化art_ratings.value_counts().plot(kind='box')</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004123200840.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="箱线图"></p><h6 id="（3）定距等级"><a href="#（3）定距等级" class="headerlink" title="（3）定距等级"></a>（3）定距等级</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;定距等级的数据是定量的数据。定距等级的数据之差是有意的。因此，不仅可以对值进行排序和比较，还可以进行加减法的运算。例如，当我们考虑温度的时候，上海的温度是32度，哈尔滨的温度是4度，32-4=28代表两地的温差为28度。相反，对于李克特量表做这种减法则没有任何意义。</p><pre><code># 加载数据climate = pd.read_csv('./data/GlobalLandTemperaturesByCity.csv')# 移除缺失值climate.dropna(axis=0, inplace=True)climate.head()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004124223971.png" alt="移除缺失值后的数据"></p><pre><code># 对温度画直方图，擦好看温度分布climate['AverageTemperature'].hist()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004124517544.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="温度分布直方图"></p><pre><code># 将dt栏转换为日期，取年份climate['dt'] = pd.to_datetime(climate['dt'])climate['year'] = climate['dt'].map(lambda value: value.year)# 只看美国climate_sub_us = climate.loc[climate['Country'] == 'United States']climate_sub_us['century'] = climate_sub_us['year'].map(lambda x: int(x/100+1))# 使用新的centery列，对每个世纪化直方图climate_sub_us['AverageTemperature'].hist(by=climate_sub_us['century'], sharex=True, sharey=True, figsize=(10, 10), bins=20)</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004124637683.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="不同世纪的温度情况"></p><pre><code>climate_sub_us.groupby('century')['AverageTemperature'].mean().plot(kind='line')</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004124717143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="温度变换折线图"><br>在气候变化数据集中，我们针对year和averageTemperature两列数据进行描绘。</p><pre><code>x = climate_sub_us['year']y = climate_sub_us['AverageTemperature']fig, ax = plt.subplots(figsize=(10, 5))ax.scatter(x, y)plt.show()# 用groupby清除美国气温的噪声climate_sub_us.groupby('year').mean()['AverageTemperature'].plot()# 用滑动均值平滑图像climate_sub_us.groupby('year').mean()['AverageTemperature'].rolling(10).mean().plot()</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004124955638.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="温度随year的变化"></p><h6 id="（4）定比等级"><a href="#（4）定比等级" class="headerlink" title="（4）定比等级"></a>（4）定比等级</h6><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;定比等级处理的也是定量数据，拥有最高程度的控制和数学运算能力。除了加减运算，还有一个绝对零点的概念，可以做乘除运算。例如，100元是50元的两倍。$100/50=2$。</p><pre><code># 那个工资最高fig = plt.figure(figsize=(15, 5))ax = fig.gca()salary_ranges.groupby('Grade')[['Biweekly High Rate']].mean().sort_values('Biweekly High Rate', ascending=False).head(20).plot.bar(stacked=False, ax=ax, color='darkorange')ax.set_title('Top 20 Grade by Mean Biweekly High Rate')</code></pre><p><img src="https://img-blog.csdnimg.cn/20191004130454634.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="不同工作的工资(top20)"></p><pre><code># 哪个工作工资最低fig = plt.figure(figsize=(15, 5))ax = fig.gca()salary_ranges.groupby('Grade')[['Biweekly High Rate']].mean().sort_values('Biweekly High Rate', ascending=False).tail(20).plot.bar(stacked=False, ax=ax, color='darkorange')ax.set_title('Bottom 20 Grade by Mean Biweekly High Rate')</code></pre><p><img src="https://img-blog.csdnimg.cn/2019100413054433.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="不同工作的工资(Bottom20)"></p><pre><code># 计算最高工资和最低工资的比值sorted_df = salary_ranges.groupby('Grade')[['Biweekly High Rate']].mean().sort_values('Biweekly High Rate', ascending=False)sorted_df.iloc[0][0] / sorted_df.iloc[-1][0]</code></pre><p>13.931919540229886</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在本文中，最主要的内容是我们将数据分为了4个不同的等级。不同的等级我们有不同的操作和可视化方法。应用这些方法我们可以加深对数据的理解与认识。当我们拿到一个新数据集时，应首先做如下操作：</p><ol><li>判断数据是结构化的还是非结构化的</li><li>每列的数据是定量的还是定性的</li><li>每列处于的数据等级，是定类、定序、定距还是定比？</li><li>可以用什么图标可视化，条形图、饼图等。</li></ol><p><img src="https://img-blog.csdnimg.cn/20191004131137485.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="特征理解：处理数据流程"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 特征工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 特征工程，数据挖掘，数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征工程入门与实践----特征工程简介</title>
      <link href="/2019/10/01/te-zheng-gong-cheng-ru-men-yu-shi-jian-te-zheng-gong-cheng-jian-jie/"/>
      <url>/2019/10/01/te-zheng-gong-cheng-ru-men-yu-shi-jian-te-zheng-gong-cheng-jian-jie/</url>
      
        <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;人工智能的发展，让我们将那些需要手动操作才能处理的问题，让计算机也可以解决。例如，自然语言处理、人脸识别和图片分类等。因此，我们需要借助机器学习的知识来构建一个AI系统，从用户那里读取到原始数据，让计算机来帮助我们达到识别的目的。为了解决某个问题，需要收集大量的数据，这些数据都是在实际的情况中自然形成的，往往有杂乱或者不完整的情况。因此，我们需要对原始数据做处理。这就是所谓的<strong>特征工程</strong>。在日常的工作中80%的时间都用在捕获、清洗和组织数据上，20%的时间用在构造机器学习流水线上。下图展示了不同工作时间的比例。<br><img src="https://img-blog.csdnimg.cn/20191004085835215.png" alt="不同工作的时间比例"></p><ul><li>设置训练集：3%</li><li>清洗和组织数据：60%</li><li>收集数据集：19%</li><li>挖掘数据模式：9%</li><li>调整算法：4%</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;准备数据包括捕获数据、存储数据、清洗数据。<strong>清洗数据</strong>的意思是将数据转换为云系统和数据库可以轻松识别的形式。<strong>组织数据</strong>是将数据集的格式转换为更干净的格式。我们主要专注于特征工程，着眼于清洗和组织数据的过程，为机器学习流水线所服务。因此，所谓<strong>特征工程</strong>就是将数据转换为能更好的表示潜在问题的特征，而最终的目的是提高机器学习的性能。下面我们就要了解几个相关的概念。</p><ol><li><strong>特征</strong>：特征是对机器学习算法有意义的属性，对应表格数据，一列就是一个特征。</li><li><strong>响应(标签)</strong>：响应也是属性的一个，但是这个属性是我们有希望进行预测的。</li><li><strong>监督学习</strong>：利用有标签的数据，通过机器学习方法进行预测或者分类的学习过程。</li><li><strong>无监督学习</strong>：利用无标签数据，通过机器学习算法进行预测或者分类的学习过程。</li></ol><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们要做的就是通过特征工程，将杂乱、有问题的数据转化为干净、整洁的数据。这样我们就可以通过机器学习的算法来解决相应的问题。特征工程能提高机器学习的性能。评价一个特征工程的好坏的步骤为：<br>（1）在应用任何特征工程之前，得到机器学习模型的基准性能。<br>（2）应用一种或多种特征工程。<br>（3）对于每种特征工程获取一个性能指标，并与基准性能进行对比。<br>（4）如果性能增量大于某个阈值，则认为这种特征工程是有益的，可以应用在机器学习流水线上。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;接下来我们将学习以下几部分内容，来深入理解特征工程都在做什么：</p><ul><li>特征理解</li><li>特征增强</li><li>特征选择</li><li>特征构建</li><li>特征转换</li><li>特征学习</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后，说一下我自己是怎么开始认识到特征工程的重要，在我们的学习中，都是使用一些被处理好的数据来实现我们的模型。并且大多数人都将学习重点放在了模型上。这也造成了很多人都不关心特征工程这部分。直到最近参加了数学建模，选了一道需要特征工程相关知识的题，才感觉到自己对这方面知识的欠缺。最后买了这本书《特征工程入门与实践》。希望学完这本书，可以增加自己对特征工程的了解。</p><blockquote><p>注：本文的内容与图片来源于《特征工程入门与实践》。如有您也想学习相关知识，建议买一本来看。</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 特征工程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 特征工程，数据挖掘，数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN模型之GoogLeNet</title>
      <link href="/2019/09/26/cnn-mo-xing-zhi-googlenet/"/>
      <url>/2019/09/26/cnn-mo-xing-zhi-googlenet/</url>
      
        <content type="html"><![CDATA[<h4 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GoogLeNet，2014年由Google团队的Christian Szegedy等人提出，为了向LeNet致敬，所以取名GoogLeNet。2014年的ILSVRC分类任务中力压VGGNet赢得了分类任务的冠军。又名Inception。这个网络主要的特点是提高了网络内部计算资源的利用。从网络的深度和宽度两个方面都有所增加。是一个22层的卷积神经网络。要比VGGNet的19层更深。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GoogLeNet的最大特点就是其Inception结构，通过构建密集的块结构(Inception)来近似最优的稀疏结构，从而达到提高性能而又不大量增加计算量的目的。Inception结果为<br><img src="https://img-blog.csdnimg.cn/20190926143148446.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="Inception 模块"><br>在Inception模块中，包含了很多种卷积核，还有池化操作。(b)图中是带有降维的Inception模块。</p><ul><li>使用$1\times 1$、$3\times 3$、$5\times 5$大小的卷积核，padding不同尺寸，使输出图像大小一致，然后将得到的特征图拼接在一起。</li><li>层数加深，在不同深处增加loss来避免梯度回传消失。这两个loss就是辅助分类器。</li><li>$1\times 1$卷积核用来降维。<h4 id="二、模型结构"><a href="#二、模型结构" class="headerlink" title="二、模型结构"></a>二、模型结构</h4><img src="https://img-blog.csdnimg.cn/20190926144624328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="GoogLeNet网络"><br><img src="https://img-blog.csdnimg.cn/20190926144708195.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="网络配置"></li><li>AvgPool层设置$5\times 5$并且步长为3.</li><li>128个$1\times 1$的卷积用来降维，并使用ReLU激活函数</li><li>全连接层具有1024个节点，并使用ReLU激活函数</li><li>Dropout操作设置为0.7</li><li>最后是一个线性层是softmax loss 作为分类器。</li></ul><p>实验结果：<br><img src="https://img-blog.csdnimg.cn/20190926145949668.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="分类性能"></p><h4 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GoogLeNet网络通过构造密集构造块来近似预期的最佳稀疏结构，此方法的优点是在适度增加计算需求的情况下显著提高了网络的性能。实验结果也表明Inception结构的能力。</p><blockquote><p>友情链接：<br>代码实现：<a href="https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch" target="_blank" rel="noopener">https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch</a><br>联系方式：2391855138(加好友请备注)</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 卷积神经网络模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN模型之VGGNet</title>
      <link href="/2019/09/25/cnn-mo-xing-zhi-vggnet/"/>
      <url>/2019/09/25/cnn-mo-xing-zhi-vggnet/</url>
      
        <content type="html"><![CDATA[<h4 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;VGGNet是于2014年由牛津大学计算机视觉组和DeepMind公司共同研究的。在2014年的ILSVRC比赛上获得了分类项目的第二名和定位项目的第一名。这个网络据说是基于NIN网络的思想。与比赛中的第一名GooLeNet从NIN开始向两个方向发展。VGGNet的理念是更深的网络性能更好。因此，VGGNet的主要理念有：</p><ol><li>网络层数越多，也就是网络越深，网络的性能越好。</li><li>网络越深越不好训练，容易过拟合。因此，采用小卷积核。<h4 id="二、模型结构"><a href="#二、模型结构" class="headerlink" title="二、模型结构"></a>二、模型结构</h4><img src="https://img-blog.csdnimg.cn/20190925211856290.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="VGGNet网络结构"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图中所示，论文中一共提供了六种结构，可以分为VGG11、VGG13、VGG16和VGG19。其中VGG16和VGG19是我们常用的网络。它们的结构可分为两部分，第一部分为卷积层，主要目的是提取特征。第二部分为全连接层，主要目的是进行分类。在网络中主要的操作有</li></ol><ul><li>输入图像预处理只做了减均值操作，可以减去128或者减去所有像素的均值，收敛会快一些，性能不会差太多。</li><li>隐藏层使用ReLU，效率更高。不使用LRN。LRN也被证实没多大用处。在之后的模型也不被使用。</li><li>使用$3\times 3$和$1\times 1$的卷积核，非常小的感受野，这样就可以把网络加深，使用多个卷积核的总参数变少。</li><li>$1\times 1$的卷积增加了决策函数的非线性，相当于全连接。可进行通道的降维或者升维。</li><li>两个连续的$3\times 3$卷积核相当于一个$5\times 5$，三个相当于$7\times 7$。好处是网络结构更深，增加了非线性能力，参数更少了。</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在模型中，优化方法使用含有动量的随机梯度下降，损失函数中加入了L2正则化，全连接层的前两层加入了Dropout防止过拟合。网络的测试结果为<br><img src="https://img-blog.csdnimg.cn/20190925215521567.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="测试结果"></p><h4 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;VGGNet虽然是2014年分类任务的第二名，但是与第一名相差并不多，并且对之后的模型发展影响巨大。VGGNet网络得出的结论有</p><ul><li>LRN，局部归一化并不能改善网络的性能</li><li>随着网络的加深，分类误差降低，特征收敛越快，受样本变化的影响越小。</li><li>数据增加等操作可以增强模型的鲁棒性。</li><li>多裁剪评估比密集评估，效果更好。</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;VGGNet网络是一个非常好的网络，在很多任务中，都以它为基础模型，在此基础上进行更改。学习VGGNet模型，要知道它的网络结构，以及设计思想和最终的实验结论。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 卷积神经网络模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN模型之NIN</title>
      <link href="/2019/09/25/cnn-mo-xing-zhi-nin/"/>
      <url>/2019/09/25/cnn-mo-xing-zhi-nin/</url>
      
        <content type="html"><![CDATA[<h4 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NIN网络是由Min Lin等人在2014年提出的一个网络嵌套模型，使用微神经网络替换卷积神经网络中的卷积核。通过微神经网络来抽象感受野内的数据。称这种微神经网络结构为<strong>mplconv</strong>。这篇论文的创新之处主要体现在两个地方，分别是：</p><ol><li>使用微神经网络替换传统卷积神经网络的卷积核。</li><li>使用全局平均池化替代全连接层。<br><img src="https://img-blog.csdnimg.cn/20190925161649531.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt=" Comparison of linear convolution layer and mlpconv layer"></li></ol><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;微神经网络是由多层感知机实现的，上图中(a)图是传统的通过卷积核窗口在输入数据上滑动，对感受野内的数据进行抽象化。这种方式是线性的。(b)中就是论文提出的<strong>微神经网络</strong>。这是一种非线性的方式。通过实验，这种方法可以更好的抽象数据的特征。</p><h4 id="二、模型结构"><a href="#二、模型结构" class="headerlink" title="二、模型结构"></a>二、模型结构</h4><p><img src="https://img-blog.csdnimg.cn/20190925162130780.png" alt="NIN网络结构"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NIN网络中包括三个mplconv层和一个平均池化层的叠加。</p><ul><li>第一个mplconv：$5\times5$conv(ReLU) + $1\times1$conv(ReLU) + $1\times1$conv(ReLU+MaxPool+Droput)</li><li>第二个mplconv：$5\times5$conv(ReLU) + $1\times1$conv(ReLU) + $1\times1$conv(ReLU+AvgPool+Droput)</li><li>第三个mplconv：$3\times3$conv(ReLU) + $1\times1$conv(ReLU) + $1\times1$conv(ReLU)</li><li>平均池化层：通过平均池化得到的结果输入softmax中。</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从网络的结构中，我们可以注意到MPL的实现是通过$1\times 1$的卷积核实现，$1\times 1$的卷积核可以实现跨通道的交互和信息融合，可以对通道数进行降维和升维。在之后的ResNet、GoogLeNet网络中也用到。另外一个改进是全局平均池化代替全连接层。我们都知道全连接层参数多且容易发生过拟合。通过mplconv最后一层让每一类对应一个特征图。然后使用平均池化进行运算，在输入到softmax中得到最后的分类结果。并且全局平均池化也起到了正则化的作用。实验结果如下：<br><img src="https://img-blog.csdnimg.cn/20190925163909540.png" alt="实验结果"></p><h4 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NIN网络可以总结为两个方面的改进，一是使用微神经网络代替卷积核，二是使用全局平均池化代替全连接层。经过在cifar-10数据上实验，此网络的结果要好于当前的最好模型。在看这个网络时， 我也看了很多其他的网络，也听说过这个网络。当我读完论文之后，确实给我拓宽了思路，原来这块也可以更改。同样可以达到更好的结果。因此。我的感悟还是要见多识广。学习别人的思路。</p><blockquote><p>友情链接：<br>代码实现：<a href="https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch" target="_blank" rel="noopener">https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch</a><br>联系方式：2391855138(加好友请备注)</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 卷积神经网络模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN模型之ZFNet</title>
      <link href="/2019/09/16/cnn-mo-xing-zhi-zfnet/"/>
      <url>/2019/09/16/cnn-mo-xing-zhi-zfnet/</url>
      
        <content type="html"><![CDATA[<h4 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZFNet是Matthew D.Zeiler于2013年提出，并获得了13年ImageNet的冠军。2012年AlexNet问世，并在ImageNet竞赛中取得了优异的成绩，也证明了大的卷积网路的性能优异，但是我们并不知道为什么CNN性能好。因此，这篇论文介绍了一个可视化技术来了解隐藏层做了什么以及怎么进行分类。也是基于这个技术，作者对AlexNet进行了优化，调整之后的网络的性能在很多问题上性能都好于AlexNet。</p><h4 id="二、模型结构"><a href="#二、模型结构" class="headerlink" title="二、模型结构"></a>二、模型结构</h4><p><img src="https://img-blog.csdnimg.cn/20190916154402708.png" alt="ZFNet模型结构图"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZFNet的网络结构是基于AlexNet改进的。作者通过可视化技术发现小尺度的过滤器比大尺度的过滤器所得到的特征更加好。并且第一层的步长太大，导致后面出现混叠现象，学到的特征不是很好。因此，主要做了以下更改：</p><ul><li>将第一层的滤波器由11x11调整为7x7。</li><li>将第一层的步长由4调整为2.</li></ul><p><strong>可视化技术：</strong><br> <img src="https://img-blog.csdnimg.cn/20190916155817765.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，通过反池化和反卷积得到原始图像。经过了可视化后，发现调整尺寸和步长后，得到的中间层特征更好。<br><img src="https://img-blog.csdnimg.cn/20190916160615693.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h4 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;经过对中间层的可视化，可以观察到模型中间层的特征。并依据特征的好坏调整模型的卷积核大小和步长。在ImageNet上取得了比AlexNet更好的成绩，获得了2013年的第一名。这个技术也让我们明白了卷积神经网络是如何工作的。最后，在代码实现中，仅仅构造了网络的结构，我使用的是cifar10数据集。如果训练需要更改网络的一些设置。</p><blockquote><p>友情链接：<br>代码实现：<a href="https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch" target="_blank" rel="noopener">https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch</a><br>联系方式：2391855138(加好友请备注)</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 卷积神经网络模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN模型之AlexNet</title>
      <link href="/2019/09/05/cnn-mo-xing-zhi-alexnet/"/>
      <url>/2019/09/05/cnn-mo-xing-zhi-alexnet/</url>
      
        <content type="html"><![CDATA[<h4 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AlexNet是Alex Krizhevsky等人2012年提出。这个模型具有重大的意义，将ImageNet ILSVRC-2010竞赛的120万张图片1000个类别。top-1错误率为37.5%，top-5错误率为17.0%。在2012年的比赛中，将top-5错误率降到了15.3%，相较于第二名26.2%的错误率。AlexNet的性能提升了很多。</p><h4 id="二、网络结构"><a href="#二、网络结构" class="headerlink" title="二、网络结构"></a>二、网络结构</h4><p><img src="https://img-blog.csdnimg.cn/20190905211805456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AlexNet的网络结构：5个卷积层+3个全连接层(包含一个输出层)。</p><ul><li>第一个卷积层：Conv+LRN+ReLU+MaxPool。96个大小为$11\times 11\times 3$的卷积核，步长为4</li><li>第二个卷积层：Conv+LRN+ReLU+MaxPool。256个大小为$5 \times 5\times 48$的卷积核。</li><li>第三个卷积层：Conv+ReLU。256个大小为$3\times 3\times 256$的卷积核。</li><li>第四个卷积层：Conv+ReLU。384个大小为$3\times 3\times 192$的卷积核。</li><li>第五个卷积层：Conv+ReLU+MaxPool。256个大小为$3\times 3\times 192$的卷积核。</li><li>两个全连接层：都配有ReLU和Dropout。4096个单元。</li><li>输出层：1000个单元。配有softmax多分类器。</li></ul><h5 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h5><ul><li>使用ReLU代替传统的激活函数</li><li>LRN：局部响应归一化，将数据归一化到0-1之间。</li><li>重叠池化使特征图更加稠密，类似于2*2滤波器卷积</li><li>Dropout防止过拟合，正则化方法。</li><li>使用了数据增强来丰富样本。</li><li>Softmax损失函数，分类器。<h4 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h4>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AlexNet在卷积神经网络的发展上非常重要，也是从这个模型开始，卷积神经网络蓬勃发展。其使用了ReLU、LRN、Dropout等方法来提高模型的精度。虽然现在有很多模型，但这个模型也是我们必须学习的模型，从模型的分析来理解模型每个技术的作用。<blockquote><p>友情链接：<br>代码实现：<a href="https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch" target="_blank" rel="noopener">https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch</a><br>联系方式：2391855138(加好友请备注)</p></blockquote></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 卷积神经网络模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN模型之LeNet-5</title>
      <link href="/2019/09/05/cnn-mo-xing-zhi-lenet-5/"/>
      <url>/2019/09/05/cnn-mo-xing-zhi-lenet-5/</url>
      
        <content type="html"><![CDATA[<h4 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;卷积神经网络是当前深度学习领域比较火的研究方法。其应用主要是在计算机视觉上。例如，图像分类，目标检测，人脸识别等等。并且已经在这些领域取得了相当大的成就。本文主要介绍卷积神经网络的开篇之作：LeNet-5。LeNet-5由Y. LeCun 在1998年发表的文章《Gradient-Based Learning Applied to Document Recognition 》中正式提出。在论文中，应用MNIST手写数字体数据做实验。LeNet并不是1998年才存在的。在1989年Y.LeCun的另一篇文章就已经提到。知识在1998年正式提出。下面，我们就看一下LeNet-5的网络结构。</p><h4 id="二、模型结构"><a href="#二、模型结构" class="headerlink" title="二、模型结构"></a>二、模型结构</h4><p><img src="https://img-blog.csdnimg.cn/20190826193656596.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt="图1：LeNet-5网络结构图"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图是LeNet-5的网络结构图。该网络一共包含7层，输入时一个$32\times 32$的图像。当我们实际应用这个网络的时候可以根据实际的问题来修改输入尺寸与网络中的结构。</p><ol><li>Layer C1：第一个卷积层，得到6个$28\times28$的特征图。卷积核的大小为$5\times5$。</li><li>Layer S2：下采样层等同于池化层，我们一般使用最大池化操作。得到6个$14\times14$的特征图。设置$2\times2$的过滤器。</li><li>Layer C3：第二个卷积层，得到16个$5\times5$的特征图。卷积核的大小为$5\times5$。</li><li>Layer S4：下采样层等同于池化层。得到16个$5\times5$的特征图。设置$2\times2$的过滤器。</li><li>Layer C5：第三个卷积层，得到120个$1\times1$的特征图。卷积核的大小为$5\times5$。因为S4得到的特征图也是$5\times5$。所以得到的输出是1个数。这步相当于全连接。通常我们直接设置全连接层。</li><li>Layer F6：全连接层，设置84个单元。激活函数可以使用Relu。</li><li>Layer F7：输出层，10个单元。根据问题来决定，因为从0-9一共10类。随意设置为10。激活函数使用softmax。</li></ol><p><strong>主要贡献：</strong></p><ul><li>局部感受野(local receptive fields)，局部连接</li><li>权值共享（参数共享）</li><li>下采样(sub-sampling)，pooling层<h4 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h4>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LeNet-5是一个简单的卷积神经网络，相较于传统的神经网络其参数更少，性能也更优。是卷积神经网络的一个开端。最后的损失函数我们使用了均方差损失函数。如果对神经网络有一定的了解，应该可以了解整个神经网络的运行过程。到这里这篇文章就完事了。我们只是为了来记录LeNet-5的网络结构。并没有细讲网络的具体知识。如有不懂，想深入讨论。可以加我联系方式一起学习。<blockquote><p>友情链接：<br>代码实现：<a href="https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch" target="_blank" rel="noopener">https://github.com/guoyuantao/CNN_Model/tree/master/CNN_on_cifar_ByPytorch</a><br>联系方式：2391855138(加好友请备注)</p></blockquote></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 卷积神经网络模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 卷积神经网络 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>周志华《机器学习》读书笔记----第二章：模型评估与选择</title>
      <link href="/2019/09/05/zhou-zhi-hua-ji-qi-xue-xi-du-shu-bi-ji-di-er-zhang-mo-xing-ping-gu-yu-xuan-ze/"/>
      <url>/2019/09/05/zhou-zhi-hua-ji-qi-xue-xi-du-shu-bi-ji-di-er-zhang-mo-xing-ping-gu-yu-xuan-ze/</url>
      
        <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;机器学习要做的工作可以这样理解：给定一些数据，在数据上训练模型，得到能解决我们实际问题的模型。在这个过程中，数据的处理，模型的选择，模型的评估都需要花费一些时间来处理。这节内容就是模型的选择与评估。</p><h4 id="一、经验误差与过拟合"><a href="#一、经验误差与过拟合" class="headerlink" title="一、经验误差与过拟合"></a>一、经验误差与过拟合</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在训练过程中，学习器的实际预测输出与样本的真实输出之间的差异称为<strong>误差</strong>。学习器在训练集上的误差称为<strong>训练误差</strong>或<strong>经验误差</strong>。在新样本上的误差称为<strong>泛化误差</strong>。我们希望得到泛化误差小的学习器。然而我们实际能做的是使经验误差最小化。可惜的是经验误差最小时，泛化误差不一定是最好的。我们希望学习器能从训练样本中尽可能学出适用于所有潜在样本的<strong>普遍规律</strong>。但是有时候学习器的能力过强，将一些样本自身的特点当作了样本的一般性质。导致泛化性能下降，造成<strong>过拟合</strong>现象。还有时学习器的学习能力不够，学习不到样本的潜在规律，会造成<strong>欠拟合</strong>现象。也会使泛化性能下降。因此，我们要解决模型存在的欠拟合或者过拟合现象，提高模型的泛化性能。在实际的问题中，我们可以获得多种学习算法，不同的参数会出现不同的模型。因此，模型的选择就是要对候选模型的泛化误差进行评估，然后选择泛化误差最小的模型。</p><h4 id="二、评估方法"><a href="#二、评估方法" class="headerlink" title="二、评估方法"></a>二、评估方法</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;经验误差由于过拟合问题的存在，不能作为选择模型的标准。又无法直接获得泛化误差。因此，我们通过实验测试来对学习器的泛化误差进行评估，然后做出选择。我们设置一个<strong>测试集</strong>来测试学习器对新样本的判别性能。在测试集上的误差我们称之为<strong>测试误差</strong>。使用测试误差来作为泛化误差的近似。我们假设测试数据也是从真实样本中独立同分布采样得到。要求测试集与训练集要互斥。通常我们可以得到一个包含$m$个样本的数据集D,然后对D进行适当的划分，划分为测试集和训练集。<br>$$D=\left { (x_{1},y_{1}), (x_{2},y_{2}), …,(x_{m},y_{m})\right }$$</p><h5 id="方法一：留出法"><a href="#方法一：留出法" class="headerlink" title="方法一：留出法"></a>方法一：留出法</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>留出法</strong>直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试机T，用数学公式表示为：$D=S\cup T,S\cap T=\varnothing$。在训练集上训练出模型后，在测试集上评估测试误差，作为对泛化误差的估计。例如，包含1000个样本的数据集，S包含700个样本，T包含300个样本。留出法需要注意以下三点：</p><ol><li>划分数据时，要保证数据的一致性。例如1000个样本中包含500个正例，500个反例。如果按照S：70%，T：30%的比例划分。那么对于正例，应该取350个作为S，150个作为T。反例也是如此。这叫保持样本的列别比例相似。假如S、T中的样本类别比例差别很大，则测试估计将由于训练/测试数据分布的差异而产生偏差。</li><li>单次使用留出法得到的估计结果往往不够稳定可靠。因此，可以多次划分，重复实验，取平均值做留出法的评估结果。</li><li>选择训练集与测试集的比例也很重要，一般训练集大约占$\frac{2}{3}\sim \frac{4}{5}$，剩下的样本用作测试集。</li></ol><h5 id="方法二：交叉验证法"><a href="#方法二：交叉验证法" class="headerlink" title="方法二：交叉验证法"></a>方法二：交叉验证法</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>交叉验证法</strong>先将数据集D划分为k个大小相似的互斥子集。即$D=D_{1}\cup D_{2}\cup …\cup D_{k},D_{i}\cap D{j}=\varnothing (i\neq j)$。将前k-1个子集作为训练集，余下的那个子集作为测试集。获得k组训练集/测试集。可以进行k次训练和测试，返回k个测试结果的均值。这种方法一般叫做<strong>k折交叉验证法</strong>。k值是此方法的关键，一般常用的值为5、10、20等。与留出法相同，k折交叉验证法仍然可以重复多次实验，最后取平均值作为最终的评估结果。</p><h5 id="方法三：自助法"><a href="#方法三：自助法" class="headerlink" title="方法三：自助法"></a>方法三：自助法</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>自助法</strong>是让我们可以使用数据集D来训练模型，然而并不是真正意义上的数据集D，只是训练数据集的规模与数据集D相同。留出法与交叉验证法都保留了一些数据用作测试数据。会引入一些因训练样本规模不同而导致的估计偏差。自助法以<strong>自助采样</strong>为基础。自助法从包含m个样本的数据集D中采样得到训练数据集$D^{‘}$。每次从数据集D中抽取一个一样，将其放入到$D^{‘}$中，然后再将该样本放回初始数据集D中，使得样本在下次采样时仍然可以被采到。重复执行m次后，得到包含m个样本的数据集$D^{‘}$。D中会有一部分样本多次出现在$D^{‘}$中，有一部分不会出现在其中。我们可以估计样本在m次采样中始终不被采到的概率为$(1-\frac{1}{m})^{m}$,取极限得到$\underset{m\rightarrow \infty }{lim}(1-\frac{1}{m})^{m}=\frac{1}{e}\approx 0.368$，也就是说数据集D中有36.8%的数据未出现在采样数据$D^{‘}$中，因此，数据集$D^{‘}$作为训练集，$D-D^{‘}$作为测试集。自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，我们常用留出法和交叉验证法。</p><h5 id="方法四：调参与最终模型"><a href="#方法四：调参与最终模型" class="headerlink" title="方法四：调参与最终模型"></a>方法四：调参与最终模型</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;机器学习算法通常涉及两类参数，一类是算法的参数，也就是超参数，数目在10以内，另一类是模型的参数，参数有很多。因此，<strong>调参</strong>是一个重要的任务。通常的做法是给定一个参数取值范围，在其中选取几个值测试模型，选取泛化性能最好的。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们通常把学得模型在实际使用中遇到的数据称为测试集，模型评估与选择中用于评估测试的数据集通常称为<strong>验证集</strong>。因此，用测试集上的判别效果来估计模型在实际应用中的泛化能力，把训练集划分为训练集和测试集，基于验证集上的性能来进行模型选择和调参。</p><h4 id="三、性能度量"><a href="#三、性能度量" class="headerlink" title="三、性能度量"></a>三、性能度量</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了衡量模型的泛化能力，要有一个评价标准，就是性能度量。当我们使用不同的性能度量来对比不同模型的能力时，往往可以得到不同的评判结果。因此，要根据实际问题的需求，使用正确的性能度量来评判模型。给定数据集$D=\left { (x_{1},y_{1}), (x_{2},y_{2}), …,(x_{m},y_{m})\right }$，评估学习器$f$的性能，就需要将预测结果$f(x)$与真实标记$y$进行比较。</p><h5 id="1-均方误差"><a href="#1-均方误差" class="headerlink" title="1. 均方误差"></a>1. 均方误差</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;均方误差是回归任务常用的性能度量。<br>$$<br>E(f;D)=\frac{1}{m}\sum_{i=1}^{m}(f(x_{i})-y_{i})^{2}<br>$$</p><h5 id="2-错误率与精度"><a href="#2-错误率与精度" class="headerlink" title="2. 错误率与精度"></a>2. 错误率与精度</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>错误率</strong>是分类错误的样本数占样本总数的比例，<strong>精度</strong>是分类正确的样本数占样本总数的比例。<br>错误率：<br>$$<br>E(f;D)=\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}(f(x_{i})\neq y_{i})<br>$$<br>精度：<br>$$<br>acc(f;D)=\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}(f(x_{i})=  y_{i})=1-E(f;D)<br>$$</p><h5 id="3-查准率、查全率与F1"><a href="#3-查准率、查全率与F1" class="headerlink" title="3. 查准率、查全率与F1"></a>3. 查准率、查全率与F1</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>查准率</strong>是在所有预测为正例的结果中，真实为正例的比例。<strong>查全率</strong>是所有真实为正例的样本中，预测出为正例所占的比例。查准率与查全率是为了应对我们存在不同需求时的性能度量。二分类问题中，将样例根据真实类别与学习器预测类别的组合划分为真正例(TP)、假正例(FP)、真反例(TN)、假反例(FN)四种情况。<strong>F1</strong>度量是综合考虑了查准率和查全率。</p><table>    <tbody><tr>        <th rowspan="2">真实情况</th>        <th colspan="2">预测结果</th>    </tr>    <tr>        <td>正例</td>        <td>反例</td>    </tr>    <tr>        <td>正例</td>        <td>TP(真正例)</td>        <td>FN(假反例)</td>    </tr>    <tr>        <td>反例</td>        <td>FP(假正例)</td>        <td>TN(真反例)</td>    </tr></tbody></table><p>查准率：<br>$$<br>P=\frac{TP}{TP+FP}<br>$$<br>查全率：<br>$$<br>R=\frac{TP}{TP+FN}<br>$$<br>F1度量：<br>$$<br>F1=\frac{2\times P\times R}{R+P}<br>$$</p><h5 id="4-ROC与AUC"><a href="#4-ROC与AUC" class="headerlink" title="4. ROC与AUC"></a>4. ROC与AUC</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>ROC</strong>的全称是“受试者工作特征”曲线，ROC曲线的纵轴是“真正例率”(TPR)，横轴是“假正例率”(FPR)。<br>TPR：<br>$$<br>TPR=\frac{TP}{TP+FN}<br>$$<br>FPR:<br>$$<br>FPR=\frac{FP}{FP+TN}<br>$$</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>AUC</strong>代表的是ROC曲线与坐标轴围成的面积。</p><h5 id="5-代价敏感错误率与代价曲线"><a href="#5-代价敏感错误率与代价曲线" class="headerlink" title="5. 代价敏感错误率与代价曲线"></a>5. 代价敏感错误率与代价曲线</h5><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在现实的任务中，不同类型的错误所造成的后果不同。为了权衡不同类型错误所造成的不同损失，可以为错误赋予<strong>非均等代价</strong>。以二分类为例，设定一个代价矩阵，其中$cost_{ij}$表示将第i类样本预测为第j类样本的代价。一般来说，$cost_{ii}=0$.若将第0类判别为第1类所造成的损失更大。则$cost_{01}&gt;cost_{10}$。</p><table>    <tbody><tr>        <th rowspan="2">真实类别</th>        <th colspan="2">预测类别</th>    </tr>    <tr>        <td>第0类</td>        <td>第1类</td>    </tr>    <tr>        <td>第0类</td>        <td>0</td>        <td>cost01</td>    </tr>    <tr>        <td>第1类</td>        <td>cost10</td>        <td>0</td>    </tr></tbody></table><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在非均等代价下，我们希望最小化总体代价。将第0类作为正类，第1类作为反类。令$D^{+}$与$D^{-}$分别代表数据D的正例子集和反例子集。则<strong>代价敏感错误率</strong>为<br>$$<br>E(f;D;cost)=\frac{1}{m}(\sum_{x_{i}\in D^{+}}\mathbb{I}(f(x_{i}\neq y_{i})\times cost_{01}+\sum_{x_{i}\in D^{-}}\mathbb{I}(f(x_{i}\neq y_{i})\times cost_{10})<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在非均等代价下，ROC曲线不能直接反应出学习器的期望总体代价，我么可以使用<strong>代价曲线</strong>。代价曲线的横轴取值为$[0,1]$的正例概率代价：<br>$$<br>P(+)cost=\frac{p\times cost_{01}}{p\times cost_{01}+(1-p)\times cost_{10}}<br>$$<br>p代表样例为正例的概率。纵轴是取值为[0,1]的归一化代价：<br>$$<br>cost_{norm}=\frac{FNR\times p\times cost_{01}+FPR\times (1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}}<br>$$</p><h4 id="四、比较检验"><a href="#四、比较检验" class="headerlink" title="四、比较检验"></a>四、比较检验</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先使用某种实验的评估方法测得学习器的某个性能度量结果，然后对这些结果进行比较选择模型。但是，怎么进行比较，在机器学习中的性能比较涉及几个重要因素：</p><ol><li>我们得到的是在测试集上的性能，我们希望比较的是泛化性能。那测试性能是否可以代表泛化性能。</li><li>测试性能因测试数据本身的选择有关系，测试集的大小和测试集样例不同，都会影响到测试的性能。</li><li>机器学习算法本身存在随机性，即使参数相同，结果也不相同。</li></ol><p>这些因此，造成了我们比较学习器的性能时，就不能只进行普通的比较。<strong>统计假设检验</strong>为我们进行学习器的性能比较提供了重要依据。<font color="red">基于假设检验结果我们可推断出，若在测试集上观察到学习器A比B好，则A的泛化性能是否在统计意义上优于B，以及这个结论的把握有多大。</font>简单的说就是如果测试集上的性能A好于B，那么是否就可以说A的泛化性能好于B。对于这个结论有多大的可能认为是正确的。<br>常用的假设检验方法：</p><ul><li>假设检验</li><li>t检验</li><li>交叉验证t检验</li></ul><p>常用的性能比较方法：</p><ul><li>McNemar检验</li><li>Friedman检验与Nemenyi后续检验</li></ul><h5 id="1-偏差与方差"><a href="#1-偏差与方差" class="headerlink" title="1. 偏差与方差"></a>1. 偏差与方差</h5><p>我们试图理解学习算法为什么具有这样的性能，<strong>偏差-方差分解</strong>是解释学习算法泛化性能的一种重要工具。偏差-方差分解试图对学习算法的期望泛化错误率进行拆解。测试样本$x$。$x$在数据集中的标记为$y_{D}$，$x$的真实标记$y$。$f(x;D)$为模型的输出结果。<strong>偏差</strong>度量了学习算法的期望预测与真实结果的偏离程度，刻画了算法的本身拟合能力。<strong>方差</strong>度量了同样大小的训练集的变动所导致的学习性能的变化，刻画了数据扰动所造成的影响。<strong>噪声</strong>表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界。刻画了问题的本身难度。<br>学习算法的期望预测：$\overline{f}(x)=E_{D}[f(x;D)]$<br>样本数相同的不同训练集产生的方差：$var(x)=E_{D}[(f(x;D)-\overline{f}(x))^{2}]$<br>噪声：$\varepsilon^{2}=E_{D}[(y_{D}-y)^{2}]$<br>偏差：$bias^{2}(x)=(\overline{f}(x)-y)^{2}$<br>算法的<strong>期望泛化误差</strong>：<br>$$<br>E(f;D)=bias^{2}(x)+var(x)+\varepsilon ^{2}<br>$$<br>期望泛化误差可以分解为偏差、方差和噪声之和。因此，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 周志华《机器学习》 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 读书笔记 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI圣经《深度学习》读书笔记----第二章：线性代数</title>
      <link href="/2019/08/21/ai-sheng-jing-shen-du-xue-xi-du-shu-bi-ji-di-er-zhang-xian-xing-dai-shu/"/>
      <url>/2019/08/21/ai-sheng-jing-shen-du-xue-xi-du-shu-bi-ji-di-er-zhang-xian-xing-dai-shu/</url>
      
        <content type="html"><![CDATA[<blockquote><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;线性代数是数学的一个分支，应用于科学和工程中。线性代数主要是面向连续数学，而非离散数学。掌握好线性代数对于学习机器学习算法是必要的，尤其是深度学习算法。因此，本章学习必要的线性代数知识。</p></blockquote><h4 id="知识点一：标量、向量、矩阵和张量"><a href="#知识点一：标量、向量、矩阵和张量" class="headerlink" title="知识点一：标量、向量、矩阵和张量"></a>知识点一：标量、向量、矩阵和张量</h4><p><strong>标量(scalar)：</strong> 一个标量就是一个单独的数，不同于线性代数中研究的其他大部分对象。当介绍标量时，会明确标量的类型。<br><strong>向量(vector)：</strong> 一个向量是一列数。这些数是有序排列的，通过次序的索引，可以得到每个单独的数。表示为</p><p>$$<br>x =<br>\begin{pmatrix}<br>x_{1}\<br>x_{2}\<br>\vdots\<br>x_{n}\<br>\end{pmatrix}<br>$$<br><strong>矩阵(matrix)：</strong> 矩阵是一个二维数组，其中的每一个元素由两个索引确定。一个2行2列的矩阵表示为<br>$$<br>A =<br>\begin{pmatrix}<br>A_{1,1}&amp;A_{1,2}\<br>A_{2,1}&amp;A_{2,2}\<br>\end{pmatrix}<br>$$<br><strong>张量(tensor)：</strong> 某些情况下，会讨论坐标超过两维的数组。一般地，一个数组中的元素分布在若干维坐标的规则网格中，我们称之为张量。<br><strong>转置：</strong> 矩阵的转置是以对角线为轴的镜像。从左上角到右下角的对角线称为主对角线。表示为$(A^T)<em>{i,j}=A</em>{j,i}$。向量可看作是只有一列的矩阵，那么向量的转置就是只有一行的矩阵。标量的转置等于其本身。</p><h4 id="知识点二：矩阵的运算"><a href="#知识点二：矩阵的运算" class="headerlink" title="知识点二：矩阵的运算"></a>知识点二：矩阵的运算</h4><p> <strong>矩阵相加：</strong> 当矩阵形状相同时，矩阵对应位置的元素相加，表示为$C_{i,j}=A_{i,j}+B_{i,j}$。<br> <strong>标量和矩阵相加或相乘：</strong> 只需将标量与矩阵的每个元素相乘或相加。表示为$D_{i,j}=a<em>B_{i,j}+c$<br> *</em>矩阵和向量相加：** 就是将向量和矩阵的每一行相加。表示为$C_{i,j}=A_{i,j}+b_{j}$。这种方法类似于将向量展开成一个与矩阵同维度的矩阵，然后在相加。这种方式称为<strong>广播。</strong><br> <strong>矩阵相乘：</strong> 矩阵A和B相乘，矩阵A的列数必须和矩阵B的行数相等。表示为$C_{i,j}=\sum A_{i,k}B_{k,j}$。还有一种是矩阵元素对应乘积，也就是对应元素的乘积。</p><h4 id="知识点三：单位矩阵、逆矩阵和特殊类型的矩阵与向量"><a href="#知识点三：单位矩阵、逆矩阵和特殊类型的矩阵与向量" class="headerlink" title="知识点三：单位矩阵、逆矩阵和特殊类型的矩阵与向量"></a>知识点三：单位矩阵、逆矩阵和特殊类型的矩阵与向量</h4><p> <strong>单位矩阵：</strong> 对角线为1，其他位置为0的矩阵，单位矩阵与任何向量相乘，都不会改变。<br>$$<br>A =<br>\begin{pmatrix}<br>A_{1,1}&amp;A_{1,2}\<br>A_{2,1}&amp;A_{2,2}\<br>\end{pmatrix}<br>$$<br><strong>逆矩阵：</strong> 矩阵A的逆矩阵记作$A^{-1}$，满足$A^{-1}A=I_{n}$。<br><strong>对角矩阵：</strong> 对角矩阵是在主对角线上含有非零元素，其他位置都为零。对角矩阵的逆矩阵就是将对角线元素取倒数。<br><strong>对称矩阵：</strong> 矩阵是转置和自己相等的矩阵。即$A=A^T$。<br><strong>单位向量：</strong> 是具有单位范数的向量。即$||x||_{2}=1$。<br><strong>正交矩阵：</strong> 指行向量和列向量是分别标准正交的方阵。标准正交是矩阵中的行向量或者列向量两两相乘等于0，并且范数为1.正交矩阵满足：<br>$$<br>A^TA=AA^T=I<br>$$<br>$$<br>A^{-1}=A^T<br>$$</p><h4 id="知识点四：范数"><a href="#知识点四：范数" class="headerlink" title="知识点四：范数"></a>知识点四：范数</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;范数是用来衡量向量的大小，形式上，$L^p$范数可以定义为<br>$$<br>||x||<em>{p}=(\sum</em>{i} |x_{i}|^p)^{\frac{1}{p}}<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，$p\geq1$。范数是将向量映射到非负值的函数。x的范数可以理解为衡量从原点到点x的距离。范数需要满足如下性质：</p><ul><li>$f(x)=0=&gt;x=0$</li><li>$f(x+y)\leq f(x)+f(y)$</li><li>$\forall \alpha \in \mathbb{R}f(\alpha x)=\left | \alpha  \right |f(x)$</li><li><em>$L^2$范数：*</em> 又叫欧几里得范数，表示从原点到向量x的欧几里得距离。常用来衡量向量的大小。计算公式为：<br>$$<br>\left | x \right |<em>{2}=\left | x \right |=\sqrt{\sum</em>{i}x_{i}^{2}}<br>$$</li><li><em>$L^{1}$范数：*</em> 当问题中，零和非零元素之间的差异非常重要时，使用$L^1$范数。表示为<br>$$<br>\left | x \right |<em>{1}=\sum</em>{i}\left | x_{i} \right |<br>$$</li><li><em>$L^0$范数：*</em> 统计向量中非零元素的个数来衡量向量的大小。但是非零元素的数目并不是范数，因为对向量进行缩放，非零元素的个数不变。因此，使用$L^1$范数替代。</li><li><em>$L^{\propto }$范数：*</em> 也叫最大范数。表示向量中具有最大幅值的元素的绝对值。表示为<br>$$<br>\left | x \right |<em>{\propto }=\underset{i}{max}\left | x \right |</em>{i}<br>$$</li><li><em>Frobenius范数：*</em> 用来衡量矩阵的大小。表示为<br>$$<br>\left | A \right |<em>{F}=\sqrt{\sum</em>{i,j}A^{2}_{i,j} }<br>$$<h4 id="知识点五：特征值分解与奇异值分解"><a href="#知识点五：特征值分解与奇异值分解" class="headerlink" title="知识点五：特征值分解与奇异值分解"></a>知识点五：特征值分解与奇异值分解</h4></li><li><em>特征分解：*</em> 是将矩阵分解为一组特征向量和特征值。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;方阵A的特征向量是指与A相乘后相当于对该向量进行缩放的非零向量。表示为<br>$$<br>Av=\lambda v<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，$\lambda$为特征值，v为特征向量。我们将特征向量连接成一个矩阵，使得每一列是一个特征向量：$V=\left { v^{(1)},v^{(2)},…,v^{(3)} \right }$。同样，可以将一个特征值连接成一个向量$\lambda =\left [ \lambda _{1},…,\lambda _{n} \right ]$。因此，A的<strong>特征分解</strong>可以记作<br>$$A=Vdiag(\lambda )V^{-1}$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;并不是所有的矩阵都是可以特征分解的。所有特征值都是正数的矩阵称为正定。</li><li><em>奇异值分解(SVD)：*</em> 将矩阵分解为奇异向量和奇异值。每个实数矩阵都有一个奇异值分解。但是不一定存在特征值分解。奇异值分解可将矩阵A分解为<br>$$<br>A=UDV^{T}<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，A是一个$m\times n$的矩阵，U是一个$m\times m$的矩阵，D是一个$m\times n$的矩阵，V是一个$n\times n$的矩阵。矩阵U和V都是正交矩阵。D是对角矩阵。但不一定是方阵，D的对角线上的元素是矩阵A的奇异值。矩阵U的列向量是左奇异向量，矩阵V的列向量是右奇异向量。<h4 id="知识点六：Moore-Penrose伪逆"><a href="#知识点六：Moore-Penrose伪逆" class="headerlink" title="知识点六：Moore-Penrose伪逆"></a>知识点六：Moore-Penrose伪逆</h4>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当矩阵是非方阵时，是没有逆矩阵的。当我们求解线性方程$Ax=y$时。使用A的逆矩阵$A^{-1}$来求解。得到<br>$$<br>x = A^{-1}y<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，如果矩阵A的行数大于列数，那么上述方程没有解。如果矩阵A的行数小于列数，那么上述方程可能有多个解。因此，我们使用Moore-Penrose伪逆解决这个问题。矩阵A的伪逆定义为<br>$$<br>A^{+}=\underset{\alpha \rightarrow 0}{lim}(A^{T}A+\alpha I)^{-1}A^{T}<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，我们使用如下公式计算<br>$$<br>A^{+}=VD^{+}U^{T}<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，U、D和V时矩阵A奇异值分解后得到的矩阵。对角矩阵D的伪逆$D^+$是其非零元素取倒数之后在转置得到的。使用伪逆求得的x使得Ax和y的欧几里得距离最小。<h4 id="知识点七：迹运算和行列式"><a href="#知识点七：迹运算和行列式" class="headerlink" title="知识点七：迹运算和行列式"></a>知识点七：迹运算和行列式</h4></li><li><em>迹运算：*</em> 返回的是矩阵对角元素的和<br>$$<br>Tr(A)=\sum_{i}A_{i,i}<br>$$<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们可以使用矩阵的迹运算，描述很多运算</li><li>Frobennins范数：$\left | A \right |_{F}=\sqrt{Tr(AA^{T})}$</li><li>迹运算在转置运算下是不变的：$Tr(A)=Tr(A^{T})$</li><li>多个矩阵相乘得到的方阵的迹。等于把矩阵中最后一个挪到最前面之后相乘的迹：$Tr(ABC)=Tr(CAB)=Tr(BCA)$</li><li>循环置换后矩阵乘积得到的矩阵形状改变，但是迹运算的结果不变:$Tr(AB)=Tr(BA)$</li><li>标量在迹运算后仍是自己：$a=Tr(a)$</li></ul><p><strong>行列式：</strong> 记作$det(A)$，是一个将方阵A映射到实数的函数。行列式等于矩阵特征值的乘积。用来衡量矩阵参与矩阵乘法后空间扩大或者缩小了多少。如果为0，那么空间至少沿着某一维完全收缩。失去了所有的体积。如果行列式是1。则转换空间保持不变。</p><h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;线性代数在机器学习中扮演着重要的角色。因此，了解线性代数的知识是必要的。本章只是介绍了线性代数的一些基本知识。如果有精力，还需要仔细学习线性代数的知识。</p><blockquote><p>友情链接：<br>github主页：<a href="https://github.com/guoyuantao" target="_blank" rel="noopener">https://github.com/guoyuantao</a><br>CSDN博客：<a href="https://blog.csdn.net/gyt15663668337" target="_blank" rel="noopener">https://blog.csdn.net/gyt15663668337</a><br>个人博客主页：<a href="https://guoyuantao.github.io/">https://guoyuantao.github.io/</a><br>QQ讨论群：218803539</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI圣经《深度学习》读书笔记----第一章：引言</title>
      <link href="/2019/08/15/ai-sheng-jing-shen-du-xue-xi-du-shu-bi-ji-di-yi-zhang-yin-yan/"/>
      <url>/2019/08/15/ai-sheng-jing-shen-du-xue-xi-du-shu-bi-ji-di-yi-zhang-yin-yan/</url>
      
        <content type="html"><![CDATA[<blockquote><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这本书从我开始学习深度学习时，就买了这本书。但是，因为自身知识储备不够，觉得这本书很难。多次想学习这本书，但是都失败了。距离本次学习，已经时隔一年。希望这次能将这本书看完，学习书中的知识。并通过博客的方式，记录自己学习的过程和对知识进行总结。</p></blockquote><h3 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所谓的人工智能就是让机器具有智能，能像人类一样处理事务。具有人的智能。目前，人工智能已经成为一个具有众多实际应用和活跃研究课题的领域，并这在蓬勃发展，我们希望通过智能软件自动地处理常规劳动、理解语音或图像、帮助医学诊断和支持基础科学研究。在人工智能的早期，那些对人类智力来说比较困难，但对计算机来说很简单的问题得到迅速解决。比如说可以用一系列形式化的数学规则来描述的问题。然而，<font color="red" size="3">人工智能真正的挑战是解决那些对人类来说很容易做到，但是很难形式化的任务。</font>例如，识别图像中的物体。本书给出一种解决方案，该方案可以让计算机从经验中学习，并根据层次化的概念体系来理解世界，而每个概念则通过与某些相对简单的概念之间的关系来定义。我们称这种方法为 <strong>AI深度学习</strong>。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;人工智能的一个关键挑战就是如何一些非形式化的知识传达给计算机。一些人工智能项目将关于世界得知识用形式化的语言进行硬编码。然后计算机可以通过逻辑推理规则自动地理解这些形式化语言中的声明。这就是众所周知的<strong>知识库</strong>方法。但是这些声明是人类监督者输入的，它没有足够的形式化规则来精确地描述世界。因此，AI系统具备自己获取知识的能力，<font color="red" size="3">即从原始数据从提取模式的能力。</font>这种能力叫做<strong>机器学习</strong>。机器学习算法的性能依赖于<strong>数据的表示</strong>。例如一个称为逻辑回归的简单算法，用它判断产妇是否适合剖腹产时，AI系统不能直接检查患者，需要医生给出患者的相关信息。表示患者的每条信息称为一个特征。<font color="red" size="3">逻辑回归学习病人的这些特征如何与各种结果相关联。</font>因此，表示的选择对机器学习算法的性能产生巨大的影响。许多问题都是先提取一个合适的特征集，然后将这些特征提供给简单的机器学习算法。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，提取特征来说是一件很难的事情，依靠人类来说，并不知道应该提取那些特征。因此，解决这个问题的途径是使用机器学习来发掘表示的本身，而不仅仅是把表示映射到输出，这种方法我们称为<strong>表示学习</strong>。<font color="red" size="3">学习到的表示往往比手动设计的表示表现的更好。</font>表示学习的典型例子是自编码器，自编码器由一个编码器和一个解码器组成。编码器函数就是将输入数据转换为一种不同的表示。当设计特征或设计用于学习特征的算法时，我们的目标是分离出能解释观察数据的<strong>变差因素</strong>。这些因素不能被直接观察到的量，但会影响可观测的量。有时具有多个变差因素时，会影响到我们观察到的每个数据。而<strong>深度学习</strong>通过其他较简单的表示来表达复杂表示，解决了表示学习中的核心问题。深度学习让计算机通过简单的概念构造复杂的概念。典型例子是多层感知器。它是一个将一组输入映射到输出值的数学函数。该函数由许多简单的函数复合而成。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;深度学习是通向人工智能的途径之一，是机器学习的一种，能够使计算机系统从经验和数据中得到提高的技术。<font color="red" size="3">深度学习是一种特定类型的机器学习，具有强大的能力和灵活性，它将大千世界表示为嵌套的层次概念体系(由简单概念间的联系定义复杂概念、从一般抽象概括到高级抽象表示。</font><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用维恩图表示深度学习的关系。<br><img src="https://img-blog.csdnimg.cn/20190815195543929.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_8,color_FFFFFF,t_70" alt=""><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下图展示AI系统在不同的AI学科中彼此相关，阴影框表示能从数据中学习的组件。<br><img src="https://img-blog.csdnimg.cn/20190815201143926.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d5dDE1NjYzNjY4MzM3,size_16,color_FFFFFF,t_70" alt=""></p><h3 id="二、深度学习的发展"><a href="#二、深度学习的发展" class="headerlink" title="二、深度学习的发展"></a>二、深度学习的发展</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;人工智能的历史要追溯到1956年的达特茅斯会议，其实早在这之前就提过。只是达特茅斯会议算是一个正式的提出。有兴趣研究人工智能历史的可以去读《人工智能简史》这本书。深度学习的历史可以总结为经历了3次发展浪潮。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>20世界40年代到60年代，</strong> 深度学习的雏形出现在控制论中。随着生物学习理论的发展和一个模型的实现，能实现单个神经元的训练。感知机是第一个能根据每个类别的输入样本来学习权重的模型，在同一时期，自适应线性单元简单地返回函数f(x)本身的值来预测一个实数，并且它还可以学习从数据预测这些数。基于感知机和自适应线性单元中使用的函数f(x,w)的模型称为线性模型。但是这种线性模型存在局限性，最著名的是无法解决异或问题。这也导致了神经网络热潮的第一次大衰退。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>20世纪80年代到90年代</strong>，深度学习表现为联结主义。联结主义在认知科学的背景下出现的。认知科学是理解思维的跨学科途径，即它融合多个不同的分析层次。20世纪80年代初期，大多数认知科学家研究符号推理模型。但符号模型很难解释大脑如何真正使用神经元实现推理功能。联结主义者开始研究真正基于神经系统实现的认知模型。<font color="red" size="3">联结主义的中心思想是，当网络将大量简单的计算单元连接在一起时可以实现智能行为。</font>其中一个概念是分布式表示，思想是：系统的每一个输入都应该由多个特征表示，并且每一个特征都应该参与到多个可能输入的表示。联结主义潮流的另一个重要成就是反向传播在训练具有内部表示的深度神经网络中的成功使用以及反向传播算法的普及。神经网络的第二次浪潮一直持续到20世纪90年代中期，由于基于神经网络的深度学习并不能满足应用的需要，而同时其他机器学习方法取得了进步。这两个因素导致了神经网络浪潮的第二次衰退。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>2006年至今，</strong> 人工智能的第三次浪潮在2006年，以深度学习之名复兴。起因是Geoffrey Hinton大神名为“深度信念网络”的神经网络可以使用一种“贪婪逐层预训练”的策略有效地训练。从此，深度学习的浪潮一直持续至今。第三次浪潮开始着眼于新的无监督学习技术和深度模型在小数据集的泛化能力。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目前，深度学习的发展已经为人类的生活带来了很多应用。如在人脸识别，目标检测，机器翻译，语言识别等。深度学习的发展伴随着三个方面的发展。**一是，数据量的增大。二是，模型的规模变大。三是，精度的提高以及对现实世界的影响。深度学习能发展的这么好，也是因为数据量的增大，深度学习的模型是基于数据的。从MNIST到ImageNet。数据越来越大。<font color="red" size="3">截止2016年，一个经验法则是，监督深度学习算法在每类给定约5000个标注样本情况下一般将达到可以接受的性能，当至少有1000万个标注样本的数据集用于训练时，它将到达或超过人类表现。</font>。随着数据的增加。深度学习模型的规模也在增加，体现在参数的增加。人工神经网络的规模大概每2.4年增加一倍。但是与人类的神经元还是差很多。这也意味着计算机的计算能力要增加。最后，随着数据和模型的进化，带来的是实际问题上精度的提高。可以将一些模型应用到实际的问题中，解决实际的生活问题。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;深度学习的发展解决了现实生活中的实际问题，为我们的生活带来了方便。也让我们看到了人工智能的曙光。未来的很长时间。深度学习都将是主要的研究方向。</p><blockquote><p>友情链接：<br>github主页：<a href="https://github.com/guoyuantao" target="_blank" rel="noopener">https://github.com/guoyuantao</a><br>CSDN博客：<a href="https://blog.csdn.net/gyt15663668337" target="_blank" rel="noopener">https://blog.csdn.net/gyt15663668337</a><br>个人博客主页：<a href="https://guoyuantao.github.io/">https://guoyuantao.github.io/</a><br>QQ讨论群：218803539</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----比较操作</title>
      <link href="/2019/07/14/pytorch-xue-xi-zhi-torch-bi-jiao-cao-zuo-comparison-ops/"/>
      <url>/2019/07/14/pytorch-xue-xi-zhi-torch-bi-jiao-cao-zuo-comparison-ops/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-eq-input-other-out-None"><a href="#1-torch-eq-input-other-out-None" class="headerlink" title="1. torch.eq(input, other, out=None)"></a>1. torch.eq(input, other, out=None)</h3><p><strong>说明：</strong> 比较元素是否相等，第二个参数可以是一个数，或者是第一个参数同类型形状的张量</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 待比较张量</li><li>other(Tenosr or float) —- 比较张量或者数</li><li>out(Tensor,可选的) —- 输出张量</li></ul><p><strong>返回值：</strong> 一个torch.ByteTensor张量，包含了每个位置的比较结果(相等为1，不等为0)</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="2-torch-equal-tensor1-tensor2-out-None"><a href="#2-torch-equal-tensor1-tensor2-out-None" class="headerlink" title="2. torch.equal(tensor1, tensor2, out=None)"></a>2. torch.equal(tensor1, tensor2, out=None)</h3><p><strong>说明：</strong> 如果两个张量有相同的形状和元素值，则返回true，否则False</p><p><strong>参数：</strong></p><ul><li>tensor1(Tenosr) —- 比较张量1</li><li>tensor2(Tensor) —- 比较张量2</li><li>out(Tensor,可选的) —- 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token boolean">True</span></code></pre><h3 id="3-torch-ge-input-other-out-None"><a href="#3-torch-ge-input-other-out-None" class="headerlink" title="3. torch.ge(input, other, out=None)"></a>3. torch.ge(input, other, out=None)</h3><p><strong>说明：</strong> 逐元素比较input和other，即是否input &gt;= other。</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 待对比的张量</li><li>other(Tensor or float) —- 对比的张量或float值</li><li>out(Tensor,可选的) —- 输出张量，</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>ge<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="4-torch-gt-input-other-out-None"><a href="#4-torch-gt-input-other-out-None" class="headerlink" title="4. torch.gt(input, other, out=None)"></a>4. torch.gt(input, other, out=None)</h3><p><strong>说明：</strong> 逐元素比较input和other，即是否input &gt; other</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 要对比的张量</li><li>other(Tensor or float) —- 要对比的张量或float值</li><li>out(Tensor,可选的) —- 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>gt<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="5-torch-kthvalue-input-k-dim-None-out-None"><a href="#5-torch-kthvalue-input-k-dim-None-out-None" class="headerlink" title="5. torch.kthvalue(input, k, dim=None, out=None)"></a>5. torch.kthvalue(input, k, dim=None, out=None)</h3><p><strong>说明：</strong> 取输入张量input指定维度上第k个最小值。如果不指定dim。默认为最后一维。返回一个元组(value, indices), 其中indices是原始输入张量中沿dim维的第k个最小值下标。</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 要对比的张量</li><li>k(int) —- 第k个最小值</li><li>dim(int, 可选的) —- 沿着此维度进行排序</li><li>out(tuple,可选的) —- 输出元组</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>kthvalue<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>kthvalue<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>kthvalue<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>kthvalue<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-le-input-other-out-None"><a href="#6-torch-le-input-other-out-None" class="headerlink" title="6. torch.le(input, other, out=None)"></a>6. torch.le(input, other, out=None)</h3><p><strong>说明：</strong> 逐元素比较input和other，即是否input &lt;= other.</p><p><strong>参数：</strong></p><ul><li>input(Tenosr) —- 要对比的张量</li><li>other(Tensor or float) —- 对比的张量或float值</li><li>out(Tensor,可选的) —- 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>le<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="7-torch-lt-input-other-out-None"><a href="#7-torch-lt-input-other-out-None" class="headerlink" title="7.   torch.lt(input, other, out=None)"></a>7.   torch.lt(input, other, out=None)</h3><p><strong>说明：</strong> 逐元素比较input和other，即是否input &lt; other</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 要对比的张量</li><li>other(Tensor or float) —- 对比的张量或float值</li><li>out(Tensor,可选的) —- 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>lt<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="8-torch-max-input"><a href="#8-torch-max-input" class="headerlink" title="8. torch.max(input)"></a>8. torch.max(input)</h3><p><strong>说明：</strong> 返回输入张量所有元素的最大值</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.1553</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4140</span><span class="token punctuation">,</span>  <span class="token number">1.8393</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">1.8393</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-max-input-dim-max-None-max-indices-None"><a href="#9-torch-max-input-dim-max-None-max-indices-None" class="headerlink" title="9. torch.max(input, dim, max=None, max_indices=None)"></a>9. torch.max(input, dim, max=None, max_indices=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度上每行的最大值，并同时返回每个最大值的位置索引。</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 指定的维度</li><li>max(Tensor,可选的) —- 结果张量，包含给定维度上的最大值</li><li>max_indices(LongTensor,可选的) —- 结果张量，包含给定维度上每个最大值的位置的索引。</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.4067</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7722</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6560</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9621</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8754</span><span class="token punctuation">,</span>  <span class="token number">0.0282</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7947</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1870</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.4300</span><span class="token punctuation">,</span>  <span class="token number">0.5444</span><span class="token punctuation">,</span>  <span class="token number">0.3180</span><span class="token punctuation">,</span>  <span class="token number">1.2647</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.0775</span><span class="token punctuation">,</span>  <span class="token number">0.5886</span><span class="token punctuation">,</span>  <span class="token number">0.1662</span><span class="token punctuation">,</span>  <span class="token number">0.8986</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>max<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.4067</span><span class="token punctuation">,</span> <span class="token number">0.0282</span><span class="token punctuation">,</span> <span class="token number">1.2647</span><span class="token punctuation">,</span> <span class="token number">0.8986</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-max-input-other-out-None"><a href="#10-torch-max-input-other-out-None" class="headerlink" title="10. torch.max(input, other, out=None)"></a>10. torch.max(input, other, out=None)</h3><p><strong>说明：</strong> 返回两个元素的最大值。</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 待比较张量</li><li>other(Tensor) —- 比较张量</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.5767</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0841</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0942</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9405</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6375</span><span class="token punctuation">,</span>  <span class="token number">1.4165</span><span class="token punctuation">,</span>  <span class="token number">0.2738</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8996</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.5767</span><span class="token punctuation">,</span>  <span class="token number">1.4165</span><span class="token punctuation">,</span>  <span class="token number">0.2738</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8996</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-min-input"><a href="#11-torch-min-input" class="headerlink" title="11.torch.min(input)"></a>11.torch.min(input)</h3><p><strong>说明：</strong> 返回输入张量所有元素的最小值</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8142</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9847</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3637</span><span class="token punctuation">,</span>  <span class="token number">0.5191</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>min<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.9847</span><span class="token punctuation">)</span></code></pre><h3 id="12-torch-min-input-dim-min-None-min-indices-None"><a href="#12-torch-min-input-dim-min-None-min-indices-None" class="headerlink" title="12. torch.min(input, dim, min=None, min_indices=None)"></a>12. torch.min(input, dim, min=None, min_indices=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度上每行的最小值，并同时返回每个最小值的位置索引</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 指定的维度</li><li>min(Tensor,可选的) —- 结果张量，包含给定维度上的最小值</li><li>min_indices(LongTensor,可选的) —- 结果张量，包含给定维度上每个最小值的位置索引。</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0243</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7382</span><span class="token punctuation">,</span>  <span class="token number">0.3102</span><span class="token punctuation">,</span>  <span class="token number">0.9720</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3805</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7999</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2856</span><span class="token punctuation">,</span>  <span class="token number">0.2657</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0284</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1638</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8840</span><span class="token punctuation">,</span>  <span class="token number">1.2679</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0347</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.3428</span><span class="token punctuation">,</span>  <span class="token number">0.3107</span><span class="token punctuation">,</span>  <span class="token number">1.0575</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>min<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>min<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7382</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2856</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0284</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.3428</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="13-torch-ne-input-other-out-None"><a href="#13-torch-ne-input-other-out-None" class="headerlink" title="13. torch.ne(input, other, out=None)"></a>13. torch.ne(input, other, out=None)</h3><p><strong>说明：</strong> 逐元素比较input和other，即是否input 不等于 other。第二个参数可以为一个数或与第一个参数相同形状和类型的张量</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 待对比的张量</li><li>other(Tensor or float) —- 对比的张量或float值</li><li>out(Tensor, 可选的) —- 输出张量</li></ul><p>** 返回值：** 一个torch.ByteTensor 张量，包含了每个位置的比较结果，如果tensor和other不相等为True，返回1.</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> torch<span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>ne<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="14-torch-sort-input-dim-None-descending-False-out-None"><a href="#14-torch-sort-input-dim-None-descending-False-out-None" class="headerlink" title="14. torch.sort(input, dim=None, descending=False, out=None)"></a>14. torch.sort(input, dim=None, descending=False, out=None)</h3><p><strong>说明：</strong> 对输入张量input沿指定维度按升序排序，如果不给定dim，则默认为输入的最后一维。如果指定参数descending为True，则按降序排序。</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 要排序的张量</li><li>dim(int,可选的) —- 沿着此维度排序</li><li>descending(bool,可选的) —- 布尔值，控制升序排序</li><li>out(tuple,可选的) —- 输出张量</li></ul><p><strong>返回值：</strong> 为ByteTensor类型或与tensor相同类型，为元组(sorted_tensor,sorted_indices)，sorted_indices为原始输入中的下标</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3613</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2583</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4276</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.3106</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.1577</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7505</span><span class="token punctuation">,</span>  <span class="token number">1.7217</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6247</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1338</span><span class="token punctuation">,</span>  <span class="token number">0.4423</span><span class="token punctuation">,</span>  <span class="token number">0.0280</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4796</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> sorted<span class="token punctuation">,</span> indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> sortedtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.3106</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4276</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3613</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2583</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.1577</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7505</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6247</span><span class="token punctuation">,</span>  <span class="token number">1.7217</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4796</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1338</span><span class="token punctuation">,</span>  <span class="token number">0.0280</span><span class="token punctuation">,</span>  <span class="token number">0.4423</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> indicestensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="15-torch-topk-input-dim-None-largest-True-sorted-True-out-None"><a href="#15-torch-topk-input-dim-None-largest-True-sorted-True-out-None" class="headerlink" title="15. torch.topk(input, dim=None, largest=True, sorted=True, out=None)"></a>15. torch.topk(input, dim=None, largest=True, sorted=True, out=None)</h3><p><strong>说明：</strong> 沿指定dim维度返回输入张量input中k个最大值。如果不指定dim，则默认input的最后一维，如果largest为False，则返回最小的k个值。</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>k(int) —- “top-k”中的k值</li><li>dim(int,可选的) —- 排序的维度</li><li>largest(bool,可选的) —- 布尔值，控制返回最大或最小值</li><li>sorted(bool,可选的) —- 布尔值，控制返回值是否排序</li><li>out(tuple,可选的) —- 可选输出张量</li></ul><p><strong>返回值：</strong> 返回一个元组(values, indices)，其中indices是原始输入张量input中排序元素下标。如果设定布尔值sorted为True，将会确保返回的k个值被排序</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> largest<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----Reduction Ops</title>
      <link href="/2019/07/14/pytorch-xue-xi-zhi-torch-reduction-ops/"/>
      <url>/2019/07/14/pytorch-xue-xi-zhi-torch-reduction-ops/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-cumprod-input-dim-out-None"><a href="#1-torch-cumprod-input-dim-out-None" class="headerlink" title="1. torch.cumprod(input, dim, out=None)"></a>1. torch.cumprod(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入沿指定维度的累积积。如果输入是一个N元向量，则结果也是一个N元向量，第i个输出元素值为 $$y_{i} = x_{1} * x_{2} * … * x_{i}$$</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 累积积操作的维度</li><li>out(Tensor,可选) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> torch<span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ret <span class="token operator">=</span> torch<span class="token punctuation">.</span>cumprod<span class="token punctuation">(</span>b<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> rettensor<span class="token punctuation">(</span><span class="token punctuation">[</span>  <span class="token number">1</span><span class="token punctuation">,</span>   <span class="token number">2</span><span class="token punctuation">,</span>   <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ret1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cumprod<span class="token punctuation">(</span>b<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ret1tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2-torch-cumsum-input-dim-out-None"><a href="#2-torch-cumsum-input-dim-out-None" class="headerlink" title="2. torch.cumsum(input, dim, out=None)"></a>2. torch.cumsum(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入沿指定维度的累积和。例如，如果输入是一个N元向量，则结果也是一个N元向量，第i个输出元素的值为$$y_{i} = x_{1} + x_{2} + … + x_{i}$$</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 累积和操作的维度</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ret <span class="token operator">=</span> torch<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>b<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> rettensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="3-torch-dist-input-other-p-2-out-None"><a href="#3-torch-dist-input-other-p-2-out-None" class="headerlink" title="3. torch.dist(input, other, p=2, out=None)"></a>3. torch.dist(input, other, p=2, out=None)</h3><p><strong>说明：</strong> 返回(input - other) 的p范数</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 左侧输入张量</li><li>other(Tensor) —- 右侧输入张量</li><li>p(float,可选的) —- 所计算的范数</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1559</span><span class="token punctuation">,</span> <span class="token number">0.7725</span><span class="token punctuation">,</span> <span class="token number">0.8706</span><span class="token punctuation">,</span> <span class="token number">0.3684</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ytensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.1464</span><span class="token punctuation">,</span>  <span class="token number">0.4444</span><span class="token punctuation">,</span>  <span class="token number">1.7968</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.3197</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>dist<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">2.1900</span><span class="token punctuation">)</span></code></pre><h3 id="4-torch-mean-input"><a href="#4-torch-mean-input" class="headerlink" title="4. torch.mean(input)"></a>4. torch.mean(input)</h3><p><strong>说明：</strong> 返回输入张量所有元素的均值</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.0543</span><span class="token punctuation">,</span>  <span class="token number">1.6074</span><span class="token punctuation">,</span>  <span class="token number">0.2915</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.0518</span><span class="token punctuation">)</span></code></pre><h3 id="5-torch-mean-input-dim-out-None"><a href="#5-torch-mean-input-dim-out-None" class="headerlink" title="5. torch.mean(input, dim, out=None)"></a>5. torch.mean(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度dim上每行的均值。</p><p><strong>参数：</strong></p><ul><li>inptu(Tensor) —- 输入张量</li><li>dim(int) —- 操作的维度</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.2351</span><span class="token punctuation">,</span>  <span class="token number">0.7531</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2863</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8551</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.2716</span><span class="token punctuation">,</span>  <span class="token number">1.0863</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.0343</span><span class="token punctuation">,</span>  <span class="token number">1.9529</span><span class="token punctuation">,</span>  <span class="token number">1.4611</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.9935</span><span class="token punctuation">,</span>  <span class="token number">0.5430</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1580</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.2340</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6801</span><span class="token punctuation">,</span>  <span class="token number">1.1494</span><span class="token punctuation">,</span>  <span class="token number">0.7928</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.6019</span><span class="token punctuation">,</span> <span class="token number">0.2444</span><span class="token punctuation">,</span> <span class="token number">0.2758</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-median-input-dim-1-values-None-indices-None"><a href="#6-torch-median-input-dim-1-values-None-indices-None" class="headerlink" title="6. torch.median(input, dim=-1, values=None, indices=None)"></a>6. torch.median(input, dim=-1, values=None, indices=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度每行中的中位数，同时返回一个包含中位数的索引的LongTensor。dim值默认为输入张量的最后一维。<br><strong>注意：</strong> 这个函数没有在torch.cuda.Tensor中定义</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 缩减的维度</li><li>values(Tensor,可选的) —- 结果张量</li><li>indices(Tensor,可选的) —- 返回的索引结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2479</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4734</span><span class="token punctuation">,</span>  <span class="token number">0.1368</span><span class="token punctuation">,</span>  <span class="token number">0.9601</span><span class="token punctuation">,</span>  <span class="token number">2.9435</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.3210</span><span class="token punctuation">,</span>  <span class="token number">0.8147</span><span class="token punctuation">,</span>  <span class="token number">0.3052</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6380</span><span class="token punctuation">,</span>  <span class="token number">0.0879</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.9500</span><span class="token punctuation">,</span>  <span class="token number">0.0926</span><span class="token punctuation">,</span>  <span class="token number">0.6948</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9723</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2437</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7056</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4905</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2469</span><span class="token punctuation">,</span>  <span class="token number">0.3753</span><span class="token punctuation">,</span>  <span class="token number">1.6451</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>median<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>median<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.1368</span><span class="token punctuation">,</span>  <span class="token number">0.3052</span><span class="token punctuation">,</span>  <span class="token number">0.0926</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2469</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-mode-input-dim-1-values-None-indices-None"><a href="#7-torch-mode-input-dim-1-values-None-indices-None" class="headerlink" title="7. torch.mode(input, dim=-1, values=None, indices=None)"></a>7. torch.mode(input, dim=-1, values=None, indices=None)</h3><p><strong>说明：</strong> 返回给定维dim上，每行的众数值，同时返回一个LongTensor，包含众数的索引。dim默认为输入张量的最后一维。<br><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 缩减的维度</li><li>values(Tensor,可选的) —- 结果的张量</li><li>indices(Tensor,可选的) —- 返回的索引张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.2427</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2035</span><span class="token punctuation">,</span>  <span class="token number">0.0828</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9490</span><span class="token punctuation">,</span>  <span class="token number">0.8610</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5330</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0207</span><span class="token punctuation">,</span>  <span class="token number">1.2805</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2771</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1151</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.2495</span><span class="token punctuation">,</span>  <span class="token number">0.6887</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1247</span><span class="token punctuation">,</span>  <span class="token number">1.3126</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4973</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.3097</span><span class="token punctuation">,</span>  <span class="token number">0.1821</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9910</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0591</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.0153</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0525</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0337</span><span class="token punctuation">,</span>  <span class="token number">1.2929</span><span class="token punctuation">,</span>  <span class="token number">1.4164</span><span class="token punctuation">,</span>  <span class="token number">1.3975</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>mode<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>mode<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.2427</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0207</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2495</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.0153</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0525</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-norm-input-p-2"><a href="#8-torch-norm-input-p-2" class="headerlink" title="8. torch.norm(input, p=2)"></a>8. torch.norm(input, p=2)</h3><p><strong>说明：</strong> 返回输入张量input的p范数</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li><li>p(float,可选的) —- 范数计算中的幂指数值</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.5397</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4304</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7689</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">1.9158</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-norm-input-p-dim-out-None"><a href="#9-torch-norm-input-p-dim-out-None" class="headerlink" title="9. torch.norm(input, p, dim, out=None)"></a>9. torch.norm(input, p, dim, out=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度dim上每行的p范数。<br><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>p(float) —- 范数计算中的幂指数值</li><li>dim(int) —- 缩减的维度</li><li>out(Tenosr,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3436</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6034</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2127</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0089</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.7678</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0787</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.9961</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2598</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.6944</span><span class="token punctuation">,</span> <span class="token number">0.2129</span><span class="token punctuation">,</span> <span class="token number">2.0709</span><span class="token punctuation">,</span> <span class="token number">1.0294</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-prod-input"><a href="#10-torch-prod-input" class="headerlink" title="10. torch.prod(input)"></a>10. torch.prod(input)</h3><p><strong>说明：</strong> 返回输入张量input所有元素的积</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-prod-input-dim-out-None"><a href="#11-torch-prod-input-dim-out-None" class="headerlink" title="11. torch.prod(input, dim, out=None)"></a>11. torch.prod(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度上每行的积。<br><strong>参数：</strong> </p><ul><li>input(Tenosr) —- 输入张量</li><li>dim(int) —- 缩减的维度</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0593</span><span class="token punctuation">,</span>  <span class="token number">0.3449</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0491</span><span class="token punctuation">,</span>  <span class="token number">0.2711</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.4155</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1968</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6646</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9474</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.0205</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0133</span><span class="token punctuation">,</span>  <span class="token number">0.4972</span><span class="token punctuation">,</span>  <span class="token number">0.6296</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0008</span><span class="token punctuation">,</span>  <span class="token number">0.1060</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="12-torch-std-input"><a href="#12-torch-std-input" class="headerlink" title="12. torch.std(input)"></a>12. torch.std(input)</h3><p><strong>说明：</strong> 返回输入张量input所有元素的标准差<br><strong>参数：</strong> </p><ul><li>inut(Tensor) —- 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2022</span><span class="token punctuation">,</span>  <span class="token number">1.9407</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1263</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>std<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">1.2159</span><span class="token punctuation">)</span></code></pre><h3 id="13-torch-std-input-dim-out-None"><a href="#13-torch-std-input-dim-out-None" class="headerlink" title="13. torch.std(input, dim, out=None)"></a>13. torch.std(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度上每行的标准差。<br><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) </li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.3646</span><span class="token punctuation">,</span>  <span class="token number">0.9681</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7199</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>std<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">0.8554</span><span class="token punctuation">)</span></code></pre><h3 id="14-torch-std-input-dim-out-None"><a href="#14-torch-std-input-dim-out-None" class="headerlink" title="14. torch.std(input, dim, out=None)"></a>14. torch.std(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入给定维度上每行的标准差。</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 缩减的维度</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.4083</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.0872</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.7175</span><span class="token punctuation">,</span>  <span class="token number">0.4151</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1804</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.9027</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6310</span><span class="token punctuation">,</span>  <span class="token number">0.3519</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1215</span><span class="token punctuation">,</span>  <span class="token number">0.5891</span><span class="token punctuation">,</span>  <span class="token number">0.1468</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2249</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.3558</span><span class="token punctuation">,</span>  <span class="token number">1.2970</span><span class="token punctuation">,</span>  <span class="token number">0.1988</span><span class="token punctuation">,</span>  <span class="token number">0.1279</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>std<span class="token punctuation">(</span>a<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.6449</span><span class="token punctuation">,</span> <span class="token number">0.9626</span><span class="token punctuation">,</span> <span class="token number">0.3633</span><span class="token punctuation">,</span> <span class="token number">0.6725</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="15-torch-sum-input"><a href="#15-torch-sum-input" class="headerlink" title="15. torch.sum(input)"></a>15. torch.sum(input)</h3><p><strong>说明：</strong> 返回输入张量input所有元素的和。</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.7710</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9921</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2817</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3.0449</span><span class="token punctuation">)</span></code></pre><h3 id="16-torch-sum-input-dim-out-None"><a href="#16-torch-sum-input-dim-out-None" class="headerlink" title="16. torch.sum(input, dim, out=None)"></a>16. torch.sum(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度上每行的和，</p><p><strong>参数：</strong></p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 缩减的维度</li><li>out(Tensor, 可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6091</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5861</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2564</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3686</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7146</span><span class="token punctuation">,</span>  <span class="token number">0.7276</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7998</span><span class="token punctuation">,</span>  <span class="token number">0.5817</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.7700</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7373</span><span class="token punctuation">,</span>  <span class="token number">0.1708</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0295</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">2.2606</span><span class="token punctuation">,</span>  <span class="token number">1.9379</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7269</span><span class="token punctuation">,</span>  <span class="token number">0.7523</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.8202</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2051</span><span class="token punctuation">,</span>  <span class="token number">0.1741</span><span class="token punctuation">,</span>  <span class="token number">4.2239</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.7069</span><span class="token punctuation">,</span>  <span class="token number">1.3422</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.6123</span><span class="token punctuation">,</span>  <span class="token number">0.9359</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="17-torch-var-input"><a href="#17-torch-var-input" class="headerlink" title="17. torch.var(input)"></a>17. torch.var(input)</h3><p><strong>说明：</strong> 返回输入张量所有元素的方差</p><p><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7134</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1119</span><span class="token punctuation">,</span>  <span class="token number">1.0638</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0858</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>var<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">0.9016</span><span class="token punctuation">)</span></code></pre><h3 id="18-torch-var-input-dim-out-None"><a href="#18-torch-var-input-dim-out-None" class="headerlink" title="18. torch.var(input, dim, out=None)"></a>18. torch.var(input, dim, out=None)</h3><p><strong>说明：</strong> 返回输入张量给定维度上每行的方差</p><p><strong>参数：</strong> </p><ul><li>input(Tensor) —- 输入张量</li><li>dim(int) —- 缩减维度</li><li>out(Tensor,可选的) —- 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0977</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2619</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3367</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5301</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.8751</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2703</span><span class="token punctuation">,</span>  <span class="token number">1.2129</span><span class="token punctuation">,</span>  <span class="token number">0.5508</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.1301</span><span class="token punctuation">,</span>  <span class="token number">0.6452</span><span class="token punctuation">,</span>  <span class="token number">0.5054</span><span class="token punctuation">,</span>  <span class="token number">0.3386</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.2502</span><span class="token punctuation">,</span>  <span class="token number">1.4547</span><span class="token punctuation">,</span>  <span class="token number">1.0562</span><span class="token punctuation">,</span>  <span class="token number">0.4640</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>var<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0322</span><span class="token punctuation">,</span> <span class="token number">0.4036</span><span class="token punctuation">,</span> <span class="token number">0.1161</span><span class="token punctuation">,</span> <span class="token number">0.3031</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----数学操作(三)</title>
      <link href="/2019/06/23/pytorch-xue-xi-zhi-torch-shu-xue-cao-zuo-san/"/>
      <url>/2019/06/23/pytorch-xue-xi-zhi-torch-shu-xue-cao-zuo-san/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-reciprocal-input-out-None"><a href="#1-torch-reciprocal-input-out-None" class="headerlink" title="1. torch.reciprocal(input, out=None)"></a>1. torch.reciprocal(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的倒数。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.6535</span><span class="token punctuation">,</span>  <span class="token number">1.3616</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.6167</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0142</span><span class="token punctuation">,</span>  <span class="token number">0.0186</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>reciprocal<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>  <span class="token number">1.5303</span><span class="token punctuation">,</span>   <span class="token number">0.7345</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">0.6186</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">70.6554</span><span class="token punctuation">,</span>  <span class="token number">53.8015</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2-torch-remainder-input-divisor-out-None"><a href="#2-torch-remainder-input-divisor-out-None" class="headerlink" title="2. torch.remainder(input, divisor, out=None)"></a>2. torch.remainder(input, divisor, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的除法余数。除数与被除数可能同时包含整数或浮点数，余数与除数有相同的符号<br><strong>参数：</strong></p><ul><li>input(Tensor) – 被除数</li><li>divisor(Tensor or float) – 除数，一个数或者与除数相同大小的张量</li><li>out(Tensor，可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>remainder<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="3-torch-round-input-out-None"><a href="#3-torch-round-input-out-None" class="headerlink" title="3. torch.round(input, out=None)"></a>3. torch.round(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，将输入input张量每个元素舍入到最近的整数<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>round<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="4-torch-rsqrt-input-out-None"><a href="#4-torch-rsqrt-input-out-None" class="headerlink" title="4. torch.rsqrt(input, out=None)"></a>4. torch.rsqrt(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的平方根倒数。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选0 – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.0934</span><span class="token punctuation">,</span>  <span class="token number">0.2079</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4841</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.2004</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>rsqrt<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.2716</span><span class="token punctuation">,</span> <span class="token number">2.1930</span><span class="token punctuation">,</span>    nan<span class="token punctuation">,</span>    nan<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="5-torch-sigmoid-input-out-None"><a href="#5-torch-sigmoid-input-out-None" class="headerlink" title="5. torch.sigmoid(input, out=None)"></a>5. torch.sigmoid(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的sigmoid值<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.6220</span><span class="token punctuation">,</span>  <span class="token number">0.4341</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5248</span><span class="token punctuation">,</span>  <span class="token number">0.8342</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.6507</span><span class="token punctuation">,</span> <span class="token number">0.6068</span><span class="token punctuation">,</span> <span class="token number">0.3717</span><span class="token punctuation">,</span> <span class="token number">0.6973</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-sign-input-out-None"><a href="#6-torch-sign-input-out-None" class="headerlink" title="6. torch.sign(input, out=None)"></a>6. torch.sign(input, out=None)</h3><p><strong>说明：</strong> 符号函数，返回一个新张量，包含输入input张量每个元素的正负<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.1224</span><span class="token punctuation">,</span>  <span class="token number">0.6647</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3843</span><span class="token punctuation">,</span>  <span class="token number">1.2878</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sign<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-sin-input-out-None"><a href="#7-torch-sin-input-out-None" class="headerlink" title="7. torch.sin(input, out=None)"></a>7. torch.sin(input, out=None)</h3><p><strong>说明：</strong>返回一个新张量，包含输入input张量每个元素的正弦。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8258</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8077</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5048</span><span class="token punctuation">,</span>  <span class="token number">0.9997</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-sinh-input-out-None"><a href="#8-torch-sinh-input-out-None" class="headerlink" title="8. torch.sinh(input, out=None)"></a>8. torch.sinh(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的双曲正弦<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.1792</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0052</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2577</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1537</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sinh<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.4722</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1833</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2605</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1543</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-sqrt-input-out-None"><a href="#9-torch-sqrt-input-out-None" class="headerlink" title="9. torch.sqrt(input, out=None)"></a>9. torch.sqrt(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的平方根<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.3252</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8610</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1563</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2361</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5703</span><span class="token punctuation">,</span>    nan<span class="token punctuation">,</span>    nan<span class="token punctuation">,</span>    nan<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-tan-input-out-None"><a href="#10-torch-tan-input-out-None" class="headerlink" title="10. torch.tan(input, out=None)"></a>10. torch.tan(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的正切。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.4005</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2229</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4596</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7481</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>tan<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.4233</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2267</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">8.9521</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9280</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-tanh-input-out-None"><a href="#11-torch-tanh-input-out-None" class="headerlink" title="11. torch.tanh(input, out=None)"></a>11. torch.tanh(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的双曲正切<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2677</span><span class="token punctuation">,</span>  <span class="token number">0.7824</span><span class="token punctuation">,</span>  <span class="token number">0.0271</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0853</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="12-torch-trunc-input-out-None"><a href="#12-torch-trunc-input-out-None" class="headerlink" title="12. torch.trunc(input, out=None)"></a>12. torch.trunc(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入张量每个元素的截断值（标量x的截断值是最接近其的整数）<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1385</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7681</span><span class="token punctuation">,</span>  <span class="token number">0.4294</span><span class="token punctuation">,</span>  <span class="token number">0.4270</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>trunc<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----数学操作(二)</title>
      <link href="/2019/06/23/pytorch-xue-xi-zhi-torch-shu-xue-cao-zuo-er/"/>
      <url>/2019/06/23/pytorch-xue-xi-zhi-torch-shu-xue-cao-zuo-er/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-floor-input-out-None"><a href="#1-torch-floor-input-out-None" class="headerlink" title="1. torch.floor(input, out=None)"></a>1. torch.floor(input, out=None)</h3><p><strong>说明：</strong> 床函数，返回一个新张量，包含输入input张量每个元素的floor，即不小于元素的最大整数。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tenosr, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2-torch-fmod-input-divisor-out-None"><a href="#2-torch-fmod-input-divisor-out-None" class="headerlink" title="2. torch.fmod(input, divisor, out=None)"></a>2. torch.fmod(input, divisor, out=None)</h3><p><strong>说明：</strong> 计算除法余数。除数与被除数可能同时含有整数和浮点数。此时，余数的正负与被除数相同<br><strong>参数：</strong></p><ul><li>input(Tensor) – 被除数</li><li>divisor(Tensor或float) –  除数，一个数或与被除数相同类型的张量</li><li>out(Tensor，可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>fmod<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>fmod<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token number">0.5000</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token number">0.5000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="3-torch-frac-tensor-out-None"><a href="#3-torch-frac-tensor-out-None" class="headerlink" title="3. torch.frac(tensor, out=None)"></a>3. torch.frac(tensor, out=None)</h3><p><strong>说明：</strong> 返回每个元素的分数部分<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 输入张量，可以是小数也可是整数</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>frac<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2.3</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.0000</span><span class="token punctuation">,</span>  <span class="token number">0.3000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="4-torch-lerp-start-end-weight-out-None"><a href="#4-torch-lerp-start-end-weight-out-None" class="headerlink" title="4. torch.lerp(start, end, weight, out=None)"></a>4. torch.lerp(start, end, weight, out=None)</h3><p><strong>说明：</strong> 对两个张量以start，end做线性插值，将结果返回到输出张量。即out = start + weight * (end - start).<br><strong>参数：</strong></p><ul><li>start(Tensor) – 起始点张量</li><li>end(Tensor) – 终止点张量</li><li>weight(float) – 插值公式的weight</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> start <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> end <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> starttensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> endtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>lerp<span class="token punctuation">(</span>start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5.5000</span><span class="token punctuation">,</span> <span class="token number">6.0000</span><span class="token punctuation">,</span> <span class="token number">6.5000</span><span class="token punctuation">,</span> <span class="token number">7.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="5-torch-log-input-out-None"><a href="#5-torch-log-input-out-None" class="headerlink" title="5. torch.log(input, out=None)"></a>5. torch.log(input, out=None)</h3><p><strong>说明：</strong> 计算input的自然对数<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.1601</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8747</span><span class="token punctuation">,</span>  <span class="token number">0.2048</span><span class="token punctuation">,</span>  <span class="token number">1.8377</span><span class="token punctuation">,</span>  <span class="token number">0.2801</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>    nan<span class="token punctuation">,</span>     nan<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.5856</span><span class="token punctuation">,</span>  <span class="token number">0.6085</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2725</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-log1p-input-out-None"><a href="#6-torch-log1p-input-out-None" class="headerlink" title="6. torch.log1p(input, out=None)"></a>6. torch.log1p(input, out=None)</h3><p><strong>说明：</strong> 计算input+1的自然对数，对值比较小的输入，此函数比torch.log()更准确<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.4177</span><span class="token punctuation">,</span>  <span class="token number">0.7744</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.8840</span><span class="token punctuation">,</span>  <span class="token number">0.3302</span><span class="token punctuation">,</span>  <span class="token number">1.7383</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1667</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>log1p<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.3490</span><span class="token punctuation">,</span>  <span class="token number">0.5735</span><span class="token punctuation">,</span>     nan<span class="token punctuation">,</span>  <span class="token number">0.2854</span><span class="token punctuation">,</span>  <span class="token number">1.0073</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1824</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-mul-input-value-out-None"><a href="#7-torch-mul-input-value-out-None" class="headerlink" title="7. torch.mul(input, value, out=None)"></a>7. torch.mul(input, value, out=None)</h3><p><strong>说明：</strong> 用标量值value乘以输入input的每个元素，并返回一个新的结果张量。out = tensor * value<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>value(Number) – 乘到每个元素的数</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.7720</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8593</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0354</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0747</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">177.2037</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">85.9287</span><span class="token punctuation">,</span>   <span class="token operator">-</span><span class="token number">3.5436</span><span class="token punctuation">,</span>   <span class="token operator">-</span><span class="token number">7.4714</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-mul-input-other-out-None"><a href="#8-torch-mul-input-other-out-None" class="headerlink" title="8. torch.mul(input, other, out=None)"></a>8. torch.mul(input, other, out=None)</h3><p><strong>说明：</strong> 两个张量input，other按元素进行相乘，并返回输出张量<br><strong>参数：</strong></p><ul><li>input(Tensor) – 第一个相乘张量</li><li>other(Tensor) – 第二个相乘张量</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.1404</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3859</span><span class="token punctuation">,</span>  <span class="token number">1.9077</span><span class="token punctuation">,</span>  <span class="token number">0.7873</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.5376</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7447</span><span class="token punctuation">,</span>  <span class="token number">1.6224</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3152</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0610</span><span class="token punctuation">,</span>  <span class="token number">0.2805</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0194</span><span class="token punctuation">,</span>  <span class="token number">0.4091</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0842</span><span class="token punctuation">,</span>  <span class="token number">0.1382</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1696</span><span class="token punctuation">,</span>  <span class="token number">0.0576</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-neg-input-out-None"><a href="#9-torch-neg-input-out-None" class="headerlink" title="9. torch.neg(input, out=None)"></a>9. torch.neg(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量按元素取负。out = -1 * input<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.8791</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5795</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1354</span><span class="token punctuation">,</span>  <span class="token number">0.4425</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1631</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>neg<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8791</span><span class="token punctuation">,</span>  <span class="token number">0.5795</span><span class="token punctuation">,</span>  <span class="token number">1.1354</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4425</span><span class="token punctuation">,</span>  <span class="token number">0.1631</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-pow-input-exponent-out-None"><a href="#10-torch-pow-input-exponent-out-None" class="headerlink" title="10. torch.pow(input, exponent, out=None)"></a>10. torch.pow(input, exponent, out=None)</h3><p><strong>说明：</strong> 对输入input按元素求exponent次幂值，并返回结果张量，幂值exponent可以为标量也可以是和input相同大小的张量。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>exponent(float or Tensor) – 幂值</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2202</span><span class="token punctuation">,</span>  <span class="token number">0.0814</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0079</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7530</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4.8492e-02</span><span class="token punctuation">,</span> <span class="token number">6.6341e-03</span><span class="token punctuation">,</span> <span class="token number">6.1897e-05</span><span class="token punctuation">,</span> <span class="token number">5.6697e-01</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-pow-base-input-out-None"><a href="#11-torch-pow-base-input-out-None" class="headerlink" title="11. torch.pow(base, input, out=None)"></a>11. torch.pow(base, input, out=None)</h3><p><strong>说明：</strong> base为标量浮点值，input为张量，返回的输出张量out与输出张量相同形状。执行操作<br><strong>参数：</strong></p><ul><li>base(float) – 标量值，指数的底</li><li>input(Tensor) – 幂值</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> exp <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> base <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>base<span class="token punctuation">,</span> exp<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----数学操作(一)</title>
      <link href="/2019/06/23/pytorch-xue-xi-zhi-torch-shu-xue-cao-zuo-yi/"/>
      <url>/2019/06/23/pytorch-xue-xi-zhi-torch-shu-xue-cao-zuo-yi/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-abs-input-out-None"><a href="#1-torch-abs-input-out-None" class="headerlink" title="1. torch.abs(input, out=None)"></a>1. torch.abs(input, out=None)</h3><p><strong>说明：</strong> 计算输入张量的每个元素绝对值<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(可选) – 输出</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> torch<span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2-torch-acos-input-out-None"><a href="#2-torch-acos-input-out-None" class="headerlink" title="2. torch.acos(input, out=None)"></a>2. torch.acos(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入张量每个元素的反余弦。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">2.5609</span><span class="token punctuation">,</span>  <span class="token number">0.1132</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5844</span><span class="token punctuation">,</span>  <span class="token number">0.0257</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>acos<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>   nan<span class="token punctuation">,</span> <span class="token number">1.4573</span><span class="token punctuation">,</span> <span class="token number">2.1950</span><span class="token punctuation">,</span> <span class="token number">1.5451</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="3-torch-add-input-value-out-None"><a href="#3-torch-add-input-value-out-None" class="headerlink" title="3. torch.add(input, value, out=None)"></a>3. torch.add(input, value, out=None)</h3><p><strong>说明：</strong> 对输入张量input逐元素加上标量值value，并返回到一个新的张量out。即out = tensor + value。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>value(Number) – 添加到输入每个元素的数</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.6450</span><span class="token punctuation">,</span>  <span class="token number">0.8491</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2552</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1404</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">20.6450</span><span class="token punctuation">,</span> <span class="token number">20.8491</span><span class="token punctuation">,</span> <span class="token number">19.7448</span><span class="token punctuation">,</span> <span class="token number">19.8596</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">9.8</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10.4450</span><span class="token punctuation">,</span> <span class="token number">10.6491</span><span class="token punctuation">,</span>  <span class="token number">9.5448</span><span class="token punctuation">,</span>  <span class="token number">9.6596</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="4-torch-add-input-value-other-out-None"><a href="#4-torch-add-input-value-other-out-None" class="headerlink" title="4. torch.add(input, value, other, out=None)"></a>4. torch.add(input, value, other, out=None)</h3><p><strong>说明：</strong> other张量的每个元素乘以以标量值value，并加到input张量上，返回结果到输出张量out。即out = input + (other * value)。形状需要匹配。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 第一个输入张量</li><li>value(Number) – 用于第二个张量的尺寸因子</li><li>other(Tensor) – 第二个输入张量</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0692</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1224</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.6475</span><span class="token punctuation">,</span>  <span class="token number">2.0617</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5094</span><span class="token punctuation">,</span>  <span class="token number">0.4380</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3469</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8634</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5.1634</span><span class="token punctuation">,</span>  <span class="token number">3.2573</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">5.1164</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">6.5726</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="5-torch-addcdiv-tensor-value-1-tensor1-tensor2-out-None"><a href="#5-torch-addcdiv-tensor-value-1-tensor1-tensor2-out-None" class="headerlink" title="5. torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None)"></a>5. torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None)</h3><p><strong>说明：</strong> 用tensor2对tensor1逐元素相除，然后乘以标量值value，并加到tensor。张量的形状需要匹配。我实验过形状不匹配时，会报错。<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 张量，对tensor1./tensor2进行相加</li><li>value(number) – 标量，对tensor1./tensor2进行相除</li><li>tensor1(Tensor) – 张量，作为被除数(分子)</li><li>tensor2(Tensor) – 张量，作为除数(分母)</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> t <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> t2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>addcdiv<span class="token punctuation">(</span>t<span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.8583</span><span class="token punctuation">,</span>  <span class="token number">2.1763</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5981</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.2156</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3442</span><span class="token punctuation">,</span>  <span class="token number">1.3631</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-addcmul-tensor-value-1-tensor1-tensor2-out-None"><a href="#6-torch-addcmul-tensor-value-1-tensor1-tensor2-out-None" class="headerlink" title="6. torch.addcmul(tensor, value=1, tensor1, tensor2, out=None)"></a>6. torch.addcmul(tensor, value=1, tensor1, tensor2, out=None)</h3><p><strong>说明：</strong> 用tensor2对tensor1逐元素相乘，并对结果乘以标量值value然后加到tensor。张量的形状需要匹配的。<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 张量，对tensor1*tensor2进行相加</li><li>value(Number) – 标量，对tensor1，tensor2进行相乘</li><li>tensor1(Tensor) – 张量，作为乘子1</li><li>tensor2(Tensor) – 张量，作为乘子2</li><li>out(Tensor， 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> t <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> t2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>addcmul<span class="token punctuation">(</span>t<span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0198</span><span class="token punctuation">,</span>  <span class="token number">1.0696</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2039</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8555</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9452</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2066</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-asin-input-out-None"><a href="#7-torch-asin-input-out-None" class="headerlink" title="7. torch.asin(input, out=None)"></a>7. torch.asin(input, out=None)</h3><p><strong>说明：</strong> 返回一个张量，包含输入input张量每个元素的反正弦函数<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 输入张量</li><li>out(Tensor，可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.0829</span><span class="token punctuation">,</span>  <span class="token number">0.3976</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7801</span><span class="token punctuation">,</span>  <span class="token number">1.1426</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>asin<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>    nan<span class="token punctuation">,</span>  <span class="token number">0.4089</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8948</span><span class="token punctuation">,</span>     nan<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-atan-input-out-None"><a href="#8-torch-atan-input-out-None" class="headerlink" title="8. torch.atan(input, out=None)"></a>8. torch.atan(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的反正切函数。<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 输入张量</li><li>out(Tensor, optional) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>atan<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.4967</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6854</span><span class="token punctuation">,</span>  <span class="token number">0.8361</span><span class="token punctuation">,</span>  <span class="token number">1.0014</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-atan2-input1-input2-out-None"><a href="#9-torch-atan2-input1-input2-out-None" class="headerlink" title="9. torch.atan2(input1, input2, out=None)"></a>9. torch.atan2(input1, input2, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含两个输入张量input1和input2的反正切函数<br><strong>参数：</strong></p><ul><li>input1(Tensor) – 第一个输入张量</li><li>input2(Tensor) – 第二个输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>atan2<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.8779</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.7628</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.9384</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4760</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-ceil-input-out-None"><a href="#10-torch-ceil-input-out-None" class="headerlink" title="10. torch.ceil(input, out=None)"></a>10. torch.ceil(input, out=None)</h3><p><strong>说明：</strong> 天井函数，对输入input张量每个元素向上取整，即取不小于每个元素的最小整数。并返回结果到输出<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7592</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8455</span><span class="token punctuation">,</span>  <span class="token number">1.2844</span><span class="token punctuation">,</span>  <span class="token number">1.4402</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-clamp-input-min-max-out-None"><a href="#11-torch-clamp-input-min-max-out-None" class="headerlink" title="11. torch.clamp(input, min, max, out=None)"></a>11. torch.clamp(input, min, max, out=None)</h3><p><strong>说明：</strong> 将输入input张量每个元素的夹紧到区间[min,max]，并返回结果到一个新张量。对小于min的值，令其等于min，大于max的值等于max。其他值仍等于原值。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>min(Numberi) – 限制范围下限</li><li>max(Number) – 限制范围上限</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.8579</span><span class="token punctuation">,</span>  <span class="token number">0.4232</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1166</span><span class="token punctuation">,</span>  <span class="token number">1.1509</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>a<span class="token punctuation">,</span> min<span class="token operator">=</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> max<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5000</span><span class="token punctuation">,</span>  <span class="token number">0.4232</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1166</span><span class="token punctuation">,</span>  <span class="token number">0.5000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="12-torch-clamp-input-min-out-None"><a href="#12-torch-clamp-input-min-out-None" class="headerlink" title="12. torch.clamp(input, *, min, out=None)"></a>12. torch.clamp(input, *, min, out=None)</h3><p><strong>说明：</strong> 将输入input张量每个元素的限制都不小于min，并返回结果到一个新张量。如果输入是FloatTensor或DoubleTensor类型，则参数min必须为实数，否则须为整数。经过实验得知。无论输入类型，皆可。<br><strong>参数：</strong></p><ul><li>input(Tenosr) – 输入张量</li><li>min(Number) – 限制范围下限</li><li>out(Tenosr,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.6551</span><span class="token punctuation">,</span>  <span class="token number">0.6760</span><span class="token punctuation">,</span>  <span class="token number">2.2335</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7242</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0403</span><span class="token punctuation">,</span>  <span class="token number">0.7974</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>a<span class="token punctuation">,</span> min<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.6551</span><span class="token punctuation">,</span> <span class="token number">0.6760</span><span class="token punctuation">,</span> <span class="token number">2.2335</span><span class="token punctuation">,</span> <span class="token number">0.5000</span><span class="token punctuation">,</span> <span class="token number">0.5000</span><span class="token punctuation">,</span> <span class="token number">0.7974</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="13-torch-clamp-input-max-out-None"><a href="#13-torch-clamp-input-max-out-None" class="headerlink" title="13. torch.clamp(input, *, max, out=None)"></a>13. torch.clamp(input, *, max, out=None)</h3><p><strong>说明：</strong> 将输入input张量每个元素的限制到不大于max，并返回结果到一个新张量。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>max(Number) – 限制范围上限</li><li>out(Tenosr, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.9049</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.5959</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2436</span><span class="token punctuation">,</span>  <span class="token number">0.2380</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5851</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>a<span class="token punctuation">,</span> max<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.9049</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.5959</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2436</span><span class="token punctuation">,</span>  <span class="token number">0.2380</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5851</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="14-torch-cos-input-out-None"><a href="#14-torch-cos-input-out-None" class="headerlink" title="14. torch.cos(input, out=None)"></a>14. torch.cos(input, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的余弦。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tenosr,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5251</span><span class="token punctuation">,</span>  <span class="token number">1.2806</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0669</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2035</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.8653</span><span class="token punctuation">,</span> <span class="token number">0.2861</span><span class="token punctuation">,</span> <span class="token number">0.9978</span><span class="token punctuation">,</span> <span class="token number">0.9794</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="15-torch-cosh-input-out-None"><a href="#15-torch-cosh-input-out-None" class="headerlink" title="15. torch.cosh(input, out=None)"></a>15. torch.cosh(input, out=None)</h3><p><strong>说明：</strong>返回一个新张量，包含输入input张量每个元素的双曲余弦<br><strong>参数：</strong></p><ul><li>input(Tenosr) – 输入张量</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.6999</span><span class="token punctuation">,</span>  <span class="token number">0.4897</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0476</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4528</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>cosh<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.2551</span><span class="token punctuation">,</span> <span class="token number">1.1223</span><span class="token punctuation">,</span> <span class="token number">1.6008</span><span class="token punctuation">,</span> <span class="token number">1.1043</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="16-torch-div-input-value-out-None"><a href="#16-torch-div-input-value-out-None" class="headerlink" title="16. torch.div(input, value, out=None)"></a>16. torch.div(input, value, out=None)</h3><p><strong>说明：</strong> 将input逐元素除以标量值value，并返回结果到输出张量out。<br><strong>参数：</strong></p><ul><li>input(Tenosr) – 输入张量</li><li>value(Number) – 除数</li><li>out(Tenosr,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.1755</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7143</span><span class="token punctuation">,</span>  <span class="token number">2.1232</span><span class="token punctuation">,</span>  <span class="token number">0.4559</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.3207</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>div<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">2.3510</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4286</span><span class="token punctuation">,</span>  <span class="token number">4.2465</span><span class="token punctuation">,</span>  <span class="token number">0.9119</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.6414</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="17-torch-div-input-other-out-None"><a href="#17-torch-div-input-other-out-None" class="headerlink" title="17. torch.div(input, other, out=None)"></a>17. torch.div(input, other, out=None)</h3><p><strong>说明：</strong> 两张量input和other逐元素相除，并将结果返回到输出。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 张量(分子)</li><li>other(Tensor) – 张量(分母)</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.6808</span><span class="token punctuation">,</span>  <span class="token number">1.1017</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1122</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.9604</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1047</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9544</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2481</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9300</span><span class="token punctuation">,</span>  <span class="token number">0.5857</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4382</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4094</span><span class="token punctuation">,</span>  <span class="token number">0.6650</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2651</span><span class="token punctuation">,</span>  <span class="token number">0.5529</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7386</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0719</span><span class="token punctuation">,</span>  <span class="token number">1.3542</span><span class="token punctuation">,</span>  <span class="token number">2.0680</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>div<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.4734</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.6912</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.6723</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3.6223</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1894</span><span class="token punctuation">,</span>  <span class="token number">1.2921</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">3.4513</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6867</span><span class="token punctuation">,</span>  <span class="token number">0.2832</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="18-torch-exp-tensor-out-None"><a href="#18-torch-exp-tensor-out-None" class="headerlink" title="18. torch.exp(tensor, out=None)"></a>18. torch.exp(tensor, out=None)</h3><p><strong>说明：</strong> 返回一个新张量，包含输入input张量每个元素的指数。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.3263</span><span class="token punctuation">,</span> <span class="token number">2.6751</span><span class="token punctuation">,</span> <span class="token number">1.1791</span><span class="token punctuation">,</span> <span class="token number">0.4109</span><span class="token punctuation">,</span> <span class="token number">0.2701</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----随机抽样、序列化、并行化</title>
      <link href="/2019/06/23/pytorch-xue-xi-zhi-torch-sui-ji-chou-yang-xu-lie-hua-bing-xing-hua/"/>
      <url>/2019/06/23/pytorch-xue-xi-zhi-torch-sui-ji-chou-yang-xu-lie-hua-bing-xing-hua/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-manual-seed-seed"><a href="#1-torch-manual-seed-seed" class="headerlink" title="1. torch.manual_seed(seed)"></a>1. torch.manual_seed(seed)</h3><p><strong>说明：</strong> 设置生成随机数的种子，返回一个torch._C.Generator对象。使用随机数种子之后，生成的随机数是相同的。<br><strong>参数：</strong></p><ul><li>seed(int or long) – 种子</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> torch<span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">&lt;</span>torch<span class="token punctuation">.</span>_C<span class="token punctuation">.</span>Generator object at <span class="token number">0x0000019684586350</span><span class="token operator">></span><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7576</span><span class="token punctuation">,</span> <span class="token number">0.2793</span><span class="token punctuation">,</span> <span class="token number">0.4031</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.7347</span><span class="token punctuation">,</span> <span class="token number">0.0293</span><span class="token punctuation">,</span> <span class="token number">0.7999</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">&lt;</span>torch<span class="token punctuation">.</span>_C<span class="token punctuation">.</span>Generator object at <span class="token number">0x0000019684586350</span><span class="token operator">></span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7576</span><span class="token punctuation">,</span> <span class="token number">0.2793</span><span class="token punctuation">,</span> <span class="token number">0.4031</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.7347</span><span class="token punctuation">,</span> <span class="token number">0.0293</span><span class="token punctuation">,</span> <span class="token number">0.7999</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">==</span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="2-torch-initial-seed"><a href="#2-torch-initial-seed" class="headerlink" title="2. torch.initial_seed()"></a>2. torch.initial_seed()</h3><p><strong>说明：</strong>返回生成随机数的原始种子值</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">&lt;</span>torch<span class="token punctuation">.</span>_C<span class="token punctuation">.</span>Generator object at <span class="token number">0x0000019684586350</span><span class="token operator">></span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>initial_seed<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token number">4</span></code></pre><h3 id="3-torch-get-rng-state"><a href="#3-torch-get-rng-state" class="headerlink" title="3. torch.get_rng_state()"></a>3. torch.get_rng_state()</h3><p><strong>说明：</strong> 返回随机生成器状态(ByteTensor)</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>initial_seed<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token number">4</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>get_rng_state<span class="token punctuation">(</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></code></pre><h3 id="4-torch-set-rng-state"><a href="#4-torch-set-rng-state" class="headerlink" title="4. torch.set_rng_state()"></a>4. torch.set_rng_state()</h3><p><strong>说明：</strong> 设定随机生成器状态<br><strong>参数：</strong></p><ul><li>new_state(ByteTensor) – 期望的状态</li></ul><h3 id="5-torch-default-generator"><a href="#5-torch-default-generator" class="headerlink" title="5. torch.default_generator"></a>5. torch.default_generator</h3><p><strong>说明：</strong>默认的随机生成器。等于&lt;torch._C.Generator object&gt;</p><h3 id="6-torch-bernoulli-input-out-None"><a href="#6-torch-bernoulli-input-out-None" class="headerlink" title="6. torch.bernoulli(input, out=None)"></a>6. torch.bernoulli(input, out=None)</h3><p><strong>说明：</strong>从伯努利分布中抽取二元随机数(0或1)。输入张量包含用于抽取二元值的概率。因此，输入中的所有值都必须在[0,1]区间内。输出张量的第i个元素值，将会以输入张量的第i个概率值等于1。返回值将会是与输入相同大小的张量，每个值为0或者1.<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入为伯努利分布的概率值</li><li>out(Tensor,可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>uniform_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5596</span><span class="token punctuation">,</span> <span class="token number">0.5591</span><span class="token punctuation">,</span> <span class="token number">0.0915</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.2100</span><span class="token punctuation">,</span> <span class="token number">0.0072</span><span class="token punctuation">,</span> <span class="token number">0.0390</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.9929</span><span class="token punctuation">,</span> <span class="token number">0.9131</span><span class="token punctuation">,</span> <span class="token number">0.6186</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-multinomial-input-num-samples-replacement-False-out-None"><a href="#7-torch-multinomial-input-num-samples-replacement-False-out-None" class="headerlink" title="7. torch.multinomial(input, num_samples, replacement=False, out=None)"></a>7. torch.multinomial(input, num_samples, replacement=False, out=None)</h3><p><strong>说明：</strong> 返回一个张量，每行包含从input相应行中定义的多项分布中抽取的num_samples个样本。要求输入input每行的值不需要总和为1，但是必须非负且总和不能为0。当抽取样本时，依次从左到右排列(第一个样本对应第一列)。如果输入input是一个向量，输出out也是一个相同长度num_samples的向量。如果输入input是m行的矩阵，输出out是形如m x n的矩阵。并且如果参数replacement为True，则样本抽取可以重复。否则，一个样本在每行不能被重复。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 包含概率的张量</li><li>num_samples(int) – 抽取的样本数</li><li>replacement(bool) – 布尔值，决定是否能重复抽取</li><li>out(Tensor) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> weights <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> weightstensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>weights<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> replacement<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-normal-means-std-out-None"><a href="#8-torch-normal-means-std-out-None" class="headerlink" title="8. torch.normal(means, std, out=None)"></a>8. torch.normal(means, std, out=None)</h3><p><strong>说明：</strong>返回一个张量，包含从给定参数means，std的离散正态分布中抽取随机数。均值means是一个张量，包含每个输出元素相关的正态分布的均值。std是一个张量。包含每个输出元素相关的正态分布的标准差。均值和标准差的形状不须匹配，但每个张量的元素个数必须想听。<br><strong>参数：</strong></p><ul><li>means(Tensor) – 均值</li><li>std(Tensor) – 标准差</li><li>out(Tensor) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> n_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> n_datatensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> x0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> n_data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> x0tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.6544</span><span class="token punctuation">,</span> <span class="token number">0.9805</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2.1114</span><span class="token punctuation">,</span> <span class="token number">2.7113</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1.0646</span><span class="token punctuation">,</span> <span class="token number">1.9675</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2.7652</span><span class="token punctuation">,</span> <span class="token number">3.2138</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1.1204</span><span class="token punctuation">,</span> <span class="token number">2.0293</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-save-obj-f-pickle-module-lt-module-‘pickle’-from-‘-home-lzjs-…"><a href="#9-torch-save-obj-f-pickle-module-lt-module-‘pickle’-from-‘-home-lzjs-…" class="headerlink" title="9. torch.save(obj, f, pickle_module=<module ‘pickle’ from ‘/home/lzjs/…)"></a>9. torch.save(obj, f, pickle_module=&lt;module ‘pickle’ from ‘/home/lzjs/…)</h3><p><strong>说明：</strong> 保存一个对象到一个硬盘文件上。<br><strong>参数：</strong></p><ul><li>obj – 保存对象</li><li>f – 类文件对象或一个保存文件名的字符串</li><li>pickle_module – 用于pickling源数据和对象的模块</li><li>pickle_protocol – 指定pickle protocal可以覆盖默认参数</li></ul><h3 id="10-torch-load-f-map-location-None-pickle-module-lt-module-‘pickle’-from-‘-home-lzjs-…"><a href="#10-torch-load-f-map-location-None-pickle-module-lt-module-‘pickle’-from-‘-home-lzjs-…" class="headerlink" title="10. torch.load(f, map_location=None, pickle_module=<module ‘pickle’ from ‘/home/lzjs/…)"></a>10. torch.load(f, map_location=None, pickle_module=&lt;module ‘pickle’ from ‘/home/lzjs/…)</h3><p><strong>说明：</strong> 从磁盘文件中读取一个通过torch.save()保存的对象。torch.load()可通过参数map_location动态地进行内存重映射，使其能从不动设备中读取文件。一般调用时，需两个参数：storage和location tag。返回不同地址中的storage，或者返回None。如果这个参数是字典的话，意味着从文件的地址标记到当前系统的地址标记的映射。<br><strong>参数：</strong></p><ul><li>f – l类文件对象或一个保存文件名的字符串</li><li>map_location – 一个函数或字典规定如何remap存储位置</li><li>pickle_module – 用于unpickling元数据和对象的模块</li></ul><pre class=" language-python"><code class="language-python">torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'tensors.pt'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 加载所有的张量到CPU</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'tensor.pt'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token keyword">lambda</span> storage<span class="token punctuation">,</span> loc<span class="token punctuation">:</span>storage<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 加载张量到GPU</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'tensors.pt'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'cuda:1'</span><span class="token punctuation">:</span><span class="token string">'cuda:0'</span><span class="token punctuation">}</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-get-num-threads"><a href="#11-torch-get-num-threads" class="headerlink" title="11. torch.get_num_threads()"></a>11. torch.get_num_threads()</h3><p><strong>说明：</strong> 获得用于并行化CPU操作的OpenMP线程数</p><h3 id="12-torch-set-num-threads"><a href="#12-torch-set-num-threads" class="headerlink" title="12. torch.set_num_threads()"></a>12. torch.set_num_threads()</h3><p><strong>说明：</strong> 设定用于并行化CPU操作的OpenMP线程数</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----索引、切片、连接、变异操作</title>
      <link href="/2019/06/22/pytorch-xue-xi-zhi-torch-suo-yin-qie-pian-lian-jie-bian-yi-cao-zuo/"/>
      <url>/2019/06/22/pytorch-xue-xi-zhi-torch-suo-yin-qie-pian-lian-jie-bian-yi-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-cat-seq-dim-0-out-None"><a href="#1-torch-cat-seq-dim-0-out-None" class="headerlink" title="1. torch.cat(seq, dim=0, out=None)"></a>1. torch.cat(seq, dim=0, out=None)</h3><p><strong>说明：</strong> 在给定维度上对输入的张量序列seq进行连接操作<br><strong>参数：</strong></p><ul><li>seq(Tensor的序列) – 可以是相同类型的Tensor的任何Python序列</li><li>dim(int, 可选) – 张量连接的维度，按dim维度连接张量</li><li>out(Tensor,可选) – 输出参数</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.2132</span><span class="token punctuation">,</span>  <span class="token number">0.5984</span><span class="token punctuation">,</span>  <span class="token number">0.7383</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.0272</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7861</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1590</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.2132</span><span class="token punctuation">,</span>  <span class="token number">0.5984</span><span class="token punctuation">,</span>  <span class="token number">0.7383</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.0272</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7861</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1590</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.2132</span><span class="token punctuation">,</span>  <span class="token number">0.5984</span><span class="token punctuation">,</span>  <span class="token number">0.7383</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.0272</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7861</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1590</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.2132</span><span class="token punctuation">,</span>  <span class="token number">0.5984</span><span class="token punctuation">,</span>  <span class="token number">0.7383</span><span class="token punctuation">,</span>  <span class="token number">0.2132</span><span class="token punctuation">,</span>  <span class="token number">0.5984</span><span class="token punctuation">,</span>  <span class="token number">0.7383</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.0272</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7861</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1590</span><span class="token punctuation">,</span>  <span class="token number">1.0272</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7861</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1590</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2-torch-chunk-tensor-chunks-dim"><a href="#2-torch-chunk-tensor-chunks-dim" class="headerlink" title="2. torch.chunk(tensor, chunks, dim)"></a>2. torch.chunk(tensor, chunks, dim)</h3><p><strong>说明：</strong> 在给定的维度上讲张量进行分块。<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 待分块的输入张量</li><li>chunks(int) – 分块的个数</li><li>dim(int) – 维度，沿着此维度进行分块</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0103</span><span class="token punctuation">,</span>  <span class="token number">2.3358</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.9236</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3890</span><span class="token punctuation">,</span>  <span class="token number">0.6594</span><span class="token punctuation">,</span>  <span class="token number">0.6664</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.5240</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4193</span><span class="token punctuation">,</span>  <span class="token number">0.1681</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0103</span><span class="token punctuation">,</span>  <span class="token number">2.3358</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.9236</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3890</span><span class="token punctuation">,</span>  <span class="token number">0.6594</span><span class="token punctuation">,</span>  <span class="token number">0.6664</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.5240</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4193</span><span class="token punctuation">,</span>  <span class="token number">0.1681</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0103</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3890</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.5240</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">2.3358</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.6594</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4193</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.9236</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.6664</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.1681</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0103</span><span class="token punctuation">,</span>  <span class="token number">2.3358</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3890</span><span class="token punctuation">,</span>  <span class="token number">0.6594</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.5240</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4193</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.9236</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.6664</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.1681</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="3-torch-gather-input-dim-index-out-None"><a href="#3-torch-gather-input-dim-index-out-None" class="headerlink" title="3. torch.gather(input, dim, index, out=None)"></a>3. torch.gather(input, dim, index, out=None)</h3><p><strong>说明：</strong> 沿着给定维度，将输入索引张量index指定的位置的值重新聚合为一个新的张量。如果dim=1，那就是横向，index的索引代表列。dim=0那就是纵向，index索引代表的就是行值。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 源张量</li><li>dim(int) – 索引的维度</li><li>index(LongTensor) – 聚合元素的下表</li><li>out(Tensor,可选) – 目标张量</li></ul><p>下面的例子中，维度为1.那么取横行的元素。所以在第一行的下标为[0, 0],因此，聚合后的元素都取1，第二行的下表为[1, 0],因此聚合后的元素去[4, 3]。</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> t <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ttensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> index <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> indextensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>t<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="4-torch-index-select-input-dim-index-out-None"><a href="#4-torch-index-select-input-dim-index-out-None" class="headerlink" title="4. torch.index_select(input, dim, index, out=None)"></a>4. torch.index_select(input, dim, index, out=None)</h3><p><strong>说明：</strong>沿着指定维度对输入进行切片，取index中指定的相应项，返回一个新的张量，返回的张量与原始的张量有相同的维度。返回张量不与原始张量共享内存中的空间。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>dim(int) – 索引的维度</li><li>index(LongTensor) – 包含索引下标的一维张量</li><li>out(Tensor, 可选) – 目标张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0190</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7541</span><span class="token punctuation">,</span>  <span class="token number">2.1090</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9576</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4745</span><span class="token punctuation">,</span>  <span class="token number">0.1462</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.2930</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9130</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.7339</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.0842</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9208</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5618</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> indices<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0190</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7541</span><span class="token punctuation">,</span>  <span class="token number">2.1090</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9576</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.7339</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.0842</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9208</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5618</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> indices<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0190</span><span class="token punctuation">,</span>  <span class="token number">2.1090</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.4745</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.2930</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.7339</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9208</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="5-torch-masked-select-input-mask-out-None"><a href="#5-torch-masked-select-input-mask-out-None" class="headerlink" title="5. torch.masked_select(input, mask, out=None)"></a>5. torch.masked_select(input, mask, out=None)</h3><p><strong>说明：</strong> 根据掩码张量mask中的二元值，取输入张量中指定项，将取值返回到一个新的1维张量。张量mask必须跟input张量有相同数量的元素数目，但形状或维度不需要相同。并且返回的张量不与原始张量共享内存空间。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>mask(ByteTensor) – 掩码张量，包含了二元索引值</li><li>out(Tensor, 可选) – 目标张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>ByteTensor<span class="token punctuation">(</span>x <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> masktensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>x<span class="token punctuation">,</span> mask<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1965</span><span class="token punctuation">,</span> <span class="token number">0.4689</span><span class="token punctuation">,</span> <span class="token number">0.2898</span><span class="token punctuation">,</span> <span class="token number">0.4847</span><span class="token punctuation">,</span> <span class="token number">2.8944</span><span class="token punctuation">,</span> <span class="token number">0.7096</span><span class="token punctuation">,</span> <span class="token number">0.0900</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-nonzero-input-out-None"><a href="#6-torch-nonzero-input-out-None" class="headerlink" title="6. torch.nonzero(input, out=None)"></a>6. torch.nonzero(input, out=None)</h3><p><strong>说明：</strong> 返回一个包含输入input中非零元素索引的张量。输出张量中的每行包含输入中非零元素的索引。如果输入input有n维，则输出的索引张量output的形状为z x n，这里z是输入张量input中所有非零元素的个数。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 源张量</li><li>out(LongTensor, 可选) – 包含索引值的结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                             <span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-split-tensor-split-size-dim-0"><a href="#7-torch-split-tensor-split-size-dim-0" class="headerlink" title="7. torch.split(tensor, split_size, dim=0)"></a>7. torch.split(tensor, split_size, dim=0)</h3><p><strong>说明：</strong> 将输入张量分割成相等形状的chunks(如果可分)。如果沿指定维的张量形状大小不能被整分，则最后一块会小于其他分块。<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 待分割张量</li><li>split_size(int) – 单个分块的形状大小</li><li>dim(int) – 沿着此维进行分割</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.1135</span><span class="token punctuation">,</span>  <span class="token number">0.5779</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9737</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0718</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.4136</span><span class="token punctuation">,</span>  <span class="token number">1.1577</span><span class="token punctuation">,</span>  <span class="token number">0.5689</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1970</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.4281</span><span class="token punctuation">,</span>  <span class="token number">0.3540</span><span class="token punctuation">,</span>  <span class="token number">1.4346</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1444</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1135</span><span class="token punctuation">,</span> <span class="token number">0.5779</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.4136</span><span class="token punctuation">,</span> <span class="token number">1.1577</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1.4281</span><span class="token punctuation">,</span> <span class="token number">0.3540</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.9737</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0718</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.5689</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1970</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.4346</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1444</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.1135</span><span class="token punctuation">,</span>  <span class="token number">0.5779</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9737</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0718</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.4136</span><span class="token punctuation">,</span>  <span class="token number">1.1577</span><span class="token punctuation">,</span>  <span class="token number">0.5689</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1970</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.4281</span><span class="token punctuation">,</span>  <span class="token number">0.3540</span><span class="token punctuation">,</span>  <span class="token number">1.4346</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1444</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-squeeze-input-dim-None-out-None"><a href="#8-torch-squeeze-input-dim-None-out-None" class="headerlink" title="8. torch.squeeze(input, dim=None, out=None)"></a>8. torch.squeeze(input, dim=None, out=None)</h3><p><strong>说明：</strong>将输入张量形状中的1去除并返回。如果输入是形如(Ax1xBx1xCx1xD)，那么输入的形状就为：(AxBxCxD)。当给定维度时，那么挤压操作只在给定维度上。例如，输入形状为：(Ax1xB),squeeze(input,0)将会保持张量不变，只有用squeeze(input,1)，形状会变成(AxB)。注意返回张量与输入张量共享内存，所以改变其中一个的内容会改变另一个。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>dim(int,可选) – 如果给定，则input只会在给定维度挤压</li><li>out(Tensor, 可选) – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-stack-sequence-dim-0"><a href="#9-torch-stack-sequence-dim-0" class="headerlink" title="9. torch.stack(sequence, dim=0)"></a>9. torch.stack(sequence, dim=0)</h3><p><strong>说明：</strong> 沿着一个新维度对输入张量序列进行连接。序列中所有的张量都应该为相同形状。<br>** 参数：**</p><ul><li>sequence(序列) – 待连接的张量序列</li><li>dim(int) – 插入的维度，必须介于0与待连接的张量序列数之间</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> atensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                   <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                   <span class="token punctuation">[</span><span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">90</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> btensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">70</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">90</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> c <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                   <span class="token punctuation">[</span><span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                   <span class="token punctuation">[</span><span class="token number">700</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">,</span> <span class="token number">900</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ctensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">400</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">700</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">900</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span>  <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">20</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span>  <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">40</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">30</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span>  <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">50</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span>  <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">60</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">70</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">700</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span>  <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">80</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span>  <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">90</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">900</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-t-input-out-None"><a href="#10-torch-t-input-out-None" class="headerlink" title="10. torch.t(input, out=None)"></a>10. torch.t(input, out=None)</h3><p><strong>说明：</strong>输入一个矩阵(2为张量)，并转置0,1维。可以被视为函数transpose(input, 0, 1)的简写函数。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>out(Tensor, 可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.9204</span><span class="token punctuation">,</span>  <span class="token number">0.7971</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.8631</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8583</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.3379</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4079</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>t<span class="token punctuation">(</span>x<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.9204</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8583</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.7971</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.3379</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.8631</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4079</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-transpose-input-dim0-dim1-out-None"><a href="#11-torch-transpose-input-dim0-dim1-out-None" class="headerlink" title="11. torch.transpose(input, dim0, dim1, out=None)"></a>11. torch.transpose(input, dim0, dim1, out=None)</h3><p><strong>说明：</strong> 返回输入矩阵input的转置。交换维度dim0和dim1.输出张量与输入张量共享内存，所以改变其中一个会导致另外一个也被修改。<br><strong>参数：</strong></p><ul><li>input(Tensor) – 输入张量</li><li>dim0(int) – 转置的第一维</li><li>dim1(int) – 转置的第二维</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.5434</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.3860</span><span class="token punctuation">,</span>  <span class="token number">0.0252</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.4734</span><span class="token punctuation">,</span>  <span class="token number">0.2466</span><span class="token punctuation">,</span>  <span class="token number">0.3052</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.5434</span><span class="token punctuation">,</span>  <span class="token number">0.4734</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.3860</span><span class="token punctuation">,</span>  <span class="token number">0.2466</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.0252</span><span class="token punctuation">,</span>  <span class="token number">0.3052</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="12-torch-unbind-tensor-dim-0"><a href="#12-torch-unbind-tensor-dim-0" class="headerlink" title="12. torch.unbind(tensor, dim=0):"></a>12. torch.unbind(tensor, dim=0):</h3><p><strong>说明：</strong> 移除指定维后，返回一个元组，包含了沿着指定维切片后的各个切片。<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 输入张量</li><li>dim(int) – 删除的维度</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.4775</span><span class="token punctuation">,</span>  <span class="token number">0.0161</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9403</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.6109</span><span class="token punctuation">,</span>  <span class="token number">2.1144</span><span class="token punctuation">,</span>  <span class="token number">1.1833</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2656</span><span class="token punctuation">,</span>  <span class="token number">0.7772</span><span class="token punctuation">,</span>  <span class="token number">0.5989</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.4775</span><span class="token punctuation">,</span>  <span class="token number">1.6109</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2656</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0161</span><span class="token punctuation">,</span> <span class="token number">2.1144</span><span class="token punctuation">,</span> <span class="token number">0.7772</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.9403</span><span class="token punctuation">,</span>  <span class="token number">1.1833</span><span class="token punctuation">,</span>  <span class="token number">0.5989</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="13-torch-unsqueeze-input-dim-out-None"><a href="#13-torch-unsqueeze-input-dim-out-None" class="headerlink" title="13. torch.unsqueeze(input, dim, out=None)"></a>13. torch.unsqueeze(input, dim, out=None)</h3><p><strong>说明：</strong>返回一个新的张量，对输入的指定位置插入维度1.注意返回张量与输入张量共享内存，如果dim为负，则将会被转换为dim + input.dim() + 1.<br><strong>参数：</strong></p><ul><li>tensor(Tensor) – 输入张量</li><li>dim(int) – 插入维度的索引</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch学习之torch----创建操作</title>
      <link href="/2019/06/21/pytorch-xue-xi-zhi-torch-chuang-jian-cao-zuo/"/>
      <url>/2019/06/21/pytorch-xue-xi-zhi-torch-chuang-jian-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h3 id="1-torch-eye-n-m-None-out-None"><a href="#1-torch-eye-n-m-None-out-None" class="headerlink" title="1. torch.eye(n, m=None, out=None)"></a>1. torch.eye(n, m=None, out=None)</h3><p><strong>说明：</strong> 创建一个2维张量，对角线数字为1， 其他位置为0。也就是一个单位矩阵。</p><p><strong>参数：</strong></p><ul><li>n – 行数，</li><li>m – 列数，如果为None，默认等于n，</li><li>out – 输出张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> torch<span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="2-torch-from-numpy-ndarray"><a href="#2-torch-from-numpy-ndarray" class="headerlink" title="2. torch.from_numpy(ndarray)"></a>2. torch.from_numpy(ndarray)</h3><p><strong>说明：</strong> 将numpy.ndarray转换为Tensor。返回的Tensor和numpy的ndarray共享同一内存空间。修改一个会导致另外一个也被修改。返回的张量不能调整大小。</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">import</span> numpy<span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> numpy<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> t <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> ttensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> t<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token operator">>></span><span class="token operator">></span> aarray<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="3-torch-linspace-start-end-steps-100-out-None"><a href="#3-torch-linspace-start-end-steps-100-out-None" class="headerlink" title="3. torch.linspace(start, end, steps=100, out=None)"></a>3. torch.linspace(start, end, steps=100, out=None)</h3><p><strong>说明：</strong> 返回start和end之间长度为steps的一维张量，也就是start和end之间的steps个数。并且其返回的是一个等差数列。<br><strong>参数：</strong></p><ul><li>start(float) – 点集的起始值，</li><li>end(float) – 点集的最终值，</li><li>steps(int) – start和end之间的采样数，即返回多少个数</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> steps<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>   <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>   <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">1.2500</span><span class="token punctuation">,</span> <span class="token number">2.5000</span><span class="token punctuation">,</span> <span class="token number">3.7500</span><span class="token punctuation">,</span> <span class="token number">5.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token operator">=</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> steps<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10.0000</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">7.7778</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">5.5556</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">3.3333</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">1.1111</span><span class="token punctuation">,</span>   <span class="token number">1.1111</span><span class="token punctuation">,</span>   <span class="token number">3.3333</span><span class="token punctuation">,</span>          <span class="token number">5.5556</span><span class="token punctuation">,</span>   <span class="token number">7.7778</span><span class="token punctuation">,</span>  <span class="token number">10.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="4-torch-logspace-start-end-steps-100-out-None"><a href="#4-torch-logspace-start-end-steps-100-out-None" class="headerlink" title="4. torch.logspace(start, end, steps=100, out=None)"></a>4. torch.logspace(start, end, steps=100, out=None)</h3><p><strong>说明：</strong> 返回一个1维张量，包含在区间和上，以对数刻度均匀间隔的steps个点。输出1维张量的长度为steps。<br><strong>参数：</strong></p><ul><li>start(float) – 点集的起始点</li><li>end(float) – 点集的最终点</li><li>steps(int) – 在start和end间生成的样本数</li><li>out(Tensor,可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>logspace<span class="token punctuation">(</span>start<span class="token operator">=</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> steps<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0000e-10</span><span class="token punctuation">,</span> <span class="token number">1.0000e-05</span><span class="token punctuation">,</span> <span class="token number">1.0000e+00</span><span class="token punctuation">,</span> <span class="token number">1.0000e+05</span><span class="token punctuation">,</span> <span class="token number">1.0000e+10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>logspace<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.2589</span><span class="token punctuation">,</span>  <span class="token number">2.1135</span><span class="token punctuation">,</span>  <span class="token number">3.5481</span><span class="token punctuation">,</span>  <span class="token number">5.9566</span><span class="token punctuation">,</span> <span class="token number">10.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="5-torch-ones-sizes-out-None"><a href="#5-torch-ones-sizes-out-None" class="headerlink" title="5. torch.ones(*sizes, out=None)"></a>5. torch.ones(*sizes, out=None)</h3><p><strong>说明：</strong> 返回一个全为1的张量，形状由可变参数sizes定义。<br><strong>参数：</strong></p><ul><li>sizes(int) – 整数序列，定义了输出的形状。如(3,3）</li><li>out(Tensor, 可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="6-torch-rand-size-out-None"><a href="#6-torch-rand-size-out-None" class="headerlink" title="6. torch.rand(*size, out=None)"></a>6. torch.rand(*size, out=None)</h3><p><strong>说明：</strong> 返回一个张量，填充在[0,1]区间的一组均匀分布随机数。Tensor的形状由变量sizes定义。<br><strong>参数：</strong></p><ul><li>sizes(int) – 整数序列，定义了输出形状</li><li>out(Tensor, 可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.4962</span><span class="token punctuation">,</span> <span class="token number">0.0724</span><span class="token punctuation">,</span> <span class="token number">0.0478</span><span class="token punctuation">,</span> <span class="token number">0.3524</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.3200</span><span class="token punctuation">,</span> <span class="token number">0.7308</span><span class="token punctuation">,</span> <span class="token number">0.3226</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.8039</span><span class="token punctuation">,</span> <span class="token number">0.2359</span><span class="token punctuation">,</span> <span class="token number">0.7256</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="7-torch-randn-size-out-None"><a href="#7-torch-randn-size-out-None" class="headerlink" title="7. torch.randn(*size, out=None)"></a>7. torch.randn(*size, out=None)</h3><p><strong>说明：</strong> 返回一个张量，包含了从正态分布(均值为0，方差为1)中抽取一组随机数。Tensor的形状由变量sizes定义。<br><strong>参数：</strong></p><ul><li>sizes(int) – 整数序列，定义了输出形状</li><li>out(Tensor, 可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.3094</span><span class="token punctuation">,</span>  <span class="token number">0.4774</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1807</span><span class="token punctuation">,</span>  <span class="token number">0.9894</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3299</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0495</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4758</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0680</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3875</span><span class="token punctuation">,</span>  <span class="token number">0.9846</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="8-torch-randperm-n-out-None"><a href="#8-torch-randperm-n-out-None" class="headerlink" title="8. torch.randperm(n, out=None)"></a>8. torch.randperm(n, out=None)</h3><p><strong>说明：</strong> 返回以LongTenor，输入参数n，返回一个从0到n-1的随机整数排列。<br><strong>参数：</strong></p><ul><li>n(int) – 上限，即最大值。</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="9-torch-arange-start-end-step-1-out-None"><a href="#9-torch-arange-start-end-step-1-out-None" class="headerlink" title="9. torch.arange(start, end, step=1, out=None)"></a>9. torch.arange(start, end, step=1, out=None)</h3><p><strong>说明：</strong>  返回一个1维张量，长度为，中间计算值，向下取整的意思。包含从start到end，以step为步长的一组序列值。默认步长为1。<br><strong>参数：</strong></p><ul><li>start(float) – 该点集的起始点</li><li>end(float) – 点集的终止点</li><li>step(float) – 相邻点的间隔大小</li><li>out(Tensor, 可选的) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token number">1.5000</span><span class="token punctuation">,</span> <span class="token number">2.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="10-torch-range-start-end-step-1-out-None"><a href="#10-torch-range-start-end-step-1-out-None" class="headerlink" title="10. torch.range(start, end, step=1, out=None)"></a>10. torch.range(start, end, step=1, out=None)</h3><p><strong>说明：</strong> 返回一维张量，长度为+1，从start开始，到end结束。以step为步长的一组值。step是两个值之间的间隔。<br><strong>参数：</strong></p><ul><li>start(float) – 点集的起始点</li><li>end(float) – 点集的最终值</li><li>step(int) – 相邻点之间的间隔大小</li><li>out(Tensor, 可选的) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>__main__<span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">:</span> UserWarning<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>range <span class="token keyword">is</span> deprecated <span class="token keyword">in</span> favor of torch<span class="token punctuation">.</span>arange <span class="token operator">and</span> will be removed <span class="token keyword">in</span> <span class="token number">0.5</span><span class="token punctuation">.</span> Note that arange generates values <span class="token keyword">in</span> <span class="token punctuation">[</span>start<span class="token punctuation">;</span> end<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">not</span> <span class="token punctuation">[</span>start<span class="token punctuation">;</span> end<span class="token punctuation">]</span><span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token number">1.5000</span><span class="token punctuation">,</span> <span class="token number">2.0000</span><span class="token punctuation">,</span> <span class="token number">2.5000</span><span class="token punctuation">,</span> <span class="token number">3.0000</span><span class="token punctuation">,</span> <span class="token number">3.5000</span><span class="token punctuation">,</span> <span class="token number">4.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><h3 id="11-torch-zeros-size-out-None"><a href="#11-torch-zeros-size-out-None" class="headerlink" title="11. torch.zeros(*size, out=None)"></a>11. torch.zeros(*size, out=None)</h3><p><strong>说明：</strong>返回一个全0的张量，形状由可变参数sizes定义。<br><strong>参数：</strong></p><ul><li>sizes(int) – 整数序列，定义了输出形状</li><li>out(Tensor, 可选) – 结果张量</li></ul><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p><strong>总结：</strong> 这部分内容主要是创建操作，创建一些随机数，或者是矩阵。在pytorch中，他们都是张量类型。简单的创建操作。反复练习。方可掌握。如果有numpy的基础。那就更加容易学习。其实无论numpy，tensorflow，pytorch等。在创建一些随机数/矩阵中，他们都是相同的。只不过是存在不同的第三方库中。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Pytorch </tag>
            
            <tag> 编程框架 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
